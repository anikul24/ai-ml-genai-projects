{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78eadc9e",
   "metadata": {},
   "source": [
    "# Build a Research Agent which can get information from online archive path and use serach API to create report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714e1bc",
   "metadata": {},
   "source": [
    "## 1. Intall required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fed496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic_router in c:\\users\\prach\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.1.11)\n",
      "Requirement already satisfied: pinecone in c:\\users\\prach\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (7.3.0)\n",
      "Requirement already satisfied: serpapi in c:\\users\\prach\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.1.5)\n",
      "Requirement already satisfied: google-search-results in c:\\users\\prach\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (2.4.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.10.11 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (3.13.2)\n",
      "Requirement already satisfied: aurelio-sdk>=0.0.19 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (0.0.19)\n",
      "Requirement already satisfied: colorama<0.5,>=0.4.6 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: colorlog<7,>=6.8.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (6.10.1)\n",
      "Requirement already satisfied: litellm>=1.61.3 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (1.79.3)\n",
      "Requirement already satisfied: numpy>=1.25.2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (1.109.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.10.2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (2.12.2)\n",
      "Requirement already satisfied: pyyaml<7,>=6.0.1 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: regex>=2023.12.25 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.6.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (0.12.0)\n",
      "Requirement already satisfied: tornado<7,>=6.4.2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (6.5.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from semantic_router->-r requirements.txt (line 3)) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aiohttp<4,>=3.10.11->semantic_router->-r requirements.txt (line 3)) (1.18.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\prach\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\prach\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->semantic_router->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.10.2->semantic_router->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.10.2->semantic_router->-r requirements.txt (line 3)) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.10.2->semantic_router->-r requirements.txt (line 3)) (0.4.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from tiktoken<1.0.0,>=0.6.0->semantic_router->-r requirements.txt (line 3)) (2.32.5)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pinecone->-r requirements.txt (line 4)) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pinecone->-r requirements.txt (line 4)) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pinecone->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone->-r requirements.txt (line 4)) (24.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.6.0->semantic_router->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: aiofiles<25.0.0,>=24.1.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aurelio-sdk>=0.0.19->semantic_router->-r requirements.txt (line 3)) (24.1.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aurelio-sdk>=0.0.19->semantic_router->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from aurelio-sdk>=0.0.19->semantic_router->-r requirements.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\prach\\anaconda3\\lib\\site-packages (from litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (8.1.8)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (0.14.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (4.23.0)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\prach\\anaconda3\\lib\\site-packages (from litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (0.22.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (0.22.3)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone->-r requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from tokenizers->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (1.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\prach\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\prach\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\prach\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\prach\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.61.3->semantic_router->-r requirements.txt (line 3)) (0.20.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6808323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "ARXIV_NAMESPACE = '{http://www.w3.org/2005/Atom}'\n",
    "\n",
    "\n",
    "def extract_from_arxiv (search_query='cat:cs.AI', max_results=50, json_file_path='files/arxiv_dataset.json'):\n",
    "    \"\"\"\n",
    "    Search papers from ARXIV API and save them as JSON\n",
    "\n",
    "    Args:\n",
    "        search_query (str): The search query for ArXiv (default is 'cat:cs.AI').\n",
    "        max_results (int): The maximum number of results to retrieve (default is 100).\n",
    "        json_file_path (str): File path where JSON data will be saved.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the extracted paper information.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "## check documentation at https://info.arxiv.org/help/api/user-manual.html#412-python\n",
    "\n",
    "    url = f'http://export.arxiv.org/api/query?search_query={search_query}&start=0&max_results={max_results}'\n",
    "\n",
    "    #http://export.arxiv.org/api/query?search_query=cat:cs.AI&start=0&max_results=50\n",
    "\n",
    "    #response = requests.get(url)\n",
    "    #print(response.text)\n",
    "\n",
    "    # with open('files/old_response.txt', 'r', encoding='utf-8') as f:\n",
    "    #     f.read(old_response)\n",
    "\n",
    "    old_reponse_file = 'files/old_response.xml'\n",
    "\n",
    "    #root = ET.fromstring(old_reponse_file)\n",
    "    tree = ET.parse(old_reponse_file)\n",
    "    root = tree.getroot()\n",
    "    print(type(root))\n",
    "\n",
    "    papers=[]\n",
    "\n",
    "    ## find all for multiple elements and find for first single element find\n",
    "    for entry in root.findall(f'{ARXIV_NAMESPACE}entry'):\n",
    "        title = entry.find(f'{ARXIV_NAMESPACE}title').text.strip()\n",
    "        summary = entry.find(f'{ARXIV_NAMESPACE}summary').text.strip()\n",
    "\n",
    "        #Get all authors\n",
    "        author_elements= entry.findall(f'{ARXIV_NAMESPACE}author')\n",
    "        authors = [ authors.find(f'{ARXIV_NAMESPACE}name').text    for authors in author_elements]\n",
    "        #print(f'authors: {authors}')\n",
    "\n",
    "        #get paper url\n",
    "        url = entry.find(f'{ARXIV_NAMESPACE}id').text.strip()\n",
    "        #print(f'url: {url} \\n')\n",
    "\n",
    "        arxiv_id = url.split('/')[-1]\n",
    "        #print(f'arxiv_id: {arxiv_id} \\n')\n",
    "\n",
    "        ##check for pdf link\n",
    "        pdf_link_element = entry.find(f'{ARXIV_NAMESPACE}link[@title=\"pdf\"]')\n",
    "        if pdf_link_element is not None:\n",
    "            pdf_link = pdf_link_element.attrib.get('href')\n",
    "            print(f'pdf_link: {pdf_link} \\n')\n",
    "        else:\n",
    "            pdf_link = None\n",
    "            print(f'pdf_link NOT found: {pdf_link} \\n')\n",
    "\n",
    "\n",
    "        # pdf_link = entry.find(f'{ARXIV_NAMESPACE}link[@title=\"pdf\"]').attrib.get('href')\n",
    "        # #print(f'pdf_link: {pdf_link} \\n')\n",
    "\n",
    "        papers.append({\n",
    "            'title': title,\n",
    "            'summary': summary,\n",
    "            'authors': authors,\n",
    "            'arxiv_id': arxiv_id,\n",
    "            'url': url,\n",
    "            'pdf_link': pdf_link\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(papers)\n",
    "    \n",
    "    print(df.head(1))\n",
    "\n",
    "\n",
    "    # Save the DataFrame to a JSON file.\n",
    "    with open(json_file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(papers, f, ensure_ascii=False, indent=4)\n",
    "        print(f'Data saved to {json_file_path} ...')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c938b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'xml.etree.ElementTree.Element'>\n",
      "pdf_link: http://arxiv.org/pdf/cs/9308101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9308102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9309101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9311101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9311102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9312101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9401101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9402101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9402102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9402103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9403101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9406101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9406102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9408101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9408102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9408103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9409101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9412101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9412102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9412103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9501101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9501102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9501103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9503102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9504101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9505101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9505102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9505103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9505104v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9505105v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9506101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9506102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9507101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9508101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9508102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9510101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9510102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9510103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9511101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512103v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512104v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512105v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512106v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9512107v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9601101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9602101v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9602102v1 \n",
      "\n",
      "pdf_link: http://arxiv.org/pdf/cs/9603101v1 \n",
      "\n",
      "                  title                                            summary  \\\n",
      "0  Dynamic Backtracking  Because of their occasional need to return to ...   \n",
      "\n",
      "            authors   arxiv_id                                url  \\\n",
      "0  [M. L. Ginsberg]  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
      "\n",
      "                            pdf_link  \n",
      "0  http://arxiv.org/pdf/cs/9308101v1  \n",
      "Data saved to files/arxiv_dataset.json ...\n"
     ]
    }
   ],
   "source": [
    "df = extract_from_arxiv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae3e2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5c867",
   "metadata": {},
   "source": [
    "## 2.Download PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9f8508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>pdf_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308101v1</td>\n",
       "      <td>files\\9308101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Market-Oriented Programming Environment and ...</td>\n",
       "      <td>Market price systems constitute a well-underst...</td>\n",
       "      <td>[M. P. Wellman]</td>\n",
       "      <td>9308102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308102v1</td>\n",
       "      <td>files\\9308102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An Empirical Analysis of Search in GSAT</td>\n",
       "      <td>We describe an extensive study of search in GS...</td>\n",
       "      <td>[I. P. Gent, T. Walsh]</td>\n",
       "      <td>9309101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9309101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9309101v1</td>\n",
       "      <td>files\\9309101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Difficulties of Learning Logic Programs wi...</td>\n",
       "      <td>As real logic programmers normally use cut (!)...</td>\n",
       "      <td>[F. Bergadano, D. Gunetti, U. Trinchero]</td>\n",
       "      <td>9311101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9311101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9311101v1</td>\n",
       "      <td>files\\9311101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Software Agents: Completing Patterns and Const...</td>\n",
       "      <td>To support the goal of allowing users to recor...</td>\n",
       "      <td>[J. C. Schlimmer, L. A. Hermens]</td>\n",
       "      <td>9311102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9311102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9311102v1</td>\n",
       "      <td>files\\9311102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decidable Reasoning in Terminological Knowledg...</td>\n",
       "      <td>Terminological knowledge representation system...</td>\n",
       "      <td>[M. Buchheit, F. M. Donini, A. Schaerf]</td>\n",
       "      <td>9312101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9312101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9312101v1</td>\n",
       "      <td>files\\9312101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Teleo-Reactive Programs for Agent Control</td>\n",
       "      <td>A formalism is presented for computing and org...</td>\n",
       "      <td>[N. Nilsson]</td>\n",
       "      <td>9401101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9401101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9401101v1</td>\n",
       "      <td>files\\9401101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Learning the Past Tense of English Verbs: The ...</td>\n",
       "      <td>Learning the past tense of English verbs - a s...</td>\n",
       "      <td>[C. X. Ling]</td>\n",
       "      <td>9402101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9402101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9402101v1</td>\n",
       "      <td>files\\9402101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Substructure Discovery Using Minimum Descripti...</td>\n",
       "      <td>The ability to identify interesting and repeti...</td>\n",
       "      <td>[D. J. Cook, L. B. Holder]</td>\n",
       "      <td>9402102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9402102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9402102v1</td>\n",
       "      <td>files\\9402102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bias-Driven Revision of Logical Domain Theories</td>\n",
       "      <td>The theory revision problem is the problem of ...</td>\n",
       "      <td>[M. Koppel, R. Feldman, A. M. Segre]</td>\n",
       "      <td>9402103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9402103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9402103v1</td>\n",
       "      <td>files\\9402103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Exploring the Decision Forest: An Empirical In...</td>\n",
       "      <td>We report on a series of experiments in which ...</td>\n",
       "      <td>[P. M. Murphy, M. J. Pazzani]</td>\n",
       "      <td>9403101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9403101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9403101v1</td>\n",
       "      <td>files\\9403101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A Semantics and Complete Algorithm for Subsump...</td>\n",
       "      <td>This paper analyzes the correctness of the sub...</td>\n",
       "      <td>[A. Borgida, P. F. Patel-Schneider]</td>\n",
       "      <td>9406101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9406101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9406101v1</td>\n",
       "      <td>files\\9406101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Applying GSAT to Non-Clausal Formulas</td>\n",
       "      <td>In this paper we describe how to modify GSAT s...</td>\n",
       "      <td>[R. Sebastiani]</td>\n",
       "      <td>9406102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9406102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9406102v1</td>\n",
       "      <td>files\\9406102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Worlds and Maximum Entropy</td>\n",
       "      <td>Given a knowledge base KB containing first-ord...</td>\n",
       "      <td>[A. J. Grove, J. Y. Halpern, D. Koller]</td>\n",
       "      <td>9408101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9408101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9408101v1</td>\n",
       "      <td>files\\9408101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pattern Matching and Discourse Processing in I...</td>\n",
       "      <td>Information extraction is the task of automati...</td>\n",
       "      <td>[T. Kitani, Y. Eriguchi, M. Hara]</td>\n",
       "      <td>9408102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9408102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9408102v1</td>\n",
       "      <td>files\\9408102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A System for Induction of Oblique Decision Trees</td>\n",
       "      <td>This article describes a new system for induct...</td>\n",
       "      <td>[S. K. Murthy, S. Kasif, S. Salzberg]</td>\n",
       "      <td>9408103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9408103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9408103v1</td>\n",
       "      <td>files\\9408103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>On Planning while Learning</td>\n",
       "      <td>This paper introduces a framework for Planning...</td>\n",
       "      <td>[S. Safra, M. Tennenholtz]</td>\n",
       "      <td>9409101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9409101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9409101v1</td>\n",
       "      <td>files\\9409101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wrap-Up: a Trainable Discourse Module for Info...</td>\n",
       "      <td>The vast amounts of on-line text now available...</td>\n",
       "      <td>[S. Soderland, Lehnert. W]</td>\n",
       "      <td>9412101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412101v1</td>\n",
       "      <td>files\\9412101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Operations for Learning with Graphical Models</td>\n",
       "      <td>This paper is a multidisciplinary review of em...</td>\n",
       "      <td>[W. L. Buntine]</td>\n",
       "      <td>9412102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412102v1</td>\n",
       "      <td>files\\9412102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Total-Order and Partial-Order Planning: A Comp...</td>\n",
       "      <td>For many years, the intuitions underlying part...</td>\n",
       "      <td>[S. Minton, J. Bresina, M. Drummond]</td>\n",
       "      <td>9412103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9412103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9412103v1</td>\n",
       "      <td>files\\9412103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Solving Multiclass Learning Problems via Error...</td>\n",
       "      <td>Multiclass learning problems involve finding a...</td>\n",
       "      <td>[T. G. Dietterich, G. Bakiri]</td>\n",
       "      <td>9501101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9501101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9501101v1</td>\n",
       "      <td>files\\9501101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A Domain-Independent Algorithm for Plan Adapta...</td>\n",
       "      <td>The paradigms of transformational planning, ca...</td>\n",
       "      <td>[S. Hanks, D. S. Weld]</td>\n",
       "      <td>9501102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9501102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9501102v1</td>\n",
       "      <td>files\\9501102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Truncating Temporal Differences: On the Effici...</td>\n",
       "      <td>Temporal difference (TD) methods constitute a ...</td>\n",
       "      <td>[P. Cichosz]</td>\n",
       "      <td>9501103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9501103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9501103v1</td>\n",
       "      <td>files\\9501103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cost-Sensitive Classification: Empirical Evalu...</td>\n",
       "      <td>This paper introduces ICET, a new algorithm fo...</td>\n",
       "      <td>[P. D. Turney]</td>\n",
       "      <td>9503102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9503102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9503102v1</td>\n",
       "      <td>files\\9503102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Rerepresenting and Restructuring Domain Theori...</td>\n",
       "      <td>Theory revision integrates inductive learning ...</td>\n",
       "      <td>[S. K. Donoho, L. A. Rendell]</td>\n",
       "      <td>9504101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9504101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9504101v1</td>\n",
       "      <td>files\\9504101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Using Pivot Consistency to Decompose and Solve...</td>\n",
       "      <td>Many studies have been carried out in order to...</td>\n",
       "      <td>[P. David]</td>\n",
       "      <td>9505101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9505101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9505101v1</td>\n",
       "      <td>files\\9505101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Adaptive Load Balancing: A Study in Multi-Agen...</td>\n",
       "      <td>We study the process of multi-agent reinforcem...</td>\n",
       "      <td>[A. Schaerf, Y. Shoham, M. Tennenholtz]</td>\n",
       "      <td>9505102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9505102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9505102v1</td>\n",
       "      <td>files\\9505102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Provably Bounded-Optimal Agents</td>\n",
       "      <td>Since its inception, artificial intelligence h...</td>\n",
       "      <td>[S. J. Russell, D. Subramanian]</td>\n",
       "      <td>9505103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9505103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9505103v1</td>\n",
       "      <td>files\\9505103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Pac-Learning Recursive Logic Programs: Efficie...</td>\n",
       "      <td>We present algorithms that learn certain class...</td>\n",
       "      <td>[W. W. Cohen]</td>\n",
       "      <td>9505104v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9505104v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9505104v1</td>\n",
       "      <td>files\\9505104v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Pac-learning Recursive Logic Programs: Negativ...</td>\n",
       "      <td>In a companion paper it was shown that the cla...</td>\n",
       "      <td>[W. W. Cohen]</td>\n",
       "      <td>9505105v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9505105v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9505105v1</td>\n",
       "      <td>files\\9505105v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>FLECS: Planning with a Flexible Commitment Str...</td>\n",
       "      <td>There has been evidence that least-commitment ...</td>\n",
       "      <td>[M. Veloso, P. Stone]</td>\n",
       "      <td>9506101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9506101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9506101v1</td>\n",
       "      <td>files\\9506101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Induction of First-Order Decision Lists: Resul...</td>\n",
       "      <td>This paper presents a method for inducing logi...</td>\n",
       "      <td>[R. J. Mooney, M. E. Califf]</td>\n",
       "      <td>9506102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9506102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9506102v1</td>\n",
       "      <td>files\\9506102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Building and Refining Abstract Planning Cases ...</td>\n",
       "      <td>ion is one of the most promising approaches to...</td>\n",
       "      <td>[R. Bergmann, W. Wilke]</td>\n",
       "      <td>9507101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9507101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9507101v1</td>\n",
       "      <td>files\\9507101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Using Qualitative Hypotheses to Identify Inacc...</td>\n",
       "      <td>Identifying inaccurate data has long been rega...</td>\n",
       "      <td>[Q. Zhao, T. Nishida]</td>\n",
       "      <td>9508101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9508101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9508101v1</td>\n",
       "      <td>files\\9508101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>An Integrated Framework for Learning and Reaso...</td>\n",
       "      <td>Learning and reasoning are both aspects of wha...</td>\n",
       "      <td>[C. G. Giraud-Carrier, T. R. Martinez]</td>\n",
       "      <td>9508102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9508102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9508102v1</td>\n",
       "      <td>files\\9508102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Diffusion of Context and Credit Information in...</td>\n",
       "      <td>This paper studies the problem of ergodicity o...</td>\n",
       "      <td>[Y. Bengio, P. Frasconi]</td>\n",
       "      <td>9510101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9510101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9510101v1</td>\n",
       "      <td>files\\9510101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Improving Connectionist Energy Minimization</td>\n",
       "      <td>Symmetric networks designed for energy minimiz...</td>\n",
       "      <td>[G. Pinkas, R. Dechter]</td>\n",
       "      <td>9510102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9510102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9510102v1</td>\n",
       "      <td>files\\9510102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Learning Membership Functions in a Function-Ba...</td>\n",
       "      <td>Functionality-based recognition systems recogn...</td>\n",
       "      <td>[K. Woods, D. Cook, L. Hall, K. Bowyer, L. Stark]</td>\n",
       "      <td>9510103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9510103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9510103v1</td>\n",
       "      <td>files\\9510103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Flexibly Instructable Agents</td>\n",
       "      <td>This paper presents an approach to learning fr...</td>\n",
       "      <td>[S. B. Huffman, J. E. Laird]</td>\n",
       "      <td>9511101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9511101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9511101v1</td>\n",
       "      <td>files\\9511101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OPUS: An Efficient Admissible Algorithm for Un...</td>\n",
       "      <td>OPUS is a branch and bound search algorithm th...</td>\n",
       "      <td>[G. I. Webb]</td>\n",
       "      <td>9512101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512101v1</td>\n",
       "      <td>files\\9512101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Vision-Based Road Detection in Automotive Syst...</td>\n",
       "      <td>The main aim of this work is the development o...</td>\n",
       "      <td>[A. Broggi, S. Berte]</td>\n",
       "      <td>9512102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512102v1</td>\n",
       "      <td>files\\9512102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Generalization of Clauses under Implication</td>\n",
       "      <td>In the area of inductive learning, generalizat...</td>\n",
       "      <td>[P. Idestam-Almquist]</td>\n",
       "      <td>9512103v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512103v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512103v1</td>\n",
       "      <td>files\\9512103v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Decision-Theoretic Foundations for Causal Reas...</td>\n",
       "      <td>We present a definition of cause and effect in...</td>\n",
       "      <td>[D. Heckerman, R. Shachter]</td>\n",
       "      <td>9512104v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512104v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512104v1</td>\n",
       "      <td>files\\9512104v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Translating between Horn Representations and t...</td>\n",
       "      <td>Characteristic models are an alternative, mode...</td>\n",
       "      <td>[R. Khardon]</td>\n",
       "      <td>9512105v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512105v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512105v1</td>\n",
       "      <td>files\\9512105v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Statistical Feature Combination for the Evalua...</td>\n",
       "      <td>This article describes an application of three...</td>\n",
       "      <td>[M. Buro]</td>\n",
       "      <td>9512106v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512106v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512106v1</td>\n",
       "      <td>files\\9512106v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rule-based Machine Learning Methods for Functi...</td>\n",
       "      <td>We describe a machine learning method for pred...</td>\n",
       "      <td>[S. M. Weiss, N. Indurkhya]</td>\n",
       "      <td>9512107v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9512107v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9512107v1</td>\n",
       "      <td>files\\9512107v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The Design and Experimental Analysis of Algori...</td>\n",
       "      <td>Many applications -- from planning and schedul...</td>\n",
       "      <td>[P. vanBeek, D. W. Manchak]</td>\n",
       "      <td>9601101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9601101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9601101v1</td>\n",
       "      <td>files\\9601101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Well-Founded Semantics for Extended Logic Prog...</td>\n",
       "      <td>The paper describes an extension of well-found...</td>\n",
       "      <td>[G. Brewka]</td>\n",
       "      <td>9602101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9602101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9602101v1</td>\n",
       "      <td>files\\9602101v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logarithmic-Time Updates and Queries in Probab...</td>\n",
       "      <td>Traditional databases commonly support efficie...</td>\n",
       "      <td>[A. L. Delcher, A. J. Grove, S. Kasif, J. Pearl]</td>\n",
       "      <td>9602102v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9602102v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9602102v1</td>\n",
       "      <td>files\\9602102v1.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Quantum Computing and Phase Transitions in Com...</td>\n",
       "      <td>We introduce an algorithm for combinatorial se...</td>\n",
       "      <td>[T. Hogg]</td>\n",
       "      <td>9603101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9603101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9603101v1</td>\n",
       "      <td>files\\9603101v1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                Dynamic Backtracking   \n",
       "1   A Market-Oriented Programming Environment and ...   \n",
       "2             An Empirical Analysis of Search in GSAT   \n",
       "3   The Difficulties of Learning Logic Programs wi...   \n",
       "4   Software Agents: Completing Patterns and Const...   \n",
       "5   Decidable Reasoning in Terminological Knowledg...   \n",
       "6           Teleo-Reactive Programs for Agent Control   \n",
       "7   Learning the Past Tense of English Verbs: The ...   \n",
       "8   Substructure Discovery Using Minimum Descripti...   \n",
       "9     Bias-Driven Revision of Logical Domain Theories   \n",
       "10  Exploring the Decision Forest: An Empirical In...   \n",
       "11  A Semantics and Complete Algorithm for Subsump...   \n",
       "12              Applying GSAT to Non-Clausal Formulas   \n",
       "13                  Random Worlds and Maximum Entropy   \n",
       "14  Pattern Matching and Discourse Processing in I...   \n",
       "15   A System for Induction of Oblique Decision Trees   \n",
       "16                         On Planning while Learning   \n",
       "17  Wrap-Up: a Trainable Discourse Module for Info...   \n",
       "18      Operations for Learning with Graphical Models   \n",
       "19  Total-Order and Partial-Order Planning: A Comp...   \n",
       "20  Solving Multiclass Learning Problems via Error...   \n",
       "21  A Domain-Independent Algorithm for Plan Adapta...   \n",
       "22  Truncating Temporal Differences: On the Effici...   \n",
       "23  Cost-Sensitive Classification: Empirical Evalu...   \n",
       "24  Rerepresenting and Restructuring Domain Theori...   \n",
       "25  Using Pivot Consistency to Decompose and Solve...   \n",
       "26  Adaptive Load Balancing: A Study in Multi-Agen...   \n",
       "27                    Provably Bounded-Optimal Agents   \n",
       "28  Pac-Learning Recursive Logic Programs: Efficie...   \n",
       "29  Pac-learning Recursive Logic Programs: Negativ...   \n",
       "30  FLECS: Planning with a Flexible Commitment Str...   \n",
       "31  Induction of First-Order Decision Lists: Resul...   \n",
       "32  Building and Refining Abstract Planning Cases ...   \n",
       "33  Using Qualitative Hypotheses to Identify Inacc...   \n",
       "34  An Integrated Framework for Learning and Reaso...   \n",
       "35  Diffusion of Context and Credit Information in...   \n",
       "36        Improving Connectionist Energy Minimization   \n",
       "37  Learning Membership Functions in a Function-Ba...   \n",
       "38                       Flexibly Instructable Agents   \n",
       "39  OPUS: An Efficient Admissible Algorithm for Un...   \n",
       "40  Vision-Based Road Detection in Automotive Syst...   \n",
       "41        Generalization of Clauses under Implication   \n",
       "42  Decision-Theoretic Foundations for Causal Reas...   \n",
       "43  Translating between Horn Representations and t...   \n",
       "44  Statistical Feature Combination for the Evalua...   \n",
       "45  Rule-based Machine Learning Methods for Functi...   \n",
       "46  The Design and Experimental Analysis of Algori...   \n",
       "47  Well-Founded Semantics for Extended Logic Prog...   \n",
       "48  Logarithmic-Time Updates and Queries in Probab...   \n",
       "49  Quantum Computing and Phase Transitions in Com...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Because of their occasional need to return to ...   \n",
       "1   Market price systems constitute a well-underst...   \n",
       "2   We describe an extensive study of search in GS...   \n",
       "3   As real logic programmers normally use cut (!)...   \n",
       "4   To support the goal of allowing users to recor...   \n",
       "5   Terminological knowledge representation system...   \n",
       "6   A formalism is presented for computing and org...   \n",
       "7   Learning the past tense of English verbs - a s...   \n",
       "8   The ability to identify interesting and repeti...   \n",
       "9   The theory revision problem is the problem of ...   \n",
       "10  We report on a series of experiments in which ...   \n",
       "11  This paper analyzes the correctness of the sub...   \n",
       "12  In this paper we describe how to modify GSAT s...   \n",
       "13  Given a knowledge base KB containing first-ord...   \n",
       "14  Information extraction is the task of automati...   \n",
       "15  This article describes a new system for induct...   \n",
       "16  This paper introduces a framework for Planning...   \n",
       "17  The vast amounts of on-line text now available...   \n",
       "18  This paper is a multidisciplinary review of em...   \n",
       "19  For many years, the intuitions underlying part...   \n",
       "20  Multiclass learning problems involve finding a...   \n",
       "21  The paradigms of transformational planning, ca...   \n",
       "22  Temporal difference (TD) methods constitute a ...   \n",
       "23  This paper introduces ICET, a new algorithm fo...   \n",
       "24  Theory revision integrates inductive learning ...   \n",
       "25  Many studies have been carried out in order to...   \n",
       "26  We study the process of multi-agent reinforcem...   \n",
       "27  Since its inception, artificial intelligence h...   \n",
       "28  We present algorithms that learn certain class...   \n",
       "29  In a companion paper it was shown that the cla...   \n",
       "30  There has been evidence that least-commitment ...   \n",
       "31  This paper presents a method for inducing logi...   \n",
       "32  ion is one of the most promising approaches to...   \n",
       "33  Identifying inaccurate data has long been rega...   \n",
       "34  Learning and reasoning are both aspects of wha...   \n",
       "35  This paper studies the problem of ergodicity o...   \n",
       "36  Symmetric networks designed for energy minimiz...   \n",
       "37  Functionality-based recognition systems recogn...   \n",
       "38  This paper presents an approach to learning fr...   \n",
       "39  OPUS is a branch and bound search algorithm th...   \n",
       "40  The main aim of this work is the development o...   \n",
       "41  In the area of inductive learning, generalizat...   \n",
       "42  We present a definition of cause and effect in...   \n",
       "43  Characteristic models are an alternative, mode...   \n",
       "44  This article describes an application of three...   \n",
       "45  We describe a machine learning method for pred...   \n",
       "46  Many applications -- from planning and schedul...   \n",
       "47  The paper describes an extension of well-found...   \n",
       "48  Traditional databases commonly support efficie...   \n",
       "49  We introduce an algorithm for combinatorial se...   \n",
       "\n",
       "                                              authors   arxiv_id  \\\n",
       "0                                    [M. L. Ginsberg]  9308101v1   \n",
       "1                                     [M. P. Wellman]  9308102v1   \n",
       "2                              [I. P. Gent, T. Walsh]  9309101v1   \n",
       "3            [F. Bergadano, D. Gunetti, U. Trinchero]  9311101v1   \n",
       "4                    [J. C. Schlimmer, L. A. Hermens]  9311102v1   \n",
       "5             [M. Buchheit, F. M. Donini, A. Schaerf]  9312101v1   \n",
       "6                                        [N. Nilsson]  9401101v1   \n",
       "7                                        [C. X. Ling]  9402101v1   \n",
       "8                          [D. J. Cook, L. B. Holder]  9402102v1   \n",
       "9                [M. Koppel, R. Feldman, A. M. Segre]  9402103v1   \n",
       "10                      [P. M. Murphy, M. J. Pazzani]  9403101v1   \n",
       "11                [A. Borgida, P. F. Patel-Schneider]  9406101v1   \n",
       "12                                    [R. Sebastiani]  9406102v1   \n",
       "13            [A. J. Grove, J. Y. Halpern, D. Koller]  9408101v1   \n",
       "14                  [T. Kitani, Y. Eriguchi, M. Hara]  9408102v1   \n",
       "15              [S. K. Murthy, S. Kasif, S. Salzberg]  9408103v1   \n",
       "16                         [S. Safra, M. Tennenholtz]  9409101v1   \n",
       "17                         [S. Soderland, Lehnert. W]  9412101v1   \n",
       "18                                    [W. L. Buntine]  9412102v1   \n",
       "19               [S. Minton, J. Bresina, M. Drummond]  9412103v1   \n",
       "20                      [T. G. Dietterich, G. Bakiri]  9501101v1   \n",
       "21                             [S. Hanks, D. S. Weld]  9501102v1   \n",
       "22                                       [P. Cichosz]  9501103v1   \n",
       "23                                     [P. D. Turney]  9503102v1   \n",
       "24                      [S. K. Donoho, L. A. Rendell]  9504101v1   \n",
       "25                                         [P. David]  9505101v1   \n",
       "26            [A. Schaerf, Y. Shoham, M. Tennenholtz]  9505102v1   \n",
       "27                    [S. J. Russell, D. Subramanian]  9505103v1   \n",
       "28                                      [W. W. Cohen]  9505104v1   \n",
       "29                                      [W. W. Cohen]  9505105v1   \n",
       "30                              [M. Veloso, P. Stone]  9506101v1   \n",
       "31                       [R. J. Mooney, M. E. Califf]  9506102v1   \n",
       "32                            [R. Bergmann, W. Wilke]  9507101v1   \n",
       "33                              [Q. Zhao, T. Nishida]  9508101v1   \n",
       "34             [C. G. Giraud-Carrier, T. R. Martinez]  9508102v1   \n",
       "35                           [Y. Bengio, P. Frasconi]  9510101v1   \n",
       "36                            [G. Pinkas, R. Dechter]  9510102v1   \n",
       "37  [K. Woods, D. Cook, L. Hall, K. Bowyer, L. Stark]  9510103v1   \n",
       "38                       [S. B. Huffman, J. E. Laird]  9511101v1   \n",
       "39                                       [G. I. Webb]  9512101v1   \n",
       "40                              [A. Broggi, S. Berte]  9512102v1   \n",
       "41                              [P. Idestam-Almquist]  9512103v1   \n",
       "42                        [D. Heckerman, R. Shachter]  9512104v1   \n",
       "43                                       [R. Khardon]  9512105v1   \n",
       "44                                          [M. Buro]  9512106v1   \n",
       "45                        [S. M. Weiss, N. Indurkhya]  9512107v1   \n",
       "46                        [P. vanBeek, D. W. Manchak]  9601101v1   \n",
       "47                                        [G. Brewka]  9602101v1   \n",
       "48   [A. L. Delcher, A. J. Grove, S. Kasif, J. Pearl]  9602102v1   \n",
       "49                                          [T. Hogg]  9603101v1   \n",
       "\n",
       "                                  url                           pdf_link  \\\n",
       "0   http://arxiv.org/abs/cs/9308101v1  http://arxiv.org/pdf/cs/9308101v1   \n",
       "1   http://arxiv.org/abs/cs/9308102v1  http://arxiv.org/pdf/cs/9308102v1   \n",
       "2   http://arxiv.org/abs/cs/9309101v1  http://arxiv.org/pdf/cs/9309101v1   \n",
       "3   http://arxiv.org/abs/cs/9311101v1  http://arxiv.org/pdf/cs/9311101v1   \n",
       "4   http://arxiv.org/abs/cs/9311102v1  http://arxiv.org/pdf/cs/9311102v1   \n",
       "5   http://arxiv.org/abs/cs/9312101v1  http://arxiv.org/pdf/cs/9312101v1   \n",
       "6   http://arxiv.org/abs/cs/9401101v1  http://arxiv.org/pdf/cs/9401101v1   \n",
       "7   http://arxiv.org/abs/cs/9402101v1  http://arxiv.org/pdf/cs/9402101v1   \n",
       "8   http://arxiv.org/abs/cs/9402102v1  http://arxiv.org/pdf/cs/9402102v1   \n",
       "9   http://arxiv.org/abs/cs/9402103v1  http://arxiv.org/pdf/cs/9402103v1   \n",
       "10  http://arxiv.org/abs/cs/9403101v1  http://arxiv.org/pdf/cs/9403101v1   \n",
       "11  http://arxiv.org/abs/cs/9406101v1  http://arxiv.org/pdf/cs/9406101v1   \n",
       "12  http://arxiv.org/abs/cs/9406102v1  http://arxiv.org/pdf/cs/9406102v1   \n",
       "13  http://arxiv.org/abs/cs/9408101v1  http://arxiv.org/pdf/cs/9408101v1   \n",
       "14  http://arxiv.org/abs/cs/9408102v1  http://arxiv.org/pdf/cs/9408102v1   \n",
       "15  http://arxiv.org/abs/cs/9408103v1  http://arxiv.org/pdf/cs/9408103v1   \n",
       "16  http://arxiv.org/abs/cs/9409101v1  http://arxiv.org/pdf/cs/9409101v1   \n",
       "17  http://arxiv.org/abs/cs/9412101v1  http://arxiv.org/pdf/cs/9412101v1   \n",
       "18  http://arxiv.org/abs/cs/9412102v1  http://arxiv.org/pdf/cs/9412102v1   \n",
       "19  http://arxiv.org/abs/cs/9412103v1  http://arxiv.org/pdf/cs/9412103v1   \n",
       "20  http://arxiv.org/abs/cs/9501101v1  http://arxiv.org/pdf/cs/9501101v1   \n",
       "21  http://arxiv.org/abs/cs/9501102v1  http://arxiv.org/pdf/cs/9501102v1   \n",
       "22  http://arxiv.org/abs/cs/9501103v1  http://arxiv.org/pdf/cs/9501103v1   \n",
       "23  http://arxiv.org/abs/cs/9503102v1  http://arxiv.org/pdf/cs/9503102v1   \n",
       "24  http://arxiv.org/abs/cs/9504101v1  http://arxiv.org/pdf/cs/9504101v1   \n",
       "25  http://arxiv.org/abs/cs/9505101v1  http://arxiv.org/pdf/cs/9505101v1   \n",
       "26  http://arxiv.org/abs/cs/9505102v1  http://arxiv.org/pdf/cs/9505102v1   \n",
       "27  http://arxiv.org/abs/cs/9505103v1  http://arxiv.org/pdf/cs/9505103v1   \n",
       "28  http://arxiv.org/abs/cs/9505104v1  http://arxiv.org/pdf/cs/9505104v1   \n",
       "29  http://arxiv.org/abs/cs/9505105v1  http://arxiv.org/pdf/cs/9505105v1   \n",
       "30  http://arxiv.org/abs/cs/9506101v1  http://arxiv.org/pdf/cs/9506101v1   \n",
       "31  http://arxiv.org/abs/cs/9506102v1  http://arxiv.org/pdf/cs/9506102v1   \n",
       "32  http://arxiv.org/abs/cs/9507101v1  http://arxiv.org/pdf/cs/9507101v1   \n",
       "33  http://arxiv.org/abs/cs/9508101v1  http://arxiv.org/pdf/cs/9508101v1   \n",
       "34  http://arxiv.org/abs/cs/9508102v1  http://arxiv.org/pdf/cs/9508102v1   \n",
       "35  http://arxiv.org/abs/cs/9510101v1  http://arxiv.org/pdf/cs/9510101v1   \n",
       "36  http://arxiv.org/abs/cs/9510102v1  http://arxiv.org/pdf/cs/9510102v1   \n",
       "37  http://arxiv.org/abs/cs/9510103v1  http://arxiv.org/pdf/cs/9510103v1   \n",
       "38  http://arxiv.org/abs/cs/9511101v1  http://arxiv.org/pdf/cs/9511101v1   \n",
       "39  http://arxiv.org/abs/cs/9512101v1  http://arxiv.org/pdf/cs/9512101v1   \n",
       "40  http://arxiv.org/abs/cs/9512102v1  http://arxiv.org/pdf/cs/9512102v1   \n",
       "41  http://arxiv.org/abs/cs/9512103v1  http://arxiv.org/pdf/cs/9512103v1   \n",
       "42  http://arxiv.org/abs/cs/9512104v1  http://arxiv.org/pdf/cs/9512104v1   \n",
       "43  http://arxiv.org/abs/cs/9512105v1  http://arxiv.org/pdf/cs/9512105v1   \n",
       "44  http://arxiv.org/abs/cs/9512106v1  http://arxiv.org/pdf/cs/9512106v1   \n",
       "45  http://arxiv.org/abs/cs/9512107v1  http://arxiv.org/pdf/cs/9512107v1   \n",
       "46  http://arxiv.org/abs/cs/9601101v1  http://arxiv.org/pdf/cs/9601101v1   \n",
       "47  http://arxiv.org/abs/cs/9602101v1  http://arxiv.org/pdf/cs/9602101v1   \n",
       "48  http://arxiv.org/abs/cs/9602102v1  http://arxiv.org/pdf/cs/9602102v1   \n",
       "49  http://arxiv.org/abs/cs/9603101v1  http://arxiv.org/pdf/cs/9603101v1   \n",
       "\n",
       "          pdf_file_name  \n",
       "0   files\\9308101v1.pdf  \n",
       "1   files\\9308102v1.pdf  \n",
       "2   files\\9309101v1.pdf  \n",
       "3   files\\9311101v1.pdf  \n",
       "4   files\\9311102v1.pdf  \n",
       "5   files\\9312101v1.pdf  \n",
       "6   files\\9401101v1.pdf  \n",
       "7   files\\9402101v1.pdf  \n",
       "8   files\\9402102v1.pdf  \n",
       "9   files\\9402103v1.pdf  \n",
       "10  files\\9403101v1.pdf  \n",
       "11  files\\9406101v1.pdf  \n",
       "12  files\\9406102v1.pdf  \n",
       "13  files\\9408101v1.pdf  \n",
       "14  files\\9408102v1.pdf  \n",
       "15  files\\9408103v1.pdf  \n",
       "16  files\\9409101v1.pdf  \n",
       "17  files\\9412101v1.pdf  \n",
       "18  files\\9412102v1.pdf  \n",
       "19  files\\9412103v1.pdf  \n",
       "20  files\\9501101v1.pdf  \n",
       "21  files\\9501102v1.pdf  \n",
       "22  files\\9501103v1.pdf  \n",
       "23  files\\9503102v1.pdf  \n",
       "24  files\\9504101v1.pdf  \n",
       "25  files\\9505101v1.pdf  \n",
       "26  files\\9505102v1.pdf  \n",
       "27  files\\9505103v1.pdf  \n",
       "28  files\\9505104v1.pdf  \n",
       "29  files\\9505105v1.pdf  \n",
       "30  files\\9506101v1.pdf  \n",
       "31  files\\9506102v1.pdf  \n",
       "32  files\\9507101v1.pdf  \n",
       "33  files\\9508101v1.pdf  \n",
       "34  files\\9508102v1.pdf  \n",
       "35  files\\9510101v1.pdf  \n",
       "36  files\\9510102v1.pdf  \n",
       "37  files\\9510103v1.pdf  \n",
       "38  files\\9511101v1.pdf  \n",
       "39  files\\9512101v1.pdf  \n",
       "40  files\\9512102v1.pdf  \n",
       "41  files\\9512103v1.pdf  \n",
       "42  files\\9512104v1.pdf  \n",
       "43  files\\9512105v1.pdf  \n",
       "44  files\\9512106v1.pdf  \n",
       "45  files\\9512107v1.pdf  \n",
       "46  files\\9601101v1.pdf  \n",
       "47  files\\9602101v1.pdf  \n",
       "48  files\\9602102v1.pdf  \n",
       "49  files\\9603101v1.pdf  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def download_pdfs(df, download_folder='files'):\n",
    "    '''\n",
    "    Download PDF from df and save it in local folder\n",
    "    '''\n",
    "    if not os.path.exists(download_folder):\n",
    "        os.makedirs(download_folder)\n",
    "    \n",
    "    pdf_file_names = [] ## empty list for storing pdf file names\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        pdf_link = row['pdf_link']\n",
    "\n",
    "        try:\n",
    "            response = requests.get(pdf_link)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            file_name = os.path.join(download_folder, pdf_link.split('/')[-1]) + '.pdf'\n",
    "            pdf_file_names.append(file_name)\n",
    "\n",
    "            # Save the downloaded PDF\n",
    "            # with open(file_name, 'wb') as f:\n",
    "            #     f.write(response.content)\n",
    "            \n",
    "            #print(f'PDF downloaded successfully and saved as {file_name}')\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f'Failed to download the PDF: {e}')\n",
    "            pdf_file_names.append(None)\n",
    "    \n",
    "    df['pdf_file_name'] = pdf_file_names\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "        \n",
    "download_pdfs(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8dd19",
   "metadata": {},
   "source": [
    "## 3.Splitting pdf into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe273ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "def load_pdf_chunks(file_path):\n",
    "    '''Load pdf file and chunk it'''\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    data= loader.load()\n",
    "    \n",
    "    # Initialize the RecursiveCharacterTextSplitter\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=512,  # Maximum size of each chunk\n",
    "        chunk_overlap=50  # Overlap between chunks\n",
    "    )\n",
    "\n",
    "    # Split the text\n",
    "    chunks = splitter.split_documents(data)\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e8ec6",
   "metadata": {},
   "source": [
    "### expand DF and append chunk in current DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8a2a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>authors</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>url</th>\n",
       "      <th>pdf_link</th>\n",
       "      <th>pdf_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dynamic Backtracking</td>\n",
       "      <td>Because of their occasional need to return to ...</td>\n",
       "      <td>[M. L. Ginsberg]</td>\n",
       "      <td>9308101v1</td>\n",
       "      <td>http://arxiv.org/abs/cs/9308101v1</td>\n",
       "      <td>http://arxiv.org/pdf/cs/9308101v1</td>\n",
       "      <td>files\\9308101v1.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                            summary  \\\n",
       "0  Dynamic Backtracking  Because of their occasional need to return to ...   \n",
       "\n",
       "            authors   arxiv_id                                url  \\\n",
       "0  [M. L. Ginsberg]  9308101v1  http://arxiv.org/abs/cs/9308101v1   \n",
       "\n",
       "                            pdf_link        pdf_file_name  \n",
       "0  http://arxiv.org/pdf/cs/9308101v1  files\\9308101v1.pdf  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddba2aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            50\n",
       "summary          50\n",
       "authors          50\n",
       "arxiv_id         50\n",
       "url              50\n",
       "pdf_link         50\n",
       "pdf_file_name    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba42e1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_df(df):\n",
    "    '''Expand DF to chunks\n",
    "    return New expanded df\n",
    "    '''\n",
    "\n",
    "    expanded_row = []\n",
    "\n",
    "    ## loop through each row in DF\n",
    "    for index,row in df.iterrows():\n",
    "        file_name = row['pdf_file_name']\n",
    "        #print(row)\n",
    "        try:\n",
    "            chunks = load_pdf_chunks(file_name)\n",
    "        except:\n",
    "            print(f'PDF file not found for {index} row with filename - {file_name}')\n",
    "            continue\n",
    "\n",
    "        #loop over the chunks and add it to new data frame\n",
    "        #print(f'Adding {len(chunks)} chunks for {index} row')\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            prechunk = i-1 if i > 0 else '' # Preceding chunk ID\n",
    "            postchunk = i+1 if i < len(chunks) -1 else '' # Following chunk ID\n",
    "\n",
    "            expanded_row.append(\n",
    "                {\n",
    "                    'id':\"{}#{}\".format(row['arxiv_id'],i),\n",
    "                    'title':row['title'],\n",
    "                    'summary':row['summary'],\n",
    "                    'authors':row['authors'],\n",
    "                    'arxiv_id':row['arxiv_id'],\n",
    "                    'url':row['url'],\n",
    "                    'chunk':chunk.page_content,\n",
    "                    'prechunk_id': '' if i == 0 else \"{}#{}\".format(row['arxiv_id'],prechunk),\n",
    "                    'postchunk_id': '' if i == len(chunks) -1 else \"{}#{}\".format(row['arxiv_id'],postchunk)\n",
    "\n",
    "\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(expanded_row)        \n",
    "\n",
    "\n",
    "\n",
    "#expand_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efef7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_df = expand_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef466a58",
   "metadata": {},
   "source": [
    "## 4.Create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85995dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from semantic_router.encoders import OpenAIEncoder\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "res = load_dotenv(dotenv_path=\"../ML_practice/cred.env\")\n",
    "\n",
    "print(res)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# for model in client.models.list():\n",
    "#     print(model.id)\n",
    "\n",
    "encoder = OpenAIEncoder(name='text-embedding-3-small')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a42af2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = encoder('hello namaste')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69076507",
   "metadata": {},
   "source": [
    "### create pinecone index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270acb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone,ServerlessSpec\n",
    "\n",
    "load_dotenv(dotenv_path=\"../ML_practice/cred.env\")\n",
    "\n",
    "PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "##define serveless specification\n",
    "spec = ServerlessSpec(\n",
    "        cloud='aws',\n",
    "        region='us-east-1'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93c58db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['askdoc', 'askwiki', 'langgraph-research-agent']\n"
     ]
    }
   ],
   "source": [
    "print(pc.list_indexes().names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641eef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index langgraph-research-agent already exists\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "index_name = 'langgraph-research-agent'\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "\n",
    "    index = pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension = 1536,\n",
    "        metric='cosine',\n",
    "        spec = spec\n",
    "    )\n",
    "\n",
    "    print(f'Index {index_name} Created')\n",
    "else:\n",
    "    print(f'Index {index_name} already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0477833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##get to index in variable\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd22dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "langgraph-research-agent\n"
     ]
    }
   ],
   "source": [
    "print(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c4e1761",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f603e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = pc.list_indexes().names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebc2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['askdoc', 'askwiki', 'langgraph-research-agent']\n"
     ]
    }
   ],
   "source": [
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf0fb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'': {'vector_count': 12276}},\n",
      " 'total_vector_count': 12276,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "print(index.describe_index_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "208deb43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expanded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m expanded_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'expanded_df' is not defined"
     ]
    }
   ],
   "source": [
    "expanded_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a15989c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'expanded_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m         sample\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mid\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m: vec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: meta})\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(sample)\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m data \u001b[38;5;241m=\u001b[39m expanded_df\n\u001b[0;32m     19\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;66;03m##12276\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'expanded_df' is not defined"
     ]
    }
   ],
   "source": [
    "## Now from expanded_df, get chunks and upsert into pinecone index\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def approx_payload_size_bytes(batch_tuples):\n",
    "    \"\"\"\n",
    "    Approximate JSON-serialized size of the upsert payload.\n",
    "    This is conservative but good for dynamic batching.\n",
    "    \"\"\"\n",
    "    # Represent as list of dicts similar to Pinecone upsert format\n",
    "    sample = []\n",
    "    for id, vec, meta in batch_tuples:\n",
    "        sample.append({\"id\": id, \"values\": vec, \"metadata\": meta})\n",
    "    return len(json.dumps(sample).encode('utf-8'))/(1024 * 1024)\n",
    "\n",
    "\n",
    "\n",
    "data = expanded_df\n",
    "batch_size = 64\n",
    "\n",
    "len(data) ##12276\n",
    "\n",
    "\n",
    "\n",
    "##loop through data in batches in data and upsert into index\n",
    "\n",
    "for i in tqdm(range(0,len(data),batch_size)):\n",
    "    print(\"iteration:\",i)\n",
    "    i_end = min(len(data),i+batch_size) ##end point\n",
    "\n",
    "    #print(\"i_end:\",i_end)\n",
    "\n",
    "    batch = data[i:i_end].to_dict(orient='records')\n",
    "\n",
    "    #print(\"len(batch):\",len(batch))\n",
    "\n",
    "    ##get metadata and ID for each chunk in batch\n",
    "\n",
    "    metadata= [{'arxiv_id':r['arxiv_id'],'title':r['title'],'chunk':r['chunk']} for r in batch]\n",
    "\n",
    "    ids = [r['id'] for r in batch]\n",
    "\n",
    "    chunks = [r['chunk'] for r in batch]\n",
    "\n",
    "    print(\"len(chunks) sample:\",len(chunks))\n",
    "    \n",
    "    embeds = encoder(chunks)## openai encoder function isntead of tiktoken\n",
    "\n",
    "\n",
    "\n",
    "    batch_tuple = [(ids[j],embeds[j],metadata[j]) for j in range(len(ids))]\n",
    "\n",
    "    #print(\"Current batch size:\", len(batch_tuple))\n",
    "    #print(\"First 3 chunk types:\", [type(c) for c in chunks[:3]])\n",
    "    #print(\"Any None in chunks?:\", any(c is None for c in chunks))\n",
    "\n",
    "    payload_size = approx_payload_size_bytes(batch_tuple)\n",
    "    print(f'Payload size: {payload_size} MBs')\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    ##upload embeddings , ids and metadata\n",
    "    index.upsert(vectors=zip(ids,embeds,metadata))\n",
    "\n",
    "    print(f'--'*20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ede74f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'metric': 'cosine',\n",
       " 'namespaces': {'': {'vector_count': 12276}},\n",
       " 'total_vector_count': 12276,\n",
       " 'vector_type': 'dense'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c825fc",
   "metadata": {},
   "source": [
    "## 5.Fetch tool\n",
    "Fetch tool uses regular expression for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12923d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<head>  <title>[1706.03762] Attention Is All You Need</title>\n",
      "  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "  <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/static/browse/0.3.4/images/icons/apple-touch-icon.png\">\n",
      "  <link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/static/browse/0.3.4/images/icons/favicon-32x32.png\">\n",
      "  <link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/static/browse/0.3.4/images/icons/favicon-16x16.png\">\n",
      "  <link rel=\"manifest\" href=\"/static/browse/0.3.4/images/icons/site.webmanifest\">\n",
      "  <link rel=\"mask-icon\" href=\"/static/browse/0.3.4/images/icons/safari-pinned-tab.svg\" color=\"#5bbad5\">\n",
      "  <meta name=\"msapplication-TileColor\" content=\"#da532c\">\n",
      "  <meta name=\"theme-color\" content=\"#ffffff\">\n",
      "  <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/static/browse/0.3.4/css/arXiv.css?v=20241206\" />\n",
      "  <link rel=\"stylesheet\" type=\"text/css\" media=\"print\" href=\"/static/browse/0.3.4/css/arXiv-print.css?v=20200611\" />\n",
      "  <link rel=\"stylesheet\" type=\"text/css\" media=\"screen\" href=\"/static/browse/0.3.4/css/browse_search.css\" />\n",
      "  <script language=\"javascript\" src=\"/static/browse/0.3.4/js/accordion.js\" ></script>\n",
      "  <script language=\"javascript\" src=\"/static/browse/0.3.4/js/optin-modal.js?v=20250819\"></script>\n",
      "  \n",
      "  <link rel=\"canonical\" href=\"https://arxiv.org/abs/1706.03762\"/>\n",
      "  <meta name=\"description\" content=\"Abstract page for arXiv paper 1706.03762: Attention Is All You Need\"><meta property=\"og:type\" content=\"website\" />\n",
      "<meta property=\"og:site_name\" content=\"arXiv.org\" />\n",
      "<meta property=\"og:title\" content=\"Attention Is All You Need\" />\n",
      "<meta property=\"og:url\" content=\"https://arxiv.org/abs/1706.03762v7\" />\n",
      "<meta property=\"og:image\" content=\"/static/browse/0.3.4/images/arxiv-logo-fb.png\" />\n",
      "<meta property=\"og:image:secure_url\" content=\"/static/browse/0.3.4/images/arxiv-logo-fb.png\" />\n",
      "<meta property=\"og:image:width\" content=\"1200\" />\n",
      "<meta property=\"og:image:height\" content=\"700\" />\n",
      "<meta property=\"og:image:alt\" content=\"arXiv logo\"/>\n",
      "<meta property=\"og:description\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\"/>\n",
      "<meta name=\"twitter:site\" content=\"@arxiv\"/>\n",
      "<meta name=\"twitter:card\" content=\"summary\"/>\n",
      "<meta name=\"twitter:title\" content=\"Attention Is All You Need\"/>\n",
      "<meta name=\"twitter:description\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder...\"/>\n",
      "<meta name=\"twitter:image\" content=\"https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png\"/>\n",
      "<meta name=\"twitter:image:alt\" content=\"arXiv logo\"/>\n",
      "  <link rel=\"stylesheet\" media=\"screen\" type=\"text/css\" href=\"/static/browse/0.3.4/css/tooltip.css\"/><link rel=\"stylesheet\" media=\"screen\" type=\"text/css\" href=\"https://static.arxiv.org/js/bibex-dev/bibex.css?20200709\"/>  <script src=\"/static/browse/0.3.4/js/mathjaxToggle.min.js\" type=\"text/javascript\"></script>  <script src=\"//code.jquery.com/jquery-latest.min.js\" type=\"text/javascript\"></script>\n",
      "  <script src=\"//cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js\" type=\"text/javascript\"></script>\n",
      "  <script src=\"//cdn.jsdelivr.net/npm/dompurify@2.3.5/dist/purify.min.js\"></script>\n",
      "  <script src=\"/static/browse/0.3.4/js/toggle-labs.js?20241022\" type=\"text/javascript\"></script>\n",
      "  <script src=\"/static/browse/0.3.4/js/cite.js\" type=\"text/javascript\"></script><meta name=\"citation_title\" content=\"Attention Is All You Need\" /><meta name=\"citation_author\" content=\"Vaswani, Ashish\" /><meta name=\"citation_author\" content=\"Shazeer, Noam\" /><meta name=\"citation_author\" content=\"Parmar, Niki\" /><meta name=\"citation_author\" content=\"Uszkoreit, Jakob\" /><meta name=\"citation_author\" content=\"Jones, Llion\" /><meta name=\"citation_author\" content=\"Gomez, Aidan N.\" /><meta name=\"citation_author\" content=\"Kaiser, Lukasz\" /><meta name=\"citation_author\" content=\"Polosukhin, Illia\" /><meta name=\"citation_date\" content=\"2017/06/12\" /><meta name=\"citation_online_date\" content=\"2023/08/02\" /><meta name=\"citation_pdf_url\" content=\"https://arxiv.org/pdf/1706.03762\" /><meta name=\"citation_arxiv_id\" content=\"1706.03762\" /><meta name=\"citation_abstract\" content=\"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\" />\n",
      "</head>\n",
      "\n",
      "<body  class=\"with-cu-identity\">\n",
      "  \n",
      "  \n",
      "  <div class=\"flex-wrap-footer\">\n",
      "    <header>\n",
      "      <a href=\"#content\" class=\"is-sr-only\">Skip to main content</a>\n",
      "      <!-- start desktop header -->\n",
      "      <div class=\"columns is-vcentered is-hidden-mobile\" id=\"cu-identity\">\n",
      "        <div class=\"column\" id=\"cu-logo\">\n",
      "          <a href=\"https://www.cornell.edu/\"><img src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University\" /></a>\n",
      "        </div><!-- /from April 7 at 1:00 AM to May 29 at 21:40 --><!-- /from May 2 at 1:00 AM to May 5 at 9:45 AM --><div class=\"column\" id=\"support-ack\">\n",
      "          <span id=\"support-ack-url\">We gratefully acknowledge support from the Simons Foundation, <a href=\"https://info.arxiv.org/about/ourmembers.html\">member institutions</a>, and all contributors.</span>\n",
      "          <a href=\"https://info.arxiv.org/about/donate.html\" class=\"btn-header-donate\">Donate</a>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "      <div id=\"header\" class=\"is-hidden-mobile\">\n",
      "<a aria-hidden=\"true\" tabindex=\"-1\" href=\"/IgnoreMe\"></a>\n",
      "  <div class=\"header-breadcrumbs is-hidden-mobile\">\n",
      "    <a href=\"/\"><img src=\"/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg\" alt=\"arxiv logo\" style=\"height:40px;\"/></a> <span>&gt;</span> <a href=\"/list/cs/recent\">cs</a> <span>&gt;</span> arXiv:1706.03762\n",
      "  </div>\n",
      "\n",
      "        <div class=\"columns is-vcentered is-mobile\" style=\"justify-content: flex-end;\">\n",
      "        </div>\n",
      "\n",
      "          <div class=\"search-block level-right\">\n",
      "    <form class=\"level-item mini-search\" method=\"GET\" action=\"https://arxiv.org/search\">\n",
      "      <div class=\"field has-addons\">\n",
      "        <div class=\"control\">\n",
      "          <input class=\"input is-small\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\n",
      "          <p class=\"help\"><a href=\"https://info.arxiv.org/help\">Help</a> | <a href=\"https://arxiv.org/search/advanced\">Advanced Search</a></p>\n",
      "        </div>\n",
      "        <div class=\"control\">\n",
      "          <div class=\"select is-small\">\n",
      "            <select name=\"searchtype\" aria-label=\"Field to search\">\n",
      "              <option value=\"all\" selected=\"selected\">All fields</option>\n",
      "              <option value=\"title\">Title</option>\n",
      "              <option value=\"author\">Author</option>\n",
      "              <option value=\"abstract\">Abstract</option>\n",
      "              <option value=\"comments\">Comments</option>\n",
      "              <option value=\"journal_ref\">Journal reference</option>\n",
      "              <option value=\"acm_class\">ACM classification</option>\n",
      "              <option value=\"msc_class\">MSC classification</option>\n",
      "              <option value=\"report_num\">Report number</option>\n",
      "              <option value=\"paper_id\">arXiv identifier</option>\n",
      "              <option value=\"doi\">DOI</option>\n",
      "              <option value=\"orcid\">ORCID</option>\n",
      "              <option value=\"author_id\">arXiv author ID</option>\n",
      "              <option value=\"help\">Help pages</option>\n",
      "              <option value=\"full_text\">Full text</option>\n",
      "            </select>\n",
      "          </div>\n",
      "        </div>\n",
      "        <input type=\"hidden\" name=\"source\" value=\"header\">\n",
      "        <button class=\"button is-small is-cul-darker\">Search</button>\n",
      "      </div>\n",
      "    </form>\n",
      "  </div>\n",
      "     </div><!-- /end desktop header -->\n",
      "\n",
      "      <div class=\"mobile-header\">\n",
      "        <div class=\"columns is-mobile\">\n",
      "          <div class=\"column logo-arxiv\"><a href=\"https://arxiv.org/\"><img src=\"/static/browse/0.3.4/images/arxiv-logomark-small-white.svg\" alt=\"arXiv logo\" style=\"height:60px;\" /></a></div>\n",
      "          <div class=\"column logo-cornell\"><a href=\"https://www.cornell.edu/\">\n",
      "            <picture>\n",
      "              <source media=\"(min-width: 501px)\"\n",
      "                srcset=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg  400w\"\n",
      "                sizes=\"400w\" />\n",
      "              <source srcset=\"/static/browse/0.3.4/images/icons/cu/cornell_seal_simple_black.svg 2x\" />\n",
      "              <img src=\"/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg\" alt=\"Cornell University Logo\" />\n",
      "            </picture>\n",
      "          </a></div>\n",
      "          <div class=\"column nav\" id=\"toggle-container\" role=\"menubar\">\n",
      "            <button class=\"toggle-control\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-white\"><title>open search</title><path d=\"M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z\"/></svg></button>\n",
      "            <div class=\"mobile-toggle-block toggle-target\">\n",
      "              <form class=\"mobile-search-form\" method=\"GET\" action=\"https://arxiv.org/search\">\n",
      "                <div class=\"field has-addons\">\n",
      "                  <input class=\"input\" type=\"text\" name=\"query\" placeholder=\"Search...\" aria-label=\"Search term or terms\" />\n",
      "                  <input type=\"hidden\" name=\"source\" value=\"header\">\n",
      "                  <input type=\"hidden\" name=\"searchtype\" value=\"all\">\n",
      "                  <button class=\"button\">GO</button>\n",
      "                </div>\n",
      "              </form>\n",
      "            </div>\n",
      "\n",
      "            <button class=\"toggle-control\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\" class=\"icon filter-white\" role=\"menu\"><title>open navigation menu</title><path d=\"M16 132h416c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H16C7.163 60 0 67.163 0 76v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h416c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H16c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z\"/ ></svg></button>\n",
      "            <div class=\"mobile-toggle-block toggle-target\">\n",
      "              <nav class=\"mobile-menu\" aria-labelledby=\"mobilemenulabel\">\n",
      "                <h2 id=\"mobilemenulabel\">quick links</h2>\n",
      "                <ul>\n",
      "                    <li><a href=\"https://arxiv.org/login\">Login</a></li>\n",
      "                    <li><a href=\"https://info.arxiv.org/help\">Help Pages</a></li>\n",
      "                    <li><a href=\"https://info.arxiv.org/about\">About</a></li>\n",
      "                </ul>\n",
      "              </nav>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div><!-- /end mobile-header -->\n",
      "    </header>\n",
      "\n",
      "    <main>\n",
      "      <div id=\"content\">\n",
      "<!--\n",
      "rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n",
      "         xmlns:dc=\"http://purl.org/dc/elements/1.1/\"\n",
      "         xmlns:trackback=\"http://madskills.com/public/xml/rss/module/trackback/\">\n",
      "    <rdf:Description\n",
      "        rdf:about=\"/abs/1706.03762\"\n",
      "        dc:identifier=\"/abs/1706.03762\"\n",
      "        dc:title=\"Attention Is All You Need\"\n",
      "        trackback:ping=\"/trackback/1706.03762\" />\n",
      "    </rdf:RDF>\n",
      "--><div id=\"abs-outer\">\n",
      "\n",
      "  <div class=\"leftcolumn\">\n",
      "    <div class=\"subheader\">\n",
      "      <h1>Computer Science > Computation and Language</h1>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"header-breadcrumbs-mobile\">\n",
      "      <strong>arXiv:1706.03762</strong> (cs)\n",
      "    </div>\n",
      "<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/base/1.0.1/css/abs.css\">\n",
      "<div id=\"content-inner\">\n",
      "  <div id=\"abs\">\n",
      "    <div class=\"dateline\">\n",
      "  [Submitted on 12 Jun 2017 (<a href=\"https://arxiv.org/abs/1706.03762v1\">v1</a>), last revised 2 Aug 2023 (this version, v7)]</div>\n",
      "    <h1 class=\"title mathjax\"><span class=\"descriptor\">Title:</span>Attention Is All You Need</h1>\n",
      "    <div class=\"authors\"><span class=\"descriptor\">Authors:</span><a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani,+A\" rel=\"nofollow\">Ashish Vaswani</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Shazeer,+N\" rel=\"nofollow\">Noam Shazeer</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Parmar,+N\" rel=\"nofollow\">Niki Parmar</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Uszkoreit,+J\" rel=\"nofollow\">Jakob Uszkoreit</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Jones,+L\" rel=\"nofollow\">Llion Jones</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez,+A+N\" rel=\"nofollow\">Aidan N. Gomez</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Kaiser,+L\" rel=\"nofollow\">Lukasz Kaiser</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Polosukhin,+I\" rel=\"nofollow\">Illia Polosukhin</a></div>            <div id=\"download-button-info\" hidden>View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors</div>\n",
      "    <a class=\"mobile-submission-download\" href=\"/pdf/1706.03762\">View PDF</a>\n",
      "    <a class=\"mobile-submission-download\" href=\"https://arxiv.org/html/1706.03762v7\">HTML (experimental)</a>\n",
      "\n",
      "\n",
      "\n",
      "    <blockquote class=\"abstract mathjax\">\n",
      "            <span class=\"descriptor\">Abstract:</span>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n",
      "    </blockquote>\n",
      "\n",
      "    <!--CONTEXT-->\n",
      "    <div class=\"metatable\">\n",
      "      <table summary=\"Additional metadata\">        <tr>\n",
      "          <td class=\"tablecell label\">Comments:</td>\n",
      "          <td class=\"tablecell comments mathjax\">15 pages, 5 figures</td>\n",
      "        </tr>\n",
      "<tr>\n",
      "          <td class=\"tablecell label\">Subjects:</td>\n",
      "          <td class=\"tablecell subjects\">\n",
      "            <span class=\"primary-subject\">Computation and Language (cs.CL)</span>; Machine Learning (cs.LG)</td>\n",
      "        </tr><tr>\n",
      "          <td class=\"tablecell label\">Cite as:</td>\n",
      "          <td class=\"tablecell arxivid\"><span class=\"arxivid\"><a href=\"https://arxiv.org/abs/1706.03762\">arXiv:1706.03762</a> [cs.CL]</span></td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "          <td class=\"tablecell label\">&nbsp;</td>\n",
      "          <td class=\"tablecell arxividv\">(or <span class=\"arxivid\">\n",
      "              <a href=\"https://arxiv.org/abs/1706.03762v7\">arXiv:1706.03762v7</a> [cs.CL]</span> for this version)\n",
      "          </td>\n",
      "        </tr>\n",
      "        <tr>\n",
      "          <td class=\"tablecell label\">&nbsp;</td>\n",
      "          <td class=\"tablecell arxivdoi\">              <a href=\"https://doi.org/10.48550/arXiv.1706.03762\"  id=\"arxiv-doi-link\">https://doi.org/10.48550/arXiv.1706.03762</a><div class=\"button-and-tooltip\">\n",
      "              <button class=\"more-info\" aria-describedby=\"more-info-desc-1\">\n",
      "                <svg height=\"15\" role=\"presentation\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><path fill=\"currentColor\" d=\"M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z\" class=\"\"></path></svg>\n",
      "                <span class=\"visually-hidden\">Focus to learn more</span>\n",
      "              </button>\n",
      "              <!-- tooltip description -->\n",
      "              <div role=\"tooltip\" id=\"more-info-desc-1\">\n",
      "                <span class=\"left-corner\"></span>                  arXiv-issued DOI via DataCite</div>\n",
      "            </div>\n",
      "          </td>\n",
      "        </tr></table>\n",
      "    </div>\n",
      "  </div>\n",
      "</div>\n",
      "    <div class=\"submission-history\">\n",
      "      <h2>Submission history</h2> From: Llion Jones [<a href=\"/show-email/f53b7360/1706.03762\" rel=\"nofollow\">view email</a>]      <br/>            <strong><a href=\"/abs/1706.03762v1\" rel=\"nofollow\">[v1]</a></strong>\n",
      "        Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)<br/>\n",
      "            <strong><a href=\"/abs/1706.03762v2\" rel=\"nofollow\">[v2]</a></strong>\n",
      "        Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)<br/>\n",
      "            <strong><a href=\"/abs/1706.03762v3\" rel=\"nofollow\">[v3]</a></strong>\n",
      "        Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)<br/>\n",
      "            <strong><a href=\"/abs/1706.03762v4\" rel=\"nofollow\">[v4]</a></strong>\n",
      "        Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)<br/>\n",
      "            <strong><a href=\"/abs/1706.03762v5\" rel=\"nofollow\">[v5]</a></strong>\n",
      "        Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)<br/>\n",
      "            <strong><a href=\"/abs/1706.03762v6\" rel=\"nofollow\">[v6]</a></strong>\n",
      "        Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)<br/>\n",
      "    <strong>[v7]</strong>\n",
      "        Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)<br/>\n",
      "</div>\n",
      "  </div>\n",
      "  <!--end leftcolumn-->\n",
      "<div class=\"extra-services\">    <div class=\"full-text\">\n",
      "      <a name=\"other\"></a>\n",
      "      <span class=\"descriptor\">Full-text links:</span>\n",
      "      <h2>Access Paper:</h2>\n",
      "      <ul>\n",
      "  <div id=\"download-button-info\" hidden>\n",
      "View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors</div><li><a href=\"/pdf/1706.03762\" aria-describedby=\"download-button-info\" accesskey=\"f\" class=\"abs-button download-pdf\">View PDF</a></li><li><a href=\"https://arxiv.org/html/1706.03762v7\" class=\"abs-button\" id=\"latexml-download-link\">HTML (experimental)</a></li><li><a href=\"/src/1706.03762\" class=\"abs-button download-eprint\">TeX Source\n",
      " </a></li></ul>\n",
      "      <div class=\"abs-license\"><a href=\"http://arxiv.org/licenses/nonexclusive-distrib/1.0/\" title=\"Rights to this article\">view license</a></div>\n",
      "    </div>\n",
      "    <!--end full-text-->    <div class=\"browse\">\n",
      "    Current browse context: <div class=\"current\">cs.CL</div>\n",
      "\n",
      "  <div class=\"prevnext\">\n",
      "<span class=\"arrow\">\n",
      "      <a class=\"abs-button prev-url\" href=\"/prevnext?id=1706.03762&amp;function=prev&amp;context=cs.CL\"\n",
      "         accesskey=\"p\" title=\"previous in cs.CL (accesskey p)\" rel=\"nofollow\">&lt;&nbsp;prev</a>\n",
      "    </span>\n",
      "    <span class=\"is-hidden-mobile\">&nbsp; | &nbsp;</span>    <span class=\"arrow\">\n",
      "      <a class=\"abs-button next-url\" href=\"/prevnext?id=1706.03762&amp;function=next&amp;context=cs.CL\" accesskey=\"n\"\n",
      "         title=\"next in cs.CL (accesskey n)\"  rel=\"nofollow\">next&nbsp;&gt;</a>\n",
      "    </span><br/>\n",
      "  </div><div class=\"list\">\n",
      "    <a class=\"abs-button abs-button-grey abs-button-small context-new\" href=\"/list/cs.CL/new\"  rel=\"nofollow\">new</a>\n",
      "    <span class=\"is-hidden-mobile\"> | </span>\n",
      "    <a class=\"abs-button abs-button-grey abs-button-small context-recent\" href=\"/list/cs.CL/recent\" rel=\"nofollow\">recent</a>\n",
      "    <span class=\"is-hidden-mobile\"> | </span><a class=\"abs-button abs-button-grey abs-button-small context-id\" href=\"/list/cs.CL/2017-06\" rel=\"nofollow\">2017-06</a>\n",
      "  </div><div class=\"abs-switch-cat\">\n",
      "    Change to browse by:\n",
      "    <div class=\"switch context-change\">\n",
      "        <a href=\"/abs/1706.03762?context=cs\" rel=\"nofollow\">cs</a><br class=\"is-hidden-mobile\">\n",
      "        <a class=\"subclass\" href=\"/abs/1706.03762?context=cs.LG\" rel=\"nofollow\">cs.LG</a><br class=\"is-hidden-mobile\">\n",
      "    </div>\n",
      "  </div>\n",
      "\n",
      "    </div>\n",
      "      <div class=\"extra-ref-cite\">\n",
      "        <h3>References &amp; Citations</h3>\n",
      "        <ul>\n",
      "          <li><a  class=\"abs-button abs-button-small cite-ads\" href=\"https://ui.adsabs.harvard.edu/abs/arXiv:1706.03762\">NASA ADS</a></li><li><a  class=\"abs-button abs-button-small cite-google-scholar\" href=\"https://scholar.google.com/scholar_lookup?arxiv_id=1706.03762\" target=\"_blank\" rel=\"noopener\">Google Scholar</a></li>\n",
      "          <li><a  class=\"abs-button abs-button-small cite-semantic-scholar\" href=\"https://api.semanticscholar.org/arXiv:1706.03762\" target=\"_blank\" rel=\"noopener\">Semantic Scholar</a></li>\n",
      "        </ul>\n",
      "        <div style=\"clear:both;\"></div>\n",
      "      </div>\n",
      "\n",
      "    <div class=\"extra-general\">\n",
      "        <div class=\"what-is-this\">\n",
      "            <h3><a  class=\"abs-button abs-button-grey abs-button-small trackback-link\" href=\"/tb/1706.03762\"> 123 blog links</a></h3> (<a href=\"https://info.arxiv.org/help/trackback.html\" class=\"trackback-help\">what is this?</a>)\n",
      "        </div>\n",
      "    </div>\n",
      "<div class=\"dblp\">\n",
      "    <h3><a href=\"https://dblp.uni-trier.de\">DBLP</a> - CS Bibliography</h3>\n",
      "    <div class=\"list\">\n",
      "      <a href=\"https://dblp.uni-trier.de/db/journals/corr/corr1706.html#VaswaniSPUJGKP17\" title=\"listing on DBLP\">listing</a> | <a href=\"https://dblp.uni-trier.de/rec/bibtex/journals/corr/VaswaniSPUJGKP17\" title=\"DBLP bibtex record\">bibtex</a>    </div>\n",
      "    <div class=\"list\">\n",
      "<a href=\"https://dblp.uni-trier.de/search/author?author=Ashish%20Vaswani\" title=\"DBLP author search\">Ashish Vaswani</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Noam%20Shazeer\" title=\"DBLP author search\">Noam Shazeer</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Niki%20Parmar\" title=\"DBLP author search\">Niki Parmar</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Jakob%20Uszkoreit\" title=\"DBLP author search\">Jakob Uszkoreit</a><br/><a href=\"https://dblp.uni-trier.de/search/author?author=Llion%20Jones\" title=\"DBLP author search\">Llion Jones</a>      <div class=\"list\">&hellip;</div>\n",
      "    </div>\n",
      "  </div><div class='extra-ref-cite'>\n",
      "    <span id='bib-cite-trigger' class=\"bib-cite-button abs-button\">export BibTeX citation</span>\n",
      "    <span id='bib-cite-loading' hidden='true'>Loading...</span>\n",
      "</div>\n",
      "\n",
      "<div id='bib-cite-modal' class='bib-modal' hidden='true'>\n",
      "    <div class='bib-modal-content'>\n",
      "        <div class='bib-modal-title'>\n",
      "            <h2>BibTeX formatted citation</h2>\n",
      "            <span class='bib-modal-close' >&times;</span>\n",
      "        </div>\n",
      "        <div>\n",
      "            <textarea id='bib-cite-target' class=\"bib-citation-content\" aria-label=\"loading the citation\">loading...</textarea>\n",
      "        </div>\n",
      "        <div>\n",
      "            <span>Data provided by: </span>\n",
      "            <a id='bib-cite-source-api'></a>\n",
      "        </div>\n",
      "    </div>\n",
      "</div><div class=\"bookmarks\">\n",
      "  <div><h3>Bookmark</h3></div><a class=\"abs-button abs-button-grey abs-button-small\" href=\"http://www.bibsonomy.org/BibtexHandler?requTask=upload&amp;url=https://arxiv.org/abs/1706.03762&amp;description=Attention Is All You Need\"\n",
      "     title=\"Bookmark on BibSonomy\">\n",
      "    <img src=\"/static/browse/0.3.4/images/icons/social/bibsonomy.png\"\n",
      "         alt=\"BibSonomy logo\"/>\n",
      "  </a>\n",
      "  <a class=\"abs-button abs-button-grey abs-button-small\" href=\"https://reddit.com/submit?url=https://arxiv.org/abs/1706.03762&amp;title=Attention Is All You Need\"\n",
      "     title=\"Bookmark on Reddit\">\n",
      "    <img src=\"/static/browse/0.3.4/images/icons/social/reddit.png\"\n",
      "         alt=\"Reddit logo\"/>\n",
      "  </a>\n",
      "</div>  </div>\n",
      "  <!--end extra-services-->\n",
      "<!-- LABS AREA -->\n",
      "<div id=\"labstabs\">\n",
      "  <div class=\"labstabs\"><input type=\"radio\" name=\"tabs\" id=\"tabone\"checked=\"checked\">\n",
      "    <label for=\"tabone\">Bibliographic Tools</label>\n",
      "    <div class=\"tab labs-display-bib\">\n",
      "      <h1>Bibliographic and Citation Tools</h1>\n",
      "      <div class=\"toggle\">\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input id=\"bibex-toggle\" type=\"checkbox\" class=\"lab-toggle\"\n",
      "                     data-script-url=\"/static/browse/0.3.4/bibex/bibex.js?20241202\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">Bibliographic Explorer Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-bibex\">Bibliographic Explorer</span> <em>(<a href=\"https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer\">What is the Explorer?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"connectedpapers-toggle\"\n",
      "                type=\"checkbox\"\n",
      "                class=\"lab-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/connectedpapers.js\"\n",
      "                aria-labelledby=\"label-for-connected-papers\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">Connected Papers Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-connected-papers\">Connected Papers</span> <em>(<a href=\"https://www.connectedpapers.com/about\" target=\"_blank\">What is Connected Papers?</a>)</em>\n",
      "          </div>\n",
      "        </div><div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"litmaps-toggle\"\n",
      "                type=\"checkbox\"\n",
      "                class=\"lab-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/litmaps.js?20210617\"\n",
      "                aria-labelledby=\"label-for-litmaps\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">Litmaps Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-litmaps\">Litmaps</span> <em>(<a href=\"https://www.litmaps.co/\" target=\"_blank\">What is Litmaps?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"scite-toggle\"\n",
      "                type=\"checkbox\"\n",
      "                class=\"lab-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/scite.js?20210617\"\n",
      "                aria-labelledby=\"label-for-scite\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">scite.ai Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-scite\">scite Smart Citations</span> <em>(<a href=\"https://www.scite.ai/\" target=\"_blank\">What are Smart Citations?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "        <div class=\"labs-content-placeholder labs-display\" style=\"display: none;\"></div>\n",
      "        <div style=\"min-height: 15px\" id=\"connectedpapers-output\"></div>\n",
      "        <div style=\"min-height: 15px\" id=\"litmaps-open-in\"></div>\n",
      "        <div style=\"min-height: 15px\" id=\"scite-open-in\"></div>\n",
      "    </div>\n",
      "\n",
      "\n",
      "    <input type=\"radio\" name=\"tabs\" id=\"tabtwo\">\n",
      "    <label for=\"tabtwo\">Code, Data, Media</label>\n",
      "    <div class=\"tab\">\n",
      "      <h1>Code, Data and Media Associated with this Article</h1>\n",
      "      <div class=\"toggle\">\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"alphaxiv-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/alphaxiv.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-alphaxiv\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">alphaXiv Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-alphaxiv\">alphaXiv</span> <em>(<a href=\"https://alphaxiv.org/\" target=\"_blank\">What is alphaXiv?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input        \n",
      "                id=\"catalyzex-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/catalyzex.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-cx\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">Links to Code Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-cx\">CatalyzeX Code Finder for Papers</span> <em>(<a href=\"https://www.catalyzex.com\" target=\"_blank\">What is CatalyzeX?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"dagshub-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/dagshub.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-dagshub\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">DagsHub Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-dagshub\">DagsHub</span> <em>(<a href=\"https://dagshub.com/\" target=\"_blank\">What is DagsHub?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "  \n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"gotitpub-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/gotitpub.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-gotitpub\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">GotitPub Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-gotitpub\">Gotit.pub</span> <em>(<a href=\"http://gotit.pub/faq\" target=\"_blank\">What is GotitPub?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"huggingface-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/huggingface.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-huggingface\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">Huggingface Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-huggingface\">Hugging Face</span> <em>(<a href=\"https://huggingface.co/huggingface\" target=\"_blank\">What is Huggingface?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"paperwithcode-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/paperswithcode.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-pwc\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">Links to Code Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-pwc\">Papers with Code</span> <em>(<a href=\"https://paperswithcode.com/\" target=\"_blank\">What is Papers with Code?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "\n",
      "\n",
      "        <div class=\"columns is-mobile lab-row\">\n",
      "          <div class=\"column lab-switch\">\n",
      "            <label class=\"switch\">\n",
      "              <input\n",
      "                id=\"sciencecast-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/sciencecast.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-sciencecast\">\n",
      "              <span class=\"slider\"></span>\n",
      "              <span class=\"is-sr-only\">ScienceCast Toggle</span>\n",
      "            </label>\n",
      "          </div>\n",
      "          <div class=\"column lab-name\">\n",
      "            <span id=\"label-for-sciencecast\">ScienceCast</span> <em>(<a href=\"https://sciencecast.org/welcome\" target=\"_blank\">What is ScienceCast?</a>)</em>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "      <div id=\"alphaxiv-output\" style=\"display:none\"></div>\n",
      "      <div id=\"catalyzex-output\" style=\"display:none\"></div>\n",
      "      <div id=\"dagshub-output\" style=\"display:none\"></div>\n",
      "      <div id=\"gotitpub-output\" style=\"display:none\"></div>\n",
      "      <div id=\"pwc-output\" style=\"display:none\"></div>\n",
      "      <div id=\"pwc-data-output\" style=\"display:none\"></div>\n",
      "      <div id=\"sciencecast-output\" style=\"display:none\"></div>\n",
      "      <div id=\"huggingface-output\" style=\"display:none\"></div>\n",
      "    </div>\n",
      "\n",
      "\n",
      "      <input type=\"radio\" name=\"tabs\" id=\"labstabs-demos-input\">\n",
      "      <label for=\"labstabs-demos-input\" id=\"labstabs-demos-label\">Demos</label>\n",
      "      <div class=\"tab\">\n",
      "        <h1>Demos</h1>\n",
      "        <div class=\"toggle\">\n",
      "          <div class=\"columns is-mobile lab-row\">\n",
      "            <div class=\"column lab-switch\">\n",
      "              <label class=\"switch\">\n",
      "                <input\n",
      "                  id=\"replicate-toggle\"\n",
      "                  data-script-url=\"/static/browse/0.3.4/js/replicate.js\"\n",
      "                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-replicate\">\n",
      "                <span class=\"slider\"></span>\n",
      "                <span class=\"is-sr-only\">Replicate Toggle</span>\n",
      "              </label>\n",
      "            </div>\n",
      "            <div class=\"column lab-name\">\n",
      "              <span id=\"label-for-replicate\">Replicate</span> <em>(<a href=\"https://replicate.com/docs/arxiv/about\" target=\"_blank\">What is Replicate?</a>)</em>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"columns is-mobile lab-row\">\n",
      "            <div class=\"column lab-switch\">\n",
      "              <label class=\"switch\">\n",
      "                <input\n",
      "                  id=\"spaces-toggle\"\n",
      "                  data-script-url=\"/static/browse/0.3.4/js/spaces.js\"\n",
      "                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-spaces\">\n",
      "                <span class=\"slider\"></span>\n",
      "                <span class=\"is-sr-only\">Spaces Toggle</span>\n",
      "              </label>\n",
      "            </div>\n",
      "            <div class=\"column lab-name\">\n",
      "              <span id=\"label-for-spaces\">Hugging Face Spaces</span> <em>(<a href=\"https://huggingface.co/docs/hub/spaces\" target=\"_blank\">What is Spaces?</a>)</em>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"columns is-mobile lab-row\">\n",
      "            <div class=\"column lab-switch\">\n",
      "              <label class=\"switch\">\n",
      "                <input\n",
      "                  id=\"txyz-toggle\"\n",
      "                  data-script-url=\"/static/browse/0.3.4/js/txyz.js\"\n",
      "                  type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-txyz\">\n",
      "                <span class=\"slider\"></span>\n",
      "                <span class=\"is-sr-only\">Spaces Toggle</span>\n",
      "              </label>\n",
      "            </div>\n",
      "            <div class=\"column lab-name\">\n",
      "              <span id=\"label-for-txyz\">TXYZ.AI</span> <em>(<a href=\"https://txyz.ai\" target=\"_blank\">What is TXYZ.AI?</a>)</em>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div id=\"replicate-output\"></div>\n",
      "        <div id=\"spaces-output\"></div>\n",
      "        <div id=\"txyz-output\"></div>\n",
      "      </div>\n",
      "      <input type=\"radio\" name=\"tabs\" id=\"tabfour\">\n",
      "      <label for=\"tabfour\">Related Papers</label>\n",
      "      <div class=\"tab\">\n",
      "        <h1>Recommenders and Search Tools</h1>\n",
      "        <div class=\"toggle\">\n",
      "          <div class=\"columns is-mobile lab-row\">\n",
      "            <div class=\"column lab-switch\">\n",
      "              <label class=\"switch\">\n",
      "                <input id=\"influenceflower-toggle\"\n",
      "                data-script-url=\"/static/browse/0.3.4/js/influenceflower.js\"\n",
      "                type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-influenceflower\">\n",
      "                <span class=\"slider\"></span>\n",
      "                <span class=\"is-sr-only\">Link to Influence Flower</span>\n",
      "              </label>\n",
      "            </div>\n",
      "            <div class=\"column lab-name\">\n",
      "              <span id=\"label-for-influenceflower\">Influence Flower</span> <em>(<a href=\"https://influencemap.cmlab.dev/\" target=\"_blank\">What are Influence Flowers?</a>)</em>\n",
      "            </div>\n",
      "          </div>\n",
      "          <div class=\"columns is-mobile lab-row\">\n",
      "            <div class=\"column lab-switch\">\n",
      "              <label class=\"switch\">\n",
      "                <input id=\"core-recommender-toggle\" type=\"checkbox\" class=\"lab-toggle\" aria-labelledby=\"label-for-core\">\n",
      "                <span class=\"slider\"></span>\n",
      "                <span class=\"is-sr-only\">Core recommender toggle</span>\n",
      "              </label>\n",
      "            </div>\n",
      "            <div class=\"column lab-name\">\n",
      "              <span id=\"label-for-core\">CORE Recommender</span> <em>(<a href=\"https://core.ac.uk/services/recommender\">What is CORE?</a>)</em>\n",
      "            </div>\n",
      "          </div></div>\n",
      "        <div id=\"influenceflower-output\"></div>\n",
      "        <div id=\"influenceflower-output-graph\" style=\"display:none\">\n",
      "          <ul class=\"flower-tabs\">\n",
      "            <li class=\"active\"><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-author')\">Author</a></li>\n",
      "            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-venue')\">Venue</a></li>\n",
      "            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-inst')\">Institution</a></li>\n",
      "            <li><a class=\"btn tab-btn\" onclick=\"openTab(event, 'tab-topic')\">Topic</a></li>\n",
      "          </ul>\n",
      "          <div class=\"flower-tab-content\">\n",
      "            <div class=\"tab-flower active\" id=\"tab-author\"><svg id=\"flower-graph-author\"></svg></div>\n",
      "            <div class=\"tab-flower\" id=\"tab-venue\"><svg id=\"flower-graph-venue\"></svg></div>\n",
      "            <div class=\"tab-flower\" id=\"tab-inst\"><svg id=\"flower-graph-inst\"></svg></div>\n",
      "            <div class=\"tab-flower\" id=\"tab-topic\"><svg id=\"flower-graph-topic\"></svg></div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <div id=\"coreRecommenderOutput\"></div>\n",
      "        <div id=\"iarxivOutput\"></div>\n",
      "      </div>\n",
      "\n",
      "      <input type=\"radio\" name=\"tabs\" id=\"tabfive\">\n",
      "      <label for=\"tabfive\">\n",
      "        About arXivLabs\n",
      "      </label>\n",
      "      <div class=\"tab\">\n",
      "        <div class=\"columns\">\n",
      "          <div class=\"column\">\n",
      "            <h1>arXivLabs: experimental projects with community collaborators</h1>\n",
      "            <p>arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.</p>\n",
      "            <p>Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.</p>\n",
      "            <p>Have an idea for a project that will add value for arXiv's community? <a href=\"https://info.arxiv.org/labs/index.html\"><strong>Learn more about arXivLabs</strong></a>.</p>\n",
      "          </div>\n",
      "          <div class=\"column is-narrow is-full-mobile\">\n",
      "            <p class=\"icon-labs\"><svg xmlns=\"http://www.w3.org/2000/svg\" role=\"presentation\" viewBox=\"0 0 635.572 811\"><path d=\"M175.6 676v27h-27v-27zm-54 27v27h27v-27zm-27 27v27h27v-27zm396-54v27h-27v-27zm0 27v27h27v-27zm27 27v27h27v-27zm-27-414h27v27h-27zm27 0h27v-27h-27zm27-27h27v-27h-27zm-396 45h-27v-27h27zm-27-54h-27v27h27zm-27-27h-27v27h27z\"/><path d=\"M94.6 730v27h-27v-27zm477 0v27h-27v-27zm-27-495h27v27h-27zm-450 18h-27v-27h27zm477 9h27v27h-27zm-54 495h27v27h-27zm-423 0h27v27h-27zm-54-504h27v27h-27z\" fill=\"#666\"/><path d=\"M67.6 730v27h-27v-27zm54 54v27h-27v-27zm0-108v27h27v-27zm-27 27v27h27v-27zm-81 0v27h27v-27zm585 27v27h-27v-27zm-108-54v27h27v-27zm27 27v27h27v-27zm81 0v27h27v-27zm-54-495h27v27h-27zm-54 108h27v-27h-27zm27-27h27v-27h-27zm0-81h27v-27h-27zm-423 18h-27v-27h27zm54 54h-27v27h27zm-27-27h-27v27h27zm0-81h-27v27h27zm423 612v27h-27v-27zm81-522v27h-27v-27zm-585-9v27h-27v-27z\" fill=\"#999\"/><path d=\"M94.6 784v27h-27v-27zm-27-27v27h27v-27zm-27-54v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm0-27v27h27v-27zm27 0v27h27v-27zm-108 81v27h27v-27zm558 54v27h-27v-27zm-27-27v27h27v-27zm27-54v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm0-27v27h27v-27zm-27 0v27h27v-27zm108 81v27h27v-27zm0-495h27v27h-27zm-27 27h27v-27h-27zm-54-27h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm-27 0h27v-27h-27zm0 27h27v-27h-27zm81-108h27v-27h-27zm-504 45h-27v-27h27zm27-27h-27v27h27zm54-27h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm27 0h-27v27h27zm0 27h-27v27h27zm-81-108h-27v27h27z\" fill=\"#ccc\"/><path d=\"M598.6 665.1H41.5C-76.5 667 176 280.2 176 280.2h53a46.5 46.5 0 0162.8-56.3 29.2 29.2 0 1128.5 35.9h-1a46.5 46.5 0 01-1.5 20.3l142.5-.1s255.3 387 138.3 385.1zM291 181a29.3 29.3 0 10-29.2-29.3A29.3 29.3 0 00291 181zm65.4-66.8a22.4 22.4 0 10-22.5-22.4 22.4 22.4 0 0022.5 22.4z\" fill=\"#fc0\"/><path d=\"M245.5 172V10h153v162s324 495 198 495h-558c-126 0 207-495 207-495zm126 54h56m-13 72h56m-9 72h56m-20 72h56m-22 72h56m-29 72h56m-457-45c20.8 41.7 87.3 81 160.7 81 72.1 0 142.1-38.2 163.4-81\" fill=\"none\" stroke=\"#000\" stroke-miterlimit=\"10\" stroke-width=\"20\"/><path d=\"M273.3 421.7c0 31-9.8 56.3-21.9 56.3s-21.8-25.2-21.8-56.3 9.8-56.3 21.8-56.3 21.9 25.2 21.9 56.3zm114.4-56.3c-12 0-21.8 25.2-21.8 56.3s9.7 56.3 21.8 56.3 21.9-25.2 21.9-56.3-9.8-56.3-21.9-56.3zM150.1 526.6c-18.2 6.7-27.5 22.9-23.2 30.2s14.8-5.5 33-12.2 37.4-4.9 33-12.2-24.5-12.6-42.8-5.8zm296 5.8c-4.2 7.3 14.9 5.5 33.1 12.2s28.7 19.5 33 12.2-5-23.5-23.2-30.2-38.5-1.5-42.8 5.8z\"/></svg></p>\n",
      "          </div>\n",
      "        </div>\n",
      "      </div>\n",
      "\n",
      "    </div>\n",
      "</div>\n",
      "<!-- END LABS AREA -->\n",
      "  <div class=\"endorsers\">\n",
      "    <a href=\"/auth/show-endorsers/1706.03762\" class=\"endorser-who\" rel=\"nofollow\">Which authors of this paper are endorsers?</a> |\n",
      "    <a id=\"mathjax_toggle\" href=\"javascript:setMathjaxCookie()\">Disable MathJax</a> (<a href=\"https://info.arxiv.org/help/mathjax.html\">What is MathJax?</a>)\n",
      "    <span class=\"help\" style=\"font-style: normal; float: right; margin-top: 0; margin-right: 1em;\"></span>\n",
      "  </div>\n",
      "  <script type=\"text/javascript\" language=\"javascript\">mathjaxToggle();</script>\n",
      "</div>\n",
      "      </div>\n",
      "    </main>\n",
      "\n",
      "    <footer style=\"clear: both;\">\n",
      "      <div class=\"columns is-desktop\" role=\"navigation\" aria-label=\"Secondary\" style=\"margin: -0.75em -0.75em 0.75em -0.75em\">\n",
      "        <!-- Macro-Column 1 -->\n",
      "        <div class=\"column\" style=\"padding: 0;\">\n",
      "          <div class=\"columns\">\n",
      "            <div class=\"column\">\n",
      "              <ul style=\"list-style: none; line-height: 2;\">\n",
      "                <li><a href=\"https://info.arxiv.org/about\">About</a></li>\n",
      "                <li><a href=\"https://info.arxiv.org/help\">Help</a></li>\n",
      "              </ul>\n",
      "            </div>\n",
      "            <div class=\"column\">\n",
      "              <ul style=\"list-style: none; line-height: 2;\">\n",
      "                <li>\n",
      "                  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d=\"M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z\"/></svg>\n",
      "                  <a href=\"https://info.arxiv.org/help/contact.html\"> Contact</a>\n",
      "                </li>\n",
      "                <li>\n",
      "                  <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\" class=\"icon filter-black\" role=\"presentation\"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d=\"M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z\"/></svg>\n",
      "                  <a href=\"https://info.arxiv.org/help/subscribe\"> Subscribe</a>\n",
      "                </li>\n",
      "              </ul>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div>\n",
      "        <!-- End Macro-Column 1 -->\n",
      "        <!-- Macro-Column 2 -->\n",
      "        <div class=\"column\" style=\"padding: 0;\">\n",
      "          <div class=\"columns\">\n",
      "            <div class=\"column\">\n",
      "              <ul style=\"list-style: none; line-height: 2;\">\n",
      "                <li><a href=\"https://info.arxiv.org/help/license/index.html\">Copyright</a></li>\n",
      "                <li><a href=\"https://info.arxiv.org/help/policies/privacy_policy.html\">Privacy Policy</a></li>\n",
      "              </ul>\n",
      "            </div>\n",
      "            <div class=\"column sorry-app-links\">\n",
      "              <ul style=\"list-style: none; line-height: 2;\">\n",
      "                <li><a href=\"https://info.arxiv.org/help/web_accessibility.html\">Web Accessibility Assistance</a></li>\n",
      "                <li>\n",
      "                  <p class=\"help\">\n",
      "                    <a class=\"a11y-main-link\" href=\"https://status.arxiv.org\" target=\"_blank\">arXiv Operational Status <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 256 512\" class=\"icon filter-dark_grey\" role=\"presentation\"><path d=\"M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z\"/></svg></a><br>\n",
      "                  </p>\n",
      "                </li>\n",
      "              </ul>\n",
      "            </div>\n",
      "          </div>\n",
      "        </div> <!-- end MetaColumn 2 -->\n",
      "        <!-- End Macro-Column 2 -->\n",
      "      </div>\n",
      "    </footer>\n",
      "  </div>\n",
      "\n",
      "  <script src=\"/static/base/1.0.1/js/member_acknowledgement.js\"></script>\n",
      "\n",
      "</body>\n",
      "\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "arvix_id = '1706.03762'\n",
    "\n",
    "\n",
    "res = requests.get(f'https://arxiv.org/abs/{arvix_id}')\n",
    "\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6178387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "abstract = abstract_pattern.search(res.text).group(1)\n",
    "\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "998c4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic.v1 import BaseModel, Field # Used for tool schema\n",
    "import requests\n",
    "import re\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# 1. Define the Pydantic Schema for the function's input\n",
    "class ArxivInput(BaseModel):\n",
    "    \"\"\"Input for fetching an arXiv abstract.\"\"\"\n",
    "    # Renamed the class for clarity, matching the tool's purpose\n",
    "    arvix_id: str = Field(description=\"The arXiv ID (e.g., '2407.03964') for the paper.\")\n",
    "\n",
    "\n",
    "# Regex pattern to find the abstract block\n",
    "# Note: This pattern is highly specific to a newer arXiv layout.\n",
    "abstract_pattern = re.compile(\n",
    "    r'<blockquote class=\"abstract mathjax\">\\s*<span class=\"descriptor\">Abstract:</span>\\s*(.*?)\\s*</blockquote>',\n",
    "    re.DOTALL\n",
    ")\n",
    "\n",
    "@tool(args_schema=ArxivInput) # Use the Pydantic schema\n",
    "def fetch_arxiv(arvix_id: str) -> str:\n",
    "    '''fetch arXiv abstract'''\n",
    "    print('New fetch arXiv abstract function')\n",
    "    # 1. Fetch the content\n",
    "    # Note: Older arXiv IDs like 9308101 might redirect or have simpler pages.\n",
    "    res = requests.get(f'https://arxiv.org/abs/{arvix_id}')\n",
    "    \n",
    "    # 2. Safely attempt the regex search\n",
    "    match = abstract_pattern.search(res.text)\n",
    "    \n",
    "    if match:\n",
    "        # If the expected blockquote structure is found, extract and return\n",
    "        abstract = match.group(1).strip()\n",
    "        if abstract:\n",
    "            return abstract\n",
    "        else:\n",
    "            # Found the block, but it was empty\n",
    "            raise ValueError(f'Found empty abstract block for {arvix_id}')\n",
    "    \n",
    "    # 3. Fallback/Error handling: Try a more generic match for older pages\n",
    "    # Older pages often have the abstract text directly in a div or p tag.\n",
    "    # This is an example of checking for a different, simpler pattern.\n",
    "    fallback_pattern = re.compile(\n",
    "        r'<div id=\"abstract\">\\s*<blockquote.*?>(.*?)</blockquote>',\n",
    "        re.DOTALL\n",
    "    )\n",
    "    fallback_match = fallback_pattern.search(res.text)\n",
    "    \n",
    "    if fallback_match:\n",
    "        return fallback_match.group(1).strip()\n",
    "    \n",
    "    # If no pattern matches, the error is legitimate\n",
    "    raise ValueError(f'Could not find abstract content for arXiv ID: {arvix_id}. The page structure may be non-standard.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcafc472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New fetch arXiv abstract function\n",
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.\n"
     ]
    }
   ],
   "source": [
    "arvix_id = '1706.03762'\n",
    "\n",
    "\n",
    "res = fetch_arxiv.invoke(input={'arvix_id': arvix_id}) ##invoke fetch_arxiv tool with \n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bce1ab4",
   "metadata": {},
   "source": [
    "## 6.Web Search tool \n",
    "Utilizes SERP API for google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e91877eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../ML_practice/cred.env\")\n",
    "\n",
    "SERP_API_KEY = os.getenv('SERP_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bacf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44a2de30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydantic\n",
    "pydantic.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e287ff41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: QUERY Definition & Meaning\n",
      "Snippet: 1 ... to ask questions of especially with a desire for authoritative information ... 2 ... to ask questions about especially in order to resolve a doubt ... 3 ... to put ...\n",
      "Link: https://www.merriam-webster.com/dictionary/query\n",
      "---\n",
      "Title: QUERY | definition in the Cambridge English Dictionary\n",
      "Snippet: a question, often expressing doubt about something or looking for an answer from an authority. If you have any queries about your treatment, the doctor will ...\n",
      "Link: https://dictionary.cambridge.org/us/dictionary/english/query\n",
      "---\n",
      "Title: Query\n",
      "Snippet: Computing and technology  Query, a precise request for information retrieval made to a database, data structure or information system  Command-query ...\n",
      "Link: https://en.wikipedia.org/wiki/Query\n",
      "---\n",
      "Title: QUERY Definition & Meaning\n",
      "Snippet: verb  to express uncertainty, doubt, or an objection concerning (something)  to express as a query  to put a question to (a person); ask.\n",
      "Link: https://www.dictionary.com/browse/query\n",
      "---\n",
      "Title: Home - Query\n",
      "Snippet: Query is a federated search platform for security data providing expanded data visibility without centralization.\n",
      "Link: https://www.query.ai/\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "# from pydantic import BaseModel, Field\n",
    "\n",
    "serp_params = {\n",
    "  \"engine\": \"google\",\n",
    "  \"api_key\": SERP_API_KEY\n",
    "}\n",
    "\n",
    "# # Define the Pydantic model for the tool's arguments\n",
    "# class WebSearchArgs(BaseModel):\n",
    "#     query: str = Field(description=\"The search query string.\")\n",
    "\n",
    "search = GoogleSearch({**serp_params,'q': 'query', 'num': 5})\n",
    "\n",
    "results = search.get_dict().get('organic_results', [])\n",
    "\n",
    "formatted_results = '\\n---\\n'.join([f\"Title: {result['title']}\\nSnippet: {result['snippet']}\\nLink: {result['link']}\" for result in results])\n",
    "\n",
    "\n",
    "\n",
    "print(formatted_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c3cd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'position': 1, 'title': 'QUERY Definition & Meaning', 'link': 'https://www.merriam-webster.com/dictionary/query', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.merriam-webster.com/dictionary/query&ved=2ahUKEwjVx-C69fmQAxVFrJUCHZsHEIsQFnoECCIQAQ', 'displayed_link': 'https://www.merriam-webster.com  dictionary  query', 'favicon': 'https://serpapi.com/searches/691b772b7223f464bdc06e63/images/0e8de4fa768bad099d14bcd56778d3a5e7224658273f909cac160e9fcbd8d94c.png', 'snippet': '1 ... to ask questions of especially with a desire for authoritative information ... 2 ... to ask questions about especially in order to resolve a doubt ... 3 ... to put ...', 'snippet_highlighted_words': ['to ask questions of especially with a desire for authoritative information'], 'source': 'Merriam-Webster'}, {'position': 2, 'title': 'QUERY | definition in the Cambridge English Dictionary', 'link': 'https://dictionary.cambridge.org/us/dictionary/english/query', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://dictionary.cambridge.org/us/dictionary/english/query&ved=2ahUKEwjVx-C69fmQAxVFrJUCHZsHEIsQFnoECCQQAQ', 'displayed_link': 'https://dictionary.cambridge.org  dictionary  query', 'favicon': 'https://serpapi.com/searches/691b772b7223f464bdc06e63/images/0e8de4fa768bad099d14bcd56778d3a57c7f8b6f539034ad45dbc8625721b80b.jpeg', 'snippet': 'a question, often expressing doubt about something or looking for an answer from an authority. If you have any queries about your treatment, the doctor will ...', 'snippet_highlighted_words': ['a question, often expressing doubt about something or looking for an answer from an authority'], 'source': 'Cambridge Dictionary'}, {'position': 3, 'title': 'Query', 'link': 'https://en.wikipedia.org/wiki/Query', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://en.wikipedia.org/wiki/Query&ved=2ahUKEwjVx-C69fmQAxVFrJUCHZsHEIsQFnoECCYQAQ', 'displayed_link': 'https://en.wikipedia.org  wiki  Query', 'favicon': 'https://serpapi.com/searches/691b772b7223f464bdc06e63/images/0e8de4fa768bad099d14bcd56778d3a5559b0a8f881a0fe68abd0652e53ce20a.png', 'snippet': 'Computing and technology  Query, a precise request for information retrieval made to a database, data structure or information system  Command-query ...', 'snippet_highlighted_words': ['a precise request for information retrieval'], 'source': 'Wikipedia'}, {'position': 4, 'title': 'QUERY Definition & Meaning', 'link': 'https://www.dictionary.com/browse/query', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.dictionary.com/browse/query&ved=2ahUKEwjVx-C69fmQAxVFrJUCHZsHEIsQFnoECD0QAQ', 'displayed_link': 'https://www.dictionary.com  browse  query', 'favicon': 'https://serpapi.com/searches/691b772b7223f464bdc06e63/images/0e8de4fa768bad099d14bcd56778d3a5a1db5f4f6644d8c34c60947c853398d1.png', 'snippet': 'verb  to express uncertainty, doubt, or an objection concerning (something)  to express as a query  to put a question to (a person); ask.', 'snippet_highlighted_words': ['to express uncertainty, doubt, or an objection concerning (something'], 'source': 'Dictionary.com'}, {'position': 5, 'title': 'Home - Query', 'link': 'https://www.query.ai/', 'redirect_link': 'https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://www.query.ai/&ved=2ahUKEwjVx-C69fmQAxVFrJUCHZsHEIsQFnoECEIQAQ', 'displayed_link': 'https://www.query.ai', 'thumbnail': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT5cSrdd6SqTvl0yPFDPJYWoOx6Mq7KawV5OmiGJCbumomj0ireGGad&usqp=CAE&s', 'favicon': 'https://serpapi.com/searches/691b772b7223f464bdc06e63/images/0e8de4fa768bad099d14bcd56778d3a5d52ba12170dda6eed05560b824e19c8f.png', 'snippet': 'Query is a federated search platform for security data providing expanded data visibility without centralization.', 'snippet_highlighted_words': ['Query'], 'sitelinks': {'inline': [{'title': 'Welcome to Query!', 'link': 'https://docs.query.ai/docs/introducing-query'}, {'title': 'Query Partners', 'link': 'https://www.query.ai/partners/'}, {'title': 'Query Overview', 'link': 'https://www.query.ai/resources/videos/query-overview/'}, {'title': 'Get Started With Query', 'link': 'https://www.query.ai/get-started/'}]}, 'source': 'Home - Query'}]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28e53986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "# Define the 'web_search' tool using the '@tool' decorator.\n",
    "@tool('web_search')\n",
    "def web_search(query: str) -> str:\n",
    "    '''Finds general knowledge information using a Google search.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string of the top search results, including title, snippet, and link.\n",
    "    '''\n",
    "\n",
    "    search = GoogleSearch({\n",
    "        **serp_params,  \n",
    "        'q': query,        \n",
    "        'num': 5         \n",
    "    })\n",
    "   \n",
    "    results = search.get_dict().get('organic_results', [])\n",
    "    formatted_results = '\\n---\\n'.join(\n",
    "        ['\\n'.join([x['title'], x['snippet'], x['link']]) for x in results]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Return the formatted results or a 'No results found.' message if no results exist.\n",
    "    return formatted_results if results else 'No results found.'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0cd0dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI in Fintech Use Cases: Top 10 Startups of 2025\n",
      "Within the FinTech industry, GenAI is particularly useful in creating synthetic datasets for risk assessment, enhancing customer service via advanced chatbots, ...\n",
      "https://www.coherentsolutions.com/insights/generative-ai-in-fintech-technologies-advantages-and-use-cases\n",
      "---\n",
      "Generative AI in FinTech: Benefits, Use Cases, Examples & ...\n",
      "The fusion of Generative AI is helping FinTech companies process and analyze data to unlock new avenues for innovation and operational efficiency.\n",
      "https://www.rishabhsoft.com/blog/generative-ai-in-fintech\n",
      "---\n",
      "The Unstoppable Rise of Generative AI in Financial Services\n",
      "Gen AI is reshaping financial services, with insights from Google Cloud highlighting how AI is accelerating innovation in banking and risk ...\n",
      "https://fintechmagazine.com/news/the-unstoppable-rise-of-generative-ai-in-financial-services\n",
      "---\n",
      "GenAI in banking: game-changer or world-ender?\n",
      "GenAI has the potential to transform the customer banking experience for the better. From streamlined communications to faster resolution times, ...\n",
      "https://www.charteredbanker.com/resource_listing/cpdresources/genai-in-banking-game-changer-or-world-ender.html\n",
      "---\n",
      "Generative AI in FinTech: Use Cases & Real-World Examples\n",
      "Gen AI in FinTech significantly enhances efficiency and personalized customer service. As its adoption increases, it brings improvements in critical areas like ...\n",
      "https://masterofcode.com/blog/generative-ai-for-fintech\n"
     ]
    }
   ],
   "source": [
    "output = web_search.invoke(input={'query': 'GenAI in fintech'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf03c2",
   "metadata": {},
   "source": [
    "## 7.Create a RAG tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c5f298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_rag_text(matches: list) -> str:\n",
    "    '''Formats the input text for the RAG tool and returns the formatted text as a string.'''\n",
    "    formatted_text = []\n",
    "\n",
    "\n",
    "    for x in matches:\n",
    "        text = (\n",
    "            f\"Title: {x['metadata']['title']}\\n\"\n",
    "            f\"Chunk: {x['metadata']['chunk']}\\n\"\n",
    "            f\"ArXiv ID: {x['metadata']['arxiv_id']}\\n\"\n",
    "        )\n",
    "\n",
    "        formatted_text.append(text)\n",
    "\n",
    "    formatted_text = '\\n---\\n'.join(formatted_text)\n",
    "\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "638d8371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from pydantic.v1 import BaseModel, Field # <-- New Import\n",
    "\n",
    "\n",
    "class WebSearchArgs(BaseModel):\n",
    "    arvix_id: str = Field(..., description=\"The arvix id string.\")\n",
    "\n",
    "@tool('rag_search_filter')\n",
    "def rag_search_filter(query:str, arvix_id:str) -> str:\n",
    "    '''RAG serach filter based on arvix id'''\n",
    "\n",
    "    query_encode = encoder([query])\n",
    "\n",
    "    input_vector = index.query(vector=query_encode, top_k=5, include_metadata=True, filter={'arxiv_id': arvix_id})\n",
    "\n",
    "    matches = input_vector['matches']\n",
    "\n",
    "    formatted_text = format_rag_text(matches)\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rag_search_filter.invoke(input={'query': 'Attention', 'arvix_id': '1706.03762'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10dd737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool('rag_search')\n",
    "def rag_search(query:str) -> str:\n",
    "    '''RAG search without filter'''\n",
    "\n",
    "    query_encode = encoder([query])\n",
    "\n",
    "    input_vector = index.query(vector=query_encode, top_k=5, include_metadata=True)\n",
    "\n",
    "    matches = input_vector['matches']\n",
    "\n",
    "    formatted_text = format_rag_text(matches)\n",
    "\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63cca028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StructuredTool in module langchain_core.tools.structured object:\n",
      "\n",
      "class StructuredTool(langchain_core.tools.base.BaseTool)\n",
      " |  StructuredTool(\n",
      " |      *,\n",
      " |      name: str,\n",
      " |      description: str = '',\n",
      " |      args_schema: Annotated[type[pydantic.main.BaseModel] | dict[str, Any], SkipValidation()],\n",
      " |      return_direct: bool = False,\n",
      " |      verbose: bool = False,\n",
      " |      callbacks: list[langchain_core.callbacks.base.BaseCallbackHandler] | langchain_core.callbacks.base.BaseCallbackManager | None = None,\n",
      " |      tags: list[str] | None = None,\n",
      " |      metadata: dict[str, typing.Any] | None = None,\n",
      " |      handle_tool_error: bool | str | collections.abc.Callable[[langchain_core.tools.base.ToolException], str] | None = False,\n",
      " |      handle_validation_error: bool | str | collections.abc.Callable[[pydantic_core._pydantic_core.ValidationError | pydantic.v1.error_wrappers.ValidationError], str] | None = False,\n",
      " |      response_format: Literal['content', 'content_and_artifact'] = 'content',\n",
      " |      func: collections.abc.Callable[..., typing.Any] | None = None,\n",
      " |      coroutine: collections.abc.Callable[..., collections.abc.Awaitable[typing.Any]] | None = None\n",
      " |  ) -> None\n",
      " |\n",
      " |  Tool that can operate on any number of inputs.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      StructuredTool\n",
      " |      langchain_core.tools.base.BaseTool\n",
      " |      langchain_core.runnables.base.RunnableSerializable[Union[str, dict, ToolCall], Any]\n",
      " |      langchain_core.runnables.base.RunnableSerializable\n",
      " |      langchain_core.load.serializable.Serializable\n",
      " |      pydantic.main.BaseModel\n",
      " |      langchain_core.runnables.base.Runnable\n",
      " |      abc.ABC\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  async ainvoke(\n",
      " |      self,\n",
      " |      input: 'str | dict | ToolCall',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'Any'\n",
      " |      Transform a single input into an output.\n",
      " |\n",
      " |      Args:\n",
      " |          input: The input to the `Runnable`.\n",
      " |          config: A config to use when invoking the `Runnable`.\n",
      " |              The config supports standard keys like `'tags'`, `'metadata'` for\n",
      " |              tracing purposes, `'max_concurrency'` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the `RunnableConfig`\n",
      " |              for more details.\n",
      " |\n",
      " |      Returns:\n",
      " |          The output of the `Runnable`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |\n",
      " |  from_function(\n",
      " |      func: 'Callable | None' = None,\n",
      " |      coroutine: 'Callable[..., Awaitable[Any]] | None' = None,\n",
      " |      name: 'str | None' = None,\n",
      " |      description: 'str | None' = None,\n",
      " |      return_direct: 'bool' = False,\n",
      " |      args_schema: 'ArgsSchema | None' = None,\n",
      " |      infer_schema: 'bool' = True,\n",
      " |      *,\n",
      " |      response_format: \"Literal['content', 'content_and_artifact']\" = 'content',\n",
      " |      parse_docstring: 'bool' = False,\n",
      " |      error_on_invalid_docstring: 'bool' = False,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'StructuredTool'\n",
      " |      Create tool from a given function.\n",
      " |\n",
      " |      A classmethod that helps to create a tool from a function.\n",
      " |\n",
      " |      Args:\n",
      " |          func: The function from which to create a tool.\n",
      " |          coroutine: The async function from which to create a tool.\n",
      " |          name: The name of the tool. Defaults to the function name.\n",
      " |          description: The description of the tool.\n",
      " |              Defaults to the function docstring.\n",
      " |          return_direct: Whether to return the result directly or as a callback.\n",
      " |          args_schema: The schema of the tool's input arguments.\n",
      " |          infer_schema: Whether to infer the schema from the function's signature.\n",
      " |          response_format: The tool response format.\n",
      " |\n",
      " |              If `\"content\"` then the output of the tool is interpreted as the\n",
      " |              contents of a `ToolMessage`. If `\"content_and_artifact\"` then the output\n",
      " |              is expected to be a two-tuple corresponding to the `(content, artifact)`\n",
      " |              of a `ToolMessage`.\n",
      " |          parse_docstring: If `infer_schema` and `parse_docstring`, will attempt\n",
      " |              to parse parameter descriptions from Google Style function docstrings.\n",
      " |          error_on_invalid_docstring: if `parse_docstring` is provided, configure\n",
      " |              whether to raise `ValueError` on invalid Google Style docstrings.\n",
      " |          **kwargs: Additional arguments to pass to the tool\n",
      " |\n",
      " |      Returns:\n",
      " |          The tool.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If the function is not provided.\n",
      " |          ValueError: If the function does not have a docstring and description\n",
      " |              is not provided.\n",
      " |          TypeError: If the `args_schema` is not a `BaseModel` or dict.\n",
      " |\n",
      " |      Examples:\n",
      " |          ```python\n",
      " |          def add(a: int, b: int) -> int:\n",
      " |              \"\"\"Add two numbers\"\"\"\n",
      " |              return a + b\n",
      " |          tool = StructuredTool.from_function(add)\n",
      " |          tool.run(1, 2) # 3\n",
      " |\n",
      " |          ```\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'args_schema': 'Annotated[ArgsSchema, SkipValidatio...\n",
      " |\n",
      " |  __class_vars__ = set()\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  __private_attributes__ = {}\n",
      " |\n",
      " |  __pydantic_complete__ = True\n",
      " |\n",
      " |  __pydantic_computed_fields__ = {}\n",
      " |\n",
      " |  __pydantic_core_schema__ = {'cls': <class 'langchain_core.tools.struct...\n",
      " |\n",
      " |  __pydantic_custom_init__ = True\n",
      " |\n",
      " |  __pydantic_decorators__ = DecoratorInfos(validators={}, field_validato...\n",
      " |\n",
      " |  __pydantic_fields__ = {'args_schema': FieldInfo(annotation=Union[type[...\n",
      " |\n",
      " |  __pydantic_generic_metadata__ = {'args': (), 'origin': None, 'paramete...\n",
      " |\n",
      " |  __pydantic_parent_namespace__ = None\n",
      " |\n",
      " |  __pydantic_post_init__ = None\n",
      " |\n",
      " |  __pydantic_serializer__ = SchemaSerializer(serializer=Model(\n",
      " |      Model...\n",
      " |\n",
      " |  __pydantic_setattr_handlers__ = {}\n",
      " |\n",
      " |  __pydantic_validator__ = SchemaValidator(title=\"StructuredTool\", valid...\n",
      " |\n",
      " |  __signature__ = <Signature (*, name: str, description: str = '',...bc....\n",
      " |\n",
      " |  model_config = {'arbitrary_types_allowed': True, 'extra': 'ignore', 'p...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.tools.base.BaseTool:\n",
      " |\n",
      " |  __init__(self, **kwargs: 'Any') -> 'None'\n",
      " |      Initialize the tool.\n",
      " |\n",
      " |      Raises:\n",
      " |          TypeError: If `args_schema` is not a subclass of pydantic `BaseModel` or\n",
      " |              `dict`.\n",
      " |\n",
      " |  async arun(\n",
      " |      self,\n",
      " |      tool_input: 'str | dict',\n",
      " |      verbose: 'bool | None' = None,\n",
      " |      start_color: 'str | None' = 'green',\n",
      " |      color: 'str | None' = 'green',\n",
      " |      callbacks: 'Callbacks' = None,\n",
      " |      *,\n",
      " |      tags: 'list[str] | None' = None,\n",
      " |      metadata: 'dict[str, Any] | None' = None,\n",
      " |      run_name: 'str | None' = None,\n",
      " |      run_id: 'uuid.UUID | None' = None,\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      tool_call_id: 'str | None' = None,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'Any'\n",
      " |      Run the tool asynchronously.\n",
      " |\n",
      " |      Args:\n",
      " |          tool_input: The input to the tool.\n",
      " |          verbose: Whether to log the tool's progress.\n",
      " |          start_color: The color to use when starting the tool.\n",
      " |          color: The color to use when ending the tool.\n",
      " |          callbacks: Callbacks to be called during tool execution.\n",
      " |          tags: Optional list of tags associated with the tool.\n",
      " |          metadata: Optional metadata associated with the tool.\n",
      " |          run_name: The name of the run.\n",
      " |          run_id: The id of the run.\n",
      " |          config: The configuration for the tool.\n",
      " |          tool_call_id: The id of the tool call.\n",
      " |          **kwargs: Keyword arguments to be passed to tool callbacks\n",
      " |\n",
      " |      Returns:\n",
      " |          The output of the tool.\n",
      " |\n",
      " |      Raises:\n",
      " |          ToolException: If an error occurs during tool execution.\n",
      " |\n",
      " |  get_input_schema(self, config: 'RunnableConfig | None' = None) -> 'type[BaseModel]'\n",
      " |      The tool's input schema.\n",
      " |\n",
      " |      Args:\n",
      " |          config: The configuration for the tool.\n",
      " |\n",
      " |      Returns:\n",
      " |          The input schema for the tool.\n",
      " |\n",
      " |  invoke(\n",
      " |      self,\n",
      " |      input: 'str | dict | ToolCall',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'Any'\n",
      " |      Transform a single input into an output.\n",
      " |\n",
      " |      Args:\n",
      " |          input: The input to the `Runnable`.\n",
      " |          config: A config to use when invoking the `Runnable`.\n",
      " |              The config supports standard keys like `'tags'`, `'metadata'` for\n",
      " |              tracing purposes, `'max_concurrency'` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the `RunnableConfig`\n",
      " |              for more details.\n",
      " |\n",
      " |      Returns:\n",
      " |          The output of the `Runnable`.\n",
      " |\n",
      " |  run(\n",
      " |      self,\n",
      " |      tool_input: 'str | dict[str, Any]',\n",
      " |      verbose: 'bool | None' = None,\n",
      " |      start_color: 'str | None' = 'green',\n",
      " |      color: 'str | None' = 'green',\n",
      " |      callbacks: 'Callbacks' = None,\n",
      " |      *,\n",
      " |      tags: 'list[str] | None' = None,\n",
      " |      metadata: 'dict[str, Any] | None' = None,\n",
      " |      run_name: 'str | None' = None,\n",
      " |      run_id: 'uuid.UUID | None' = None,\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      tool_call_id: 'str | None' = None,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'Any'\n",
      " |      Run the tool.\n",
      " |\n",
      " |      Args:\n",
      " |          tool_input: The input to the tool.\n",
      " |          verbose: Whether to log the tool's progress.\n",
      " |          start_color: The color to use when starting the tool.\n",
      " |          color: The color to use when ending the tool.\n",
      " |          callbacks: Callbacks to be called during tool execution.\n",
      " |          tags: Optional list of tags associated with the tool.\n",
      " |          metadata: Optional metadata associated with the tool.\n",
      " |          run_name: The name of the run.\n",
      " |          run_id: The id of the run.\n",
      " |          config: The configuration for the tool.\n",
      " |          tool_call_id: The id of the tool call.\n",
      " |          **kwargs: Keyword arguments to be passed to tool callbacks (event handler)\n",
      " |\n",
      " |      Returns:\n",
      " |          The output of the tool.\n",
      " |\n",
      " |      Raises:\n",
      " |          ToolException: If an error occurs during tool execution.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.tools.base.BaseTool:\n",
      " |\n",
      " |  __init_subclass__(**kwargs: 'Any') -> 'None'\n",
      " |      Validate the tool class definition during subclass creation.\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: Additional keyword arguments passed to the parent class.\n",
      " |\n",
      " |      Raises:\n",
      " |          SchemaAnnotationError: If `args_schema` has incorrect type annotation.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.tools.base.BaseTool:\n",
      " |\n",
      " |  args\n",
      " |      Get the tool's input arguments schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          `dict` containing the tool's argument properties.\n",
      " |\n",
      " |  is_single_input\n",
      " |      Check if the tool accepts only a single input argument.\n",
      " |\n",
      " |      Returns:\n",
      " |          `True` if the tool has only one input argument, `False` otherwise.\n",
      " |\n",
      " |  tool_call_schema\n",
      " |      Get the schema for tool calls, excluding injected arguments.\n",
      " |\n",
      " |      Returns:\n",
      " |          The schema that should be used for tool calls from language models.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.runnables.base.RunnableSerializable:\n",
      " |\n",
      " |  configurable_alternatives(\n",
      " |      self,\n",
      " |      which: 'ConfigurableField',\n",
      " |      *,\n",
      " |      default_key: 'str' = 'default',\n",
      " |      prefix_keys: 'bool' = False,\n",
      " |      **kwargs: 'Runnable[Input, Output] | Callable[[], Runnable[Input, Output]]'\n",
      " |  ) -> 'RunnableSerializable[Input, Output]'\n",
      " |      Configure alternatives for `Runnable` objects that can be set at runtime.\n",
      " |\n",
      " |      Args:\n",
      " |          which: The `ConfigurableField` instance that will be used to select the\n",
      " |              alternative.\n",
      " |          default_key: The default key to use if no alternative is selected.\n",
      " |          prefix_keys: Whether to prefix the keys with the `ConfigurableField` id.\n",
      " |          **kwargs: A dictionary of keys to `Runnable` instances or callables that\n",
      " |              return `Runnable` instances.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the alternatives configured.\n",
      " |\n",
      " |      ```python\n",
      " |      from langchain_anthropic import ChatAnthropic\n",
      " |      from langchain_core.runnables.utils import ConfigurableField\n",
      " |      from langchain_openai import ChatOpenAI\n",
      " |\n",
      " |      model = ChatAnthropic(\n",
      " |          model_name=\"claude-sonnet-4-5-20250929\"\n",
      " |      ).configurable_alternatives(\n",
      " |          ConfigurableField(id=\"llm\"),\n",
      " |          default_key=\"anthropic\",\n",
      " |          openai=ChatOpenAI(),\n",
      " |      )\n",
      " |\n",
      " |      # uses the default model ChatAnthropic\n",
      " |      print(model.invoke(\"which organization created you?\").content)\n",
      " |\n",
      " |      # uses ChatOpenAI\n",
      " |      print(\n",
      " |          model.with_config(configurable={\"llm\": \"openai\"})\n",
      " |          .invoke(\"which organization created you?\")\n",
      " |          .content\n",
      " |      )\n",
      " |      ```\n",
      " |\n",
      " |  configurable_fields(self, **kwargs: 'AnyConfigurableField') -> 'RunnableSerializable[Input, Output]'\n",
      " |      Configure particular `Runnable` fields at runtime.\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: A dictionary of `ConfigurableField` instances to configure.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValueError: If a configuration key is not found in the `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the fields configured.\n",
      " |\n",
      " |      ```python\n",
      " |      from langchain_core.runnables import ConfigurableField\n",
      " |      from langchain_openai import ChatOpenAI\n",
      " |\n",
      " |      model = ChatOpenAI(max_tokens=20).configurable_fields(\n",
      " |          max_tokens=ConfigurableField(\n",
      " |              id=\"output_token_number\",\n",
      " |              name=\"Max tokens in the output\",\n",
      " |              description=\"The maximum number of tokens in the output\",\n",
      " |          )\n",
      " |      )\n",
      " |\n",
      " |      # max_tokens = 20\n",
      " |      print(\"max_tokens_20: \", model.invoke(\"tell me something about chess\").content)\n",
      " |\n",
      " |      # max_tokens = 200\n",
      " |      print(\n",
      " |          \"max_tokens_200: \",\n",
      " |          model.with_config(configurable={\"output_token_number\": 200})\n",
      " |          .invoke(\"tell me something about chess\")\n",
      " |          .content,\n",
      " |      )\n",
      " |      ```\n",
      " |\n",
      " |  to_json(self) -> 'SerializedConstructor | SerializedNotImplemented'\n",
      " |      Serialize the `Runnable` to JSON.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON-serializable representation of the `Runnable`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from langchain_core.runnables.base.RunnableSerializable:\n",
      " |\n",
      " |  __orig_bases__ = (<class 'langchain_core.load.serializable.Serializabl...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |\n",
      " |  __repr_args__(self) -> Any\n",
      " |\n",
      " |  to_json_not_implemented(self) -> langchain_core.load.serializable.SerializedNotImplemented\n",
      " |      Serialize a \"not implemented\" object.\n",
      " |\n",
      " |      Returns:\n",
      " |          `SerializedNotImplemented`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.load.serializable.Serializable:\n",
      " |\n",
      " |  get_lc_namespace() -> list[str]\n",
      " |      Get the namespace of the LangChain object.\n",
      " |\n",
      " |      For example, if the class is `langchain.llms.openai.OpenAI`, then the\n",
      " |      namespace is `[\"langchain\", \"llms\", \"openai\"]`\n",
      " |\n",
      " |      Returns:\n",
      " |          The namespace.\n",
      " |\n",
      " |  is_lc_serializable() -> bool\n",
      " |      Is this class serializable?\n",
      " |\n",
      " |      By design, even if a class inherits from `Serializable`, it is not serializable\n",
      " |      by default. This is to prevent accidental serialization of objects that should\n",
      " |      not be serialized.\n",
      " |\n",
      " |      Returns:\n",
      " |          Whether the class is serializable. Default is `False`.\n",
      " |\n",
      " |  lc_id() -> list[str]\n",
      " |      Return a unique identifier for this class for serialization purposes.\n",
      " |\n",
      " |      The unique identifier is a list of strings that describes the path\n",
      " |      to the object.\n",
      " |\n",
      " |      For example, for the class `langchain.llms.openai.OpenAI`, the id is\n",
      " |      `[\"langchain\", \"llms\", \"openai\", \"OpenAI\"]`.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.load.serializable.Serializable:\n",
      " |\n",
      " |  lc_attributes\n",
      " |      List of attribute names that should be included in the serialized kwargs.\n",
      " |\n",
      " |      These attributes must be accepted by the constructor.\n",
      " |\n",
      " |      Default is an empty dictionary.\n",
      " |\n",
      " |  lc_secrets\n",
      " |      A map of constructor argument names to secret ids.\n",
      " |\n",
      " |      For example, `{\"openai_api_key\": \"OPENAI_API_KEY\"}`\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.load.serializable.Serializable:\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __copy__(self) -> 'Self'\n",
      " |      Returns a shallow copy of the model.\n",
      " |\n",
      " |  __deepcopy__(self, memo: 'dict[int, Any] | None' = None) -> 'Self'\n",
      " |      Returns a deep copy of the model.\n",
      " |\n",
      " |  __delattr__(self, item: 'str') -> 'Any'\n",
      " |      Implement delattr(self, name).\n",
      " |\n",
      " |  __eq__(self, other: 'Any') -> 'bool'\n",
      " |      Return self==value.\n",
      " |\n",
      " |  __getattr__(self, item: 'str') -> 'Any'\n",
      " |\n",
      " |  __getstate__(self) -> 'dict[Any, Any]'\n",
      " |      Helper for pickle.\n",
      " |\n",
      " |  __iter__(self) -> 'TupleGenerator'\n",
      " |      So `dict(model)` works.\n",
      " |\n",
      " |  __pretty__(self, fmt: 'Callable[[Any], Any]', **kwargs: 'Any') -> 'Generator[Any]' from pydantic._internal._repr.Representation\n",
      " |      Used by devtools (https://python-devtools.helpmanual.io/) to pretty print objects.\n",
      " |\n",
      " |  __replace__(self, **changes: 'Any') -> 'Self'\n",
      " |      # Because we make use of `@dataclass_transform()`, `__replace__` is already synthesized by\n",
      " |      # type checkers, so we define the implementation in this `if not TYPE_CHECKING:` block:\n",
      " |\n",
      " |  __repr__(self) -> 'str'\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __repr_name__(self) -> 'str' from pydantic._internal._repr.Representation\n",
      " |      Name of the instance's class, used in __repr__.\n",
      " |\n",
      " |  __repr_recursion__(self, object: 'Any') -> 'str' from pydantic._internal._repr.Representation\n",
      " |      Returns the string representation of a recursive object.\n",
      " |\n",
      " |  __repr_str__(self, join_str: 'str') -> 'str' from pydantic._internal._repr.Representation\n",
      " |\n",
      " |  __rich_repr__(self) -> 'RichReprResult' from pydantic._internal._repr.Representation\n",
      " |      Used by Rich (https://rich.readthedocs.io/en/stable/pretty.html) to pretty print objects.\n",
      " |\n",
      " |  __setattr__(self, name: 'str', value: 'Any') -> 'None'\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  __setstate__(self, state: 'dict[Any, Any]') -> 'None'\n",
      " |\n",
      " |  __str__(self) -> 'str'\n",
      " |      Return str(self).\n",
      " |\n",
      " |  copy(\n",
      " |      self,\n",
      " |      *,\n",
      " |      include: 'AbstractSetIntStr | MappingIntStrAny | None' = None,\n",
      " |      exclude: 'AbstractSetIntStr | MappingIntStrAny | None' = None,\n",
      " |      update: 'Dict[str, Any] | None' = None,\n",
      " |      deep: 'bool' = False\n",
      " |  ) -> 'Self'\n",
      " |      Returns a copy of the model.\n",
      " |\n",
      " |      !!! warning \"Deprecated\"\n",
      " |          This method is now deprecated; use `model_copy` instead.\n",
      " |\n",
      " |      If you need `include` or `exclude`, use:\n",
      " |\n",
      " |      ```python {test=\"skip\" lint=\"skip\"}\n",
      " |      data = self.model_dump(include=include, exclude=exclude, round_trip=True)\n",
      " |      data = {**data, **(update or {})}\n",
      " |      copied = self.model_validate(data)\n",
      " |      ```\n",
      " |\n",
      " |      Args:\n",
      " |          include: Optional set or mapping specifying which fields to include in the copied model.\n",
      " |          exclude: Optional set or mapping specifying which fields to exclude in the copied model.\n",
      " |          update: Optional dictionary of field-value pairs to override field values in the copied model.\n",
      " |          deep: If True, the values of fields that are Pydantic models will be deep-copied.\n",
      " |\n",
      " |      Returns:\n",
      " |          A copy of the model with included, excluded and updated fields as specified.\n",
      " |\n",
      " |  dict(\n",
      " |      self,\n",
      " |      *,\n",
      " |      include: 'IncEx | None' = None,\n",
      " |      exclude: 'IncEx | None' = None,\n",
      " |      by_alias: 'bool' = False,\n",
      " |      exclude_unset: 'bool' = False,\n",
      " |      exclude_defaults: 'bool' = False,\n",
      " |      exclude_none: 'bool' = False\n",
      " |  ) -> 'Dict[str, Any]'\n",
      " |\n",
      " |  json(\n",
      " |      self,\n",
      " |      *,\n",
      " |      include: 'IncEx | None' = None,\n",
      " |      exclude: 'IncEx | None' = None,\n",
      " |      by_alias: 'bool' = False,\n",
      " |      exclude_unset: 'bool' = False,\n",
      " |      exclude_defaults: 'bool' = False,\n",
      " |      exclude_none: 'bool' = False,\n",
      " |      encoder: 'Callable[[Any], Any] | None' = PydanticUndefined,\n",
      " |      models_as_dict: 'bool' = PydanticUndefined,\n",
      " |      **dumps_kwargs: 'Any'\n",
      " |  ) -> 'str'\n",
      " |\n",
      " |  model_copy(\n",
      " |      self,\n",
      " |      *,\n",
      " |      update: 'Mapping[str, Any] | None' = None,\n",
      " |      deep: 'bool' = False\n",
      " |  ) -> 'Self'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_copy`](../concepts/models.md#model-copy)\n",
      " |\n",
      " |      Returns a copy of the model.\n",
      " |\n",
      " |      !!! note\n",
      " |          The underlying instance's [`__dict__`][object.__dict__] attribute is copied. This\n",
      " |          might have unexpected side effects if you store anything in it, on top of the model\n",
      " |          fields (e.g. the value of [cached properties][functools.cached_property]).\n",
      " |\n",
      " |      Args:\n",
      " |          update: Values to change/add in the new model. Note: the data is not validated\n",
      " |              before creating the new model. You should trust this data.\n",
      " |          deep: Set to `True` to make a deep copy of the model.\n",
      " |\n",
      " |      Returns:\n",
      " |          New model instance.\n",
      " |\n",
      " |  model_dump(\n",
      " |      self,\n",
      " |      *,\n",
      " |      mode: \"Literal['json', 'python'] | str\" = 'python',\n",
      " |      include: 'IncEx | None' = None,\n",
      " |      exclude: 'IncEx | None' = None,\n",
      " |      context: 'Any | None' = None,\n",
      " |      by_alias: 'bool | None' = None,\n",
      " |      exclude_unset: 'bool' = False,\n",
      " |      exclude_defaults: 'bool' = False,\n",
      " |      exclude_none: 'bool' = False,\n",
      " |      exclude_computed_fields: 'bool' = False,\n",
      " |      round_trip: 'bool' = False,\n",
      " |      warnings: \"bool | Literal['none', 'warn', 'error']\" = True,\n",
      " |      fallback: 'Callable[[Any], Any] | None' = None,\n",
      " |      serialize_as_any: 'bool' = False\n",
      " |  ) -> 'dict[str, Any]'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump`](../concepts/serialization.md#python-mode)\n",
      " |\n",
      " |      Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\n",
      " |\n",
      " |      Args:\n",
      " |          mode: The mode in which `to_python` should run.\n",
      " |              If mode is 'json', the output will only contain JSON serializable types.\n",
      " |              If mode is 'python', the output may contain non-JSON-serializable Python objects.\n",
      " |          include: A set of fields to include in the output.\n",
      " |          exclude: A set of fields to exclude from the output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to use the field's alias in the dictionary key if defined.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          exclude_computed_fields: Whether to exclude computed fields.\n",
      " |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      " |              `round_trip` parameter instead.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |\n",
      " |      Returns:\n",
      " |          A dictionary representation of the model.\n",
      " |\n",
      " |  model_dump_json(\n",
      " |      self,\n",
      " |      *,\n",
      " |      indent: 'int | None' = None,\n",
      " |      ensure_ascii: 'bool' = False,\n",
      " |      include: 'IncEx | None' = None,\n",
      " |      exclude: 'IncEx | None' = None,\n",
      " |      context: 'Any | None' = None,\n",
      " |      by_alias: 'bool | None' = None,\n",
      " |      exclude_unset: 'bool' = False,\n",
      " |      exclude_defaults: 'bool' = False,\n",
      " |      exclude_none: 'bool' = False,\n",
      " |      exclude_computed_fields: 'bool' = False,\n",
      " |      round_trip: 'bool' = False,\n",
      " |      warnings: \"bool | Literal['none', 'warn', 'error']\" = True,\n",
      " |      fallback: 'Callable[[Any], Any] | None' = None,\n",
      " |      serialize_as_any: 'bool' = False\n",
      " |  ) -> 'str'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [`model_dump_json`](../concepts/serialization.md#json-mode)\n",
      " |\n",
      " |      Generates a JSON representation of the model using Pydantic's `to_json` method.\n",
      " |\n",
      " |      Args:\n",
      " |          indent: Indentation to use in the JSON output. If None is passed, the output will be compact.\n",
      " |          ensure_ascii: If `True`, the output is guaranteed to have all incoming non-ASCII characters escaped.\n",
      " |              If `False` (the default), these characters will be output as-is.\n",
      " |          include: Field(s) to include in the JSON output.\n",
      " |          exclude: Field(s) to exclude from the JSON output.\n",
      " |          context: Additional context to pass to the serializer.\n",
      " |          by_alias: Whether to serialize using field aliases.\n",
      " |          exclude_unset: Whether to exclude fields that have not been explicitly set.\n",
      " |          exclude_defaults: Whether to exclude fields that are set to their default value.\n",
      " |          exclude_none: Whether to exclude fields that have a value of `None`.\n",
      " |          exclude_computed_fields: Whether to exclude computed fields.\n",
      " |              While this can be useful for round-tripping, it is usually recommended to use the dedicated\n",
      " |              `round_trip` parameter instead.\n",
      " |          round_trip: If True, dumped values should be valid as input for non-idempotent types such as Json[T].\n",
      " |          warnings: How to handle serialization errors. False/\"none\" ignores them, True/\"warn\" logs errors,\n",
      " |              \"error\" raises a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError].\n",
      " |          fallback: A function to call when an unknown value is encountered. If not provided,\n",
      " |              a [`PydanticSerializationError`][pydantic_core.PydanticSerializationError] error is raised.\n",
      " |          serialize_as_any: Whether to serialize fields with duck-typing serialization behavior.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON string representation of the model.\n",
      " |\n",
      " |  model_post_init(self, context: 'Any', /) -> 'None'\n",
      " |      Override this method to perform additional initialization after `__init__` and `model_construct`.\n",
      " |      This is useful if you want to do some validation that requires the entire model to be initialized.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __class_getitem__(typevar_values: 'type[Any] | tuple[type[Any], ...]') -> 'type[BaseModel] | _forward_ref.PydanticRecursiveRef'\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __get_pydantic_core_schema__(\n",
      " |      source: 'type[BaseModel]',\n",
      " |      handler: 'GetCoreSchemaHandler',\n",
      " |      /\n",
      " |  ) -> 'CoreSchema'\n",
      " |\n",
      " |  __get_pydantic_json_schema__(\n",
      " |      core_schema: 'CoreSchema',\n",
      " |      handler: 'GetJsonSchemaHandler',\n",
      " |      /\n",
      " |  ) -> 'JsonSchemaValue'\n",
      " |      Hook into generating the model's JSON schema.\n",
      " |\n",
      " |      Args:\n",
      " |          core_schema: A `pydantic-core` CoreSchema.\n",
      " |              You can ignore this argument and call the handler with a new CoreSchema,\n",
      " |              wrap this CoreSchema (`{'type': 'nullable', 'schema': current_schema}`),\n",
      " |              or just call the handler with the original schema.\n",
      " |          handler: Call into Pydantic's internal JSON schema generation.\n",
      " |              This will raise a `pydantic.errors.PydanticInvalidForJsonSchema` if JSON schema\n",
      " |              generation fails.\n",
      " |              Since this gets called by `BaseModel.model_json_schema` you can override the\n",
      " |              `schema_generator` argument to that function to change JSON schema generation globally\n",
      " |              for a type.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON schema, as a Python object.\n",
      " |\n",
      " |  __pydantic_init_subclass__(**kwargs: 'Any') -> 'None'\n",
      " |      This is intended to behave just like `__init_subclass__`, but is called by `ModelMetaclass`\n",
      " |      only after basic class initialization is complete. In particular, attributes like `model_fields` will\n",
      " |      be present when this is called, but forward annotations are not guaranteed to be resolved yet,\n",
      " |      meaning that creating an instance of the class may fail.\n",
      " |\n",
      " |      This is necessary because `__init_subclass__` will always be called by `type.__new__`,\n",
      " |      and it would require a prohibitively large refactor to the `ModelMetaclass` to ensure that\n",
      " |      `type.__new__` was called in such a manner that the class would already be sufficiently initialized.\n",
      " |\n",
      " |      This will receive the same `kwargs` that would be passed to the standard `__init_subclass__`, namely,\n",
      " |      any kwargs passed to the class definition that aren't used internally by Pydantic.\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: Any keyword arguments passed to the class definition that aren't used internally\n",
      " |              by Pydantic.\n",
      " |\n",
      " |      Note:\n",
      " |          You may want to override [`__pydantic_on_complete__()`][pydantic.main.BaseModel.__pydantic_on_complete__]\n",
      " |          instead, which is called once the class and its fields are fully initialized and ready for validation.\n",
      " |\n",
      " |  __pydantic_on_complete__() -> 'None'\n",
      " |      This is called once the class and its fields are fully initialized and ready to be used.\n",
      " |\n",
      " |      This typically happens when the class is created (just before\n",
      " |      [`__pydantic_init_subclass__()`][pydantic.main.BaseModel.__pydantic_init_subclass__] is called on the superclass),\n",
      " |      except when forward annotations are used that could not immediately be resolved.\n",
      " |      In that case, it will be called later, when the model is rebuilt automatically or explicitly using\n",
      " |      [`model_rebuild()`][pydantic.main.BaseModel.model_rebuild].\n",
      " |\n",
      " |  construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      " |\n",
      " |  from_orm(obj: 'Any') -> 'Self'\n",
      " |\n",
      " |  model_construct(_fields_set: 'set[str] | None' = None, **values: 'Any') -> 'Self'\n",
      " |      Creates a new instance of the `Model` class with validated data.\n",
      " |\n",
      " |      Creates a new model setting `__dict__` and `__pydantic_fields_set__` from trusted or pre-validated data.\n",
      " |      Default values are respected, but no other validation is performed.\n",
      " |\n",
      " |      !!! note\n",
      " |          `model_construct()` generally respects the `model_config.extra` setting on the provided model.\n",
      " |          That is, if `model_config.extra == 'allow'`, then all extra passed values are added to the model instance's `__dict__`\n",
      " |          and `__pydantic_extra__` fields. If `model_config.extra == 'ignore'` (the default), then all extra passed values are ignored.\n",
      " |          Because no validation is performed with a call to `model_construct()`, having `model_config.extra == 'forbid'` does not result in\n",
      " |          an error if extra values are passed, but they will be ignored.\n",
      " |\n",
      " |      Args:\n",
      " |          _fields_set: A set of field names that were originally explicitly set during instantiation. If provided,\n",
      " |              this is directly used for the [`model_fields_set`][pydantic.BaseModel.model_fields_set] attribute.\n",
      " |              Otherwise, the field names from the `values` argument will be used.\n",
      " |          values: Trusted or pre-validated data dictionary.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new instance of the `Model` class with validated data.\n",
      " |\n",
      " |  model_json_schema(\n",
      " |      by_alias: 'bool' = True,\n",
      " |      ref_template: 'str' = '#/$defs/{model}',\n",
      " |      schema_generator: 'type[GenerateJsonSchema]' = <class 'pydantic.json_schema.GenerateJsonSchema'>,\n",
      " |      mode: 'JsonSchemaMode' = 'validation',\n",
      " |      *,\n",
      " |      union_format: \"Literal['any_of', 'primitive_type_array']\" = 'any_of'\n",
      " |  ) -> 'dict[str, Any]'\n",
      " |      Generates a JSON schema for a model class.\n",
      " |\n",
      " |      Args:\n",
      " |          by_alias: Whether to use attribute aliases or not.\n",
      " |          ref_template: The reference template.\n",
      " |          union_format: The format to use when combining schemas from unions together. Can be one of:\n",
      " |\n",
      " |              - `'any_of'`: Use the [`anyOf`](https://json-schema.org/understanding-json-schema/reference/combining#anyOf)\n",
      " |              keyword to combine schemas (the default).\n",
      " |              - `'primitive_type_array'`: Use the [`type`](https://json-schema.org/understanding-json-schema/reference/type)\n",
      " |              keyword as an array of strings, containing each type of the combination. If any of the schemas is not a primitive\n",
      " |              type (`string`, `boolean`, `null`, `integer` or `number`) or contains constraints/metadata, falls back to\n",
      " |              `any_of`.\n",
      " |          schema_generator: To override the logic used to generate the JSON schema, as a subclass of\n",
      " |              `GenerateJsonSchema` with your desired modifications\n",
      " |          mode: The mode in which to generate the schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          The JSON schema for the given model class.\n",
      " |\n",
      " |  model_parametrized_name(params: 'tuple[type[Any], ...]') -> 'str'\n",
      " |      Compute the class name for parametrizations of generic classes.\n",
      " |\n",
      " |      This method can be overridden to achieve a custom naming scheme for generic BaseModels.\n",
      " |\n",
      " |      Args:\n",
      " |          params: Tuple of types of the class. Given a generic class\n",
      " |              `Model` with 2 type variables and a concrete model `Model[str, int]`,\n",
      " |              the value `(str, int)` would be passed to `params`.\n",
      " |\n",
      " |      Returns:\n",
      " |          String representing the new class where `params` are passed to `cls` as type variables.\n",
      " |\n",
      " |      Raises:\n",
      " |          TypeError: Raised when trying to generate concrete names for non-generic models.\n",
      " |\n",
      " |  model_rebuild(\n",
      " |      *,\n",
      " |      force: 'bool' = False,\n",
      " |      raise_errors: 'bool' = True,\n",
      " |      _parent_namespace_depth: 'int' = 2,\n",
      " |      _types_namespace: 'MappingNamespace | None' = None\n",
      " |  ) -> 'bool | None'\n",
      " |      Try to rebuild the pydantic-core schema for the model.\n",
      " |\n",
      " |      This may be necessary when one of the annotations is a ForwardRef which could not be resolved during\n",
      " |      the initial attempt to build the schema, and automatic rebuilding fails.\n",
      " |\n",
      " |      Args:\n",
      " |          force: Whether to force the rebuilding of the model schema, defaults to `False`.\n",
      " |          raise_errors: Whether to raise errors, defaults to `True`.\n",
      " |          _parent_namespace_depth: The depth level of the parent namespace, defaults to 2.\n",
      " |          _types_namespace: The types namespace, defaults to `None`.\n",
      " |\n",
      " |      Returns:\n",
      " |          Returns `None` if the schema is already \"complete\" and rebuilding was not required.\n",
      " |          If rebuilding _was_ required, returns `True` if rebuilding was successful, otherwise `False`.\n",
      " |\n",
      " |  model_validate(\n",
      " |      obj: 'Any',\n",
      " |      *,\n",
      " |      strict: 'bool | None' = None,\n",
      " |      extra: 'ExtraValues | None' = None,\n",
      " |      from_attributes: 'bool | None' = None,\n",
      " |      context: 'Any | None' = None,\n",
      " |      by_alias: 'bool | None' = None,\n",
      " |      by_name: 'bool | None' = None\n",
      " |  ) -> 'Self'\n",
      " |      Validate a pydantic model instance.\n",
      " |\n",
      " |      Args:\n",
      " |          obj: The object to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          from_attributes: Whether to extract data from object attributes.\n",
      " |          context: Additional context to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValidationError: If the object could not be validated.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated model instance.\n",
      " |\n",
      " |  model_validate_json(\n",
      " |      json_data: 'str | bytes | bytearray',\n",
      " |      *,\n",
      " |      strict: 'bool | None' = None,\n",
      " |      extra: 'ExtraValues | None' = None,\n",
      " |      context: 'Any | None' = None,\n",
      " |      by_alias: 'bool | None' = None,\n",
      " |      by_name: 'bool | None' = None\n",
      " |  ) -> 'Self'\n",
      " |      !!! abstract \"Usage Documentation\"\n",
      " |          [JSON Parsing](../concepts/json.md#json-parsing)\n",
      " |\n",
      " |      Validate the given JSON data against the Pydantic model.\n",
      " |\n",
      " |      Args:\n",
      " |          json_data: The JSON data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |\n",
      " |      Raises:\n",
      " |          ValidationError: If `json_data` is not a JSON string or the object could not be validated.\n",
      " |\n",
      " |  model_validate_strings(\n",
      " |      obj: 'Any',\n",
      " |      *,\n",
      " |      strict: 'bool | None' = None,\n",
      " |      extra: 'ExtraValues | None' = None,\n",
      " |      context: 'Any | None' = None,\n",
      " |      by_alias: 'bool | None' = None,\n",
      " |      by_name: 'bool | None' = None\n",
      " |  ) -> 'Self'\n",
      " |      Validate the given object with string data against the Pydantic model.\n",
      " |\n",
      " |      Args:\n",
      " |          obj: The object containing string data to validate.\n",
      " |          strict: Whether to enforce types strictly.\n",
      " |          extra: Whether to ignore, allow, or forbid extra data during model validation.\n",
      " |              See the [`extra` configuration value][pydantic.ConfigDict.extra] for details.\n",
      " |          context: Extra variables to pass to the validator.\n",
      " |          by_alias: Whether to use the field's alias when validating against the provided input data.\n",
      " |          by_name: Whether to use the field's name when validating against the provided input data.\n",
      " |\n",
      " |      Returns:\n",
      " |          The validated Pydantic model.\n",
      " |\n",
      " |  parse_file(\n",
      " |      path: 'str | Path',\n",
      " |      *,\n",
      " |      content_type: 'str | None' = None,\n",
      " |      encoding: 'str' = 'utf8',\n",
      " |      proto: 'DeprecatedParseProtocol | None' = None,\n",
      " |      allow_pickle: 'bool' = False\n",
      " |  ) -> 'Self'\n",
      " |\n",
      " |  parse_obj(obj: 'Any') -> 'Self'\n",
      " |\n",
      " |  parse_raw(\n",
      " |      b: 'str | bytes',\n",
      " |      *,\n",
      " |      content_type: 'str | None' = None,\n",
      " |      encoding: 'str' = 'utf8',\n",
      " |      proto: 'DeprecatedParseProtocol | None' = None,\n",
      " |      allow_pickle: 'bool' = False\n",
      " |  ) -> 'Self'\n",
      " |\n",
      " |  schema(by_alias: 'bool' = True, ref_template: 'str' = '#/$defs/{model}') -> 'Dict[str, Any]'\n",
      " |\n",
      " |  schema_json(\n",
      " |      *,\n",
      " |      by_alias: 'bool' = True,\n",
      " |      ref_template: 'str' = '#/$defs/{model}',\n",
      " |      **dumps_kwargs: 'Any'\n",
      " |  ) -> 'str'\n",
      " |\n",
      " |  update_forward_refs(**localns: 'Any') -> 'None'\n",
      " |\n",
      " |  validate(value: 'Any') -> 'Self'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __fields_set__\n",
      " |\n",
      " |  model_extra\n",
      " |      Get extra fields set during validation.\n",
      " |\n",
      " |      Returns:\n",
      " |          A dictionary of extra fields, or `None` if `config.extra` is not set to `\"allow\"`.\n",
      " |\n",
      " |  model_fields_set\n",
      " |      Returns the set of fields that have been explicitly set on this model instance.\n",
      " |\n",
      " |      Returns:\n",
      " |          A set of strings representing the fields that have been set,\n",
      " |              i.e. that were not filled from defaults.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __pydantic_extra__\n",
      " |\n",
      " |  __pydantic_fields_set__\n",
      " |\n",
      " |  __pydantic_private__\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pydantic.main.BaseModel:\n",
      " |\n",
      " |  __hash__ = None\n",
      " |\n",
      " |  __pydantic_root_model__ = False\n",
      " |\n",
      " |  model_computed_fields = {}\n",
      " |\n",
      " |  model_fields = {'args_schema': FieldInfo(annotation=Union[type[BaseMod...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.runnables.base.Runnable:\n",
      " |\n",
      " |  __or__(\n",
      " |      self,\n",
      " |      other: 'Runnable[Any, Other] | Callable[[Iterator[Any]], Iterator[Other]] | Callable[[AsyncIterator[Any]], AsyncIterator[Other]] | Callable[[Any], Other] | Mapping[str, Runnable[Any, Other] | Callable[[Any], Other] | Any]'\n",
      " |  ) -> 'RunnableSerializable[Input, Other]'\n",
      " |      Runnable \"or\" operator.\n",
      " |\n",
      " |      Compose this `Runnable` with another object to create a\n",
      " |      `RunnableSequence`.\n",
      " |\n",
      " |      Args:\n",
      " |          other: Another `Runnable` or a `Runnable`-like object.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable`.\n",
      " |\n",
      " |  __ror__(\n",
      " |      self,\n",
      " |      other: 'Runnable[Other, Any] | Callable[[Iterator[Other]], Iterator[Any]] | Callable[[AsyncIterator[Other]], AsyncIterator[Any]] | Callable[[Other], Any] | Mapping[str, Runnable[Other, Any] | Callable[[Other], Any] | Any]'\n",
      " |  ) -> 'RunnableSerializable[Other, Output]'\n",
      " |      Runnable \"reverse-or\" operator.\n",
      " |\n",
      " |      Compose this `Runnable` with another object to create a\n",
      " |      `RunnableSequence`.\n",
      " |\n",
      " |      Args:\n",
      " |          other: Another `Runnable` or a `Runnable`-like object.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable`.\n",
      " |\n",
      " |  async abatch(\n",
      " |      self,\n",
      " |      inputs: 'list[Input]',\n",
      " |      config: 'RunnableConfig | list[RunnableConfig] | None' = None,\n",
      " |      *,\n",
      " |      return_exceptions: 'bool' = False,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'list[Output]'\n",
      " |      Default implementation runs `ainvoke` in parallel using `asyncio.gather`.\n",
      " |\n",
      " |      The default implementation of `batch` works well for IO bound runnables.\n",
      " |\n",
      " |      Subclasses must override this method if they can batch more efficiently;\n",
      " |      e.g., if the underlying `Runnable` uses an API which supports a batch mode.\n",
      " |\n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the `Runnable`.\n",
      " |          config: A config to use when invoking the `Runnable`.\n",
      " |              The config supports standard keys like `'tags'`, `'metadata'` for\n",
      " |              tracing purposes, `'max_concurrency'` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the `RunnableConfig`\n",
      " |              for more details.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A list of outputs from the `Runnable`.\n",
      " |\n",
      " |  async abatch_as_completed(\n",
      " |      self,\n",
      " |      inputs: 'Sequence[Input]',\n",
      " |      config: 'RunnableConfig | Sequence[RunnableConfig] | None' = None,\n",
      " |      *,\n",
      " |      return_exceptions: 'bool' = False,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'AsyncIterator[tuple[int, Output | Exception]]'\n",
      " |      Run `ainvoke` in parallel on a list of inputs.\n",
      " |\n",
      " |      Yields results as they complete.\n",
      " |\n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the `Runnable`.\n",
      " |          config: A config to use when invoking the `Runnable`.\n",
      " |              The config supports standard keys like `'tags'`, `'metadata'` for\n",
      " |              tracing purposes, `'max_concurrency'` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the `RunnableConfig`\n",
      " |              for more details.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          A tuple of the index of the input and the output from the `Runnable`.\n",
      " |\n",
      " |  as_tool(\n",
      " |      self,\n",
      " |      args_schema: 'type[BaseModel] | None' = None,\n",
      " |      *,\n",
      " |      name: 'str | None' = None,\n",
      " |      description: 'str | None' = None,\n",
      " |      arg_types: 'dict[str, type] | None' = None\n",
      " |  ) -> 'BaseTool'\n",
      " |      .. beta::\n",
      " |         This API is in beta and may change in the future.\n",
      " |\n",
      " |      Create a `BaseTool` from a `Runnable`.\n",
      " |\n",
      " |      `as_tool` will instantiate a `BaseTool` with a name, description, and\n",
      " |      `args_schema` from a `Runnable`. Where possible, schemas are inferred\n",
      " |      from `runnable.get_input_schema`. Alternatively (e.g., if the\n",
      " |      `Runnable` takes a dict as input and the specific dict keys are not typed),\n",
      " |      the schema can be specified directly with `args_schema`. You can also\n",
      " |      pass `arg_types` to just specify the required arguments and their types.\n",
      " |\n",
      " |      Args:\n",
      " |          args_schema: The schema for the tool.\n",
      " |          name: The name of the tool.\n",
      " |          description: The description of the tool.\n",
      " |          arg_types: A dictionary of argument names to types.\n",
      " |\n",
      " |      Returns:\n",
      " |          A `BaseTool` instance.\n",
      " |\n",
      " |      Typed dict input:\n",
      " |\n",
      " |      ```python\n",
      " |      from typing_extensions import TypedDict\n",
      " |      from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |      class Args(TypedDict):\n",
      " |          a: int\n",
      " |          b: list[int]\n",
      " |\n",
      " |\n",
      " |      def f(x: Args) -> str:\n",
      " |          return str(x[\"a\"] * max(x[\"b\"]))\n",
      " |\n",
      " |\n",
      " |      runnable = RunnableLambda(f)\n",
      " |      as_tool = runnable.as_tool()\n",
      " |      as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
      " |      ```\n",
      " |\n",
      " |      `dict` input, specifying schema via `args_schema`:\n",
      " |\n",
      " |      ```python\n",
      " |      from typing import Any\n",
      " |      from pydantic import BaseModel, Field\n",
      " |      from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |      def f(x: dict[str, Any]) -> str:\n",
      " |          return str(x[\"a\"] * max(x[\"b\"]))\n",
      " |\n",
      " |      class FSchema(BaseModel):\n",
      " |          \"\"\"Apply a function to an integer and list of integers.\"\"\"\n",
      " |\n",
      " |          a: int = Field(..., description=\"Integer\")\n",
      " |          b: list[int] = Field(..., description=\"List of ints\")\n",
      " |\n",
      " |      runnable = RunnableLambda(f)\n",
      " |      as_tool = runnable.as_tool(FSchema)\n",
      " |      as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
      " |      ```\n",
      " |\n",
      " |      `dict` input, specifying schema via `arg_types`:\n",
      " |\n",
      " |      ```python\n",
      " |      from typing import Any\n",
      " |      from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |      def f(x: dict[str, Any]) -> str:\n",
      " |          return str(x[\"a\"] * max(x[\"b\"]))\n",
      " |\n",
      " |\n",
      " |      runnable = RunnableLambda(f)\n",
      " |      as_tool = runnable.as_tool(arg_types={\"a\": int, \"b\": list[int]})\n",
      " |      as_tool.invoke({\"a\": 3, \"b\": [1, 2]})\n",
      " |      ```\n",
      " |\n",
      " |      String input:\n",
      " |\n",
      " |      ```python\n",
      " |      from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |      def f(x: str) -> str:\n",
      " |          return x + \"a\"\n",
      " |\n",
      " |\n",
      " |      def g(x: str) -> str:\n",
      " |          return x + \"z\"\n",
      " |\n",
      " |\n",
      " |      runnable = RunnableLambda(f) | g\n",
      " |      as_tool = runnable.as_tool()\n",
      " |      as_tool.invoke(\"b\")\n",
      " |      ```\n",
      " |\n",
      " |  assign(\n",
      " |      self,\n",
      " |      **kwargs: 'Runnable[dict[str, Any], Any] | Callable[[dict[str, Any]], Any] | Mapping[str, Runnable[dict[str, Any], Any] | Callable[[dict[str, Any]], Any]]'\n",
      " |  ) -> 'RunnableSerializable[Any, Any]'\n",
      " |      Assigns new fields to the `dict` output of this `Runnable`.\n",
      " |\n",
      " |      ```python\n",
      " |      from langchain_community.llms.fake import FakeStreamingListLLM\n",
      " |      from langchain_core.output_parsers import StrOutputParser\n",
      " |      from langchain_core.prompts import SystemMessagePromptTemplate\n",
      " |      from langchain_core.runnables import Runnable\n",
      " |      from operator import itemgetter\n",
      " |\n",
      " |      prompt = (\n",
      " |          SystemMessagePromptTemplate.from_template(\"You are a nice assistant.\")\n",
      " |          + \"{question}\"\n",
      " |      )\n",
      " |      model = FakeStreamingListLLM(responses=[\"foo-lish\"])\n",
      " |\n",
      " |      chain: Runnable = prompt | model | {\"str\": StrOutputParser()}\n",
      " |\n",
      " |      chain_with_assign = chain.assign(hello=itemgetter(\"str\") | model)\n",
      " |\n",
      " |      print(chain_with_assign.input_schema.model_json_schema())\n",
      " |      # {'title': 'PromptInput', 'type': 'object', 'properties':\n",
      " |      {'question': {'title': 'Question', 'type': 'string'}}}\n",
      " |      print(chain_with_assign.output_schema.model_json_schema())\n",
      " |      # {'title': 'RunnableSequenceOutput', 'type': 'object', 'properties':\n",
      " |      {'str': {'title': 'Str',\n",
      " |      'type': 'string'}, 'hello': {'title': 'Hello', 'type': 'string'}}}\n",
      " |      ```\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: A mapping of keys to `Runnable` or `Runnable`-like objects\n",
      " |              that will be invoked with the entire output dict of this `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable`.\n",
      " |\n",
      " |  async astream(\n",
      " |      self,\n",
      " |      input: 'Input',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'AsyncIterator[Output]'\n",
      " |      Default implementation of `astream`, which calls `ainvoke`.\n",
      " |\n",
      " |      Subclasses must override this method if they support streaming output.\n",
      " |\n",
      " |      Args:\n",
      " |          input: The input to the `Runnable`.\n",
      " |          config: The config to use for the `Runnable`.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          The output of the `Runnable`.\n",
      " |\n",
      " |  async astream_events(\n",
      " |      self,\n",
      " |      input: 'Any',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      *,\n",
      " |      version: \"Literal['v1', 'v2']\" = 'v2',\n",
      " |      include_names: 'Sequence[str] | None' = None,\n",
      " |      include_types: 'Sequence[str] | None' = None,\n",
      " |      include_tags: 'Sequence[str] | None' = None,\n",
      " |      exclude_names: 'Sequence[str] | None' = None,\n",
      " |      exclude_types: 'Sequence[str] | None' = None,\n",
      " |      exclude_tags: 'Sequence[str] | None' = None,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'AsyncIterator[StreamEvent]'\n",
      " |      Generate a stream of events.\n",
      " |\n",
      " |      Use to create an iterator over `StreamEvent` that provide real-time information\n",
      " |      about the progress of the `Runnable`, including `StreamEvent` from intermediate\n",
      " |      results.\n",
      " |\n",
      " |      A `StreamEvent` is a dictionary with the following schema:\n",
      " |\n",
      " |      - `event`: Event names are of the format:\n",
      " |          `on_[runnable_type]_(start|stream|end)`.\n",
      " |      - `name`: The name of the `Runnable` that generated the event.\n",
      " |      - `run_id`: Randomly generated ID associated with the given execution of the\n",
      " |          `Runnable` that emitted the event. A child `Runnable` that gets invoked as\n",
      " |          part of the execution of a parent `Runnable` is assigned its own unique ID.\n",
      " |      - `parent_ids`: The IDs of the parent runnables that generated the event. The\n",
      " |          root `Runnable` will have an empty list. The order of the parent IDs is from\n",
      " |          the root to the immediate parent. Only available for v2 version of the API.\n",
      " |          The v1 version of the API will return an empty list.\n",
      " |      - `tags`: The tags of the `Runnable` that generated the event.\n",
      " |      - `metadata`: The metadata of the `Runnable` that generated the event.\n",
      " |      - `data`: The data associated with the event. The contents of this field\n",
      " |          depend on the type of event. See the table below for more details.\n",
      " |\n",
      " |      Below is a table that illustrates some events that might be emitted by various\n",
      " |      chains. Metadata fields have been omitted from the table for brevity.\n",
      " |      Chain definitions have been included after the table.\n",
      " |\n",
      " |      !!! note\n",
      " |          This reference table is for the v2 version of the schema.\n",
      " |\n",
      " |      | event                  | name                 | chunk                               | input                                             | output                                              |\n",
      " |      | ---------------------- | -------------------- | ----------------------------------- | ------------------------------------------------- | --------------------------------------------------- |\n",
      " |      | `on_chat_model_start`  | `'[model name]'`     |                                     | `{\"messages\": [[SystemMessage, HumanMessage]]}`   |                                                     |\n",
      " |      | `on_chat_model_stream` | `'[model name]'`     | `AIMessageChunk(content=\"hello\")`   |                                                   |                                                     |\n",
      " |      | `on_chat_model_end`    | `'[model name]'`     |                                     | `{\"messages\": [[SystemMessage, HumanMessage]]}`   | `AIMessageChunk(content=\"hello world\")`             |\n",
      " |      | `on_llm_start`         | `'[model name]'`     |                                     | `{'input': 'hello'}`                              |                                                     |\n",
      " |      | `on_llm_stream`        | `'[model name]'`     | `'Hello' `                          |                                                   |                                                     |\n",
      " |      | `on_llm_end`           | `'[model name]'`     |                                     | `'Hello human!'`                                  |                                                     |\n",
      " |      | `on_chain_start`       | `'format_docs'`      |                                     |                                                   |                                                     |\n",
      " |      | `on_chain_stream`      | `'format_docs'`      | `'hello world!, goodbye world!'`    |                                                   |                                                     |\n",
      " |      | `on_chain_end`         | `'format_docs'`      |                                     | `[Document(...)]`                                 | `'hello world!, goodbye world!'`                    |\n",
      " |      | `on_tool_start`        | `'some_tool'`        |                                     | `{\"x\": 1, \"y\": \"2\"}`                              |                                                     |\n",
      " |      | `on_tool_end`          | `'some_tool'`        |                                     |                                                   | `{\"x\": 1, \"y\": \"2\"}`                                |\n",
      " |      | `on_retriever_start`   | `'[retriever name]'` |                                     | `{\"query\": \"hello\"}`                              |                                                     |\n",
      " |      | `on_retriever_end`     | `'[retriever name]'` |                                     | `{\"query\": \"hello\"}`                              | `[Document(...), ..]`                               |\n",
      " |      | `on_prompt_start`      | `'[template_name]'`  |                                     | `{\"question\": \"hello\"}`                           |                                                     |\n",
      " |      | `on_prompt_end`        | `'[template_name]'`  |                                     | `{\"question\": \"hello\"}`                           | `ChatPromptValue(messages: [SystemMessage, ...])`   |\n",
      " |\n",
      " |      In addition to the standard events, users can also dispatch custom events (see example below).\n",
      " |\n",
      " |      Custom events will be only be surfaced with in the v2 version of the API!\n",
      " |\n",
      " |      A custom event has following format:\n",
      " |\n",
      " |      | Attribute   | Type   | Description                                                                                               |\n",
      " |      | ----------- | ------ | --------------------------------------------------------------------------------------------------------- |\n",
      " |      | `name`      | `str`  | A user defined name for the event.                                                                        |\n",
      " |      | `data`      | `Any`  | The data associated with the event. This can be anything, though we suggest making it JSON serializable.  |\n",
      " |\n",
      " |      Here are declarations associated with the standard events shown above:\n",
      " |\n",
      " |      `format_docs`:\n",
      " |\n",
      " |      ```python\n",
      " |      def format_docs(docs: list[Document]) -> str:\n",
      " |          '''Format the docs.'''\n",
      " |          return \", \".join([doc.page_content for doc in docs])\n",
      " |\n",
      " |\n",
      " |      format_docs = RunnableLambda(format_docs)\n",
      " |      ```\n",
      " |\n",
      " |      `some_tool`:\n",
      " |\n",
      " |      ```python\n",
      " |      @tool\n",
      " |      def some_tool(x: int, y: str) -> dict:\n",
      " |          '''Some_tool.'''\n",
      " |          return {\"x\": x, \"y\": y}\n",
      " |      ```\n",
      " |\n",
      " |      `prompt`:\n",
      " |\n",
      " |      ```python\n",
      " |      template = ChatPromptTemplate.from_messages(\n",
      " |          [\n",
      " |              (\"system\", \"You are Cat Agent 007\"),\n",
      " |              (\"human\", \"{question}\"),\n",
      " |          ]\n",
      " |      ).with_config({\"run_name\": \"my_template\", \"tags\": [\"my_template\"]})\n",
      " |      ```\n",
      " |\n",
      " |      For instance:\n",
      " |\n",
      " |      ```python\n",
      " |      from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |      async def reverse(s: str) -> str:\n",
      " |          return s[::-1]\n",
      " |\n",
      " |\n",
      " |      chain = RunnableLambda(func=reverse)\n",
      " |\n",
      " |      events = [event async for event in chain.astream_events(\"hello\", version=\"v2\")]\n",
      " |\n",
      " |      # Will produce the following events\n",
      " |      # (run_id, and parent_ids has been omitted for brevity):\n",
      " |      [\n",
      " |          {\n",
      " |              \"data\": {\"input\": \"hello\"},\n",
      " |              \"event\": \"on_chain_start\",\n",
      " |              \"metadata\": {},\n",
      " |              \"name\": \"reverse\",\n",
      " |              \"tags\": [],\n",
      " |          },\n",
      " |          {\n",
      " |              \"data\": {\"chunk\": \"olleh\"},\n",
      " |              \"event\": \"on_chain_stream\",\n",
      " |              \"metadata\": {},\n",
      " |              \"name\": \"reverse\",\n",
      " |              \"tags\": [],\n",
      " |          },\n",
      " |          {\n",
      " |              \"data\": {\"output\": \"olleh\"},\n",
      " |              \"event\": \"on_chain_end\",\n",
      " |              \"metadata\": {},\n",
      " |              \"name\": \"reverse\",\n",
      " |              \"tags\": [],\n",
      " |          },\n",
      " |      ]\n",
      " |      ```\n",
      " |\n",
      " |      ```python title=\"Example: Dispatch Custom Event\"\n",
      " |      from langchain_core.callbacks.manager import (\n",
      " |          adispatch_custom_event,\n",
      " |      )\n",
      " |      from langchain_core.runnables import RunnableLambda, RunnableConfig\n",
      " |      import asyncio\n",
      " |\n",
      " |\n",
      " |      async def slow_thing(some_input: str, config: RunnableConfig) -> str:\n",
      " |          \"\"\"Do something that takes a long time.\"\"\"\n",
      " |          await asyncio.sleep(1) # Placeholder for some slow operation\n",
      " |          await adispatch_custom_event(\n",
      " |              \"progress_event\",\n",
      " |              {\"message\": \"Finished step 1 of 3\"},\n",
      " |              config=config # Must be included for python < 3.10\n",
      " |          )\n",
      " |          await asyncio.sleep(1) # Placeholder for some slow operation\n",
      " |          await adispatch_custom_event(\n",
      " |              \"progress_event\",\n",
      " |              {\"message\": \"Finished step 2 of 3\"},\n",
      " |              config=config # Must be included for python < 3.10\n",
      " |          )\n",
      " |          await asyncio.sleep(1) # Placeholder for some slow operation\n",
      " |          return \"Done\"\n",
      " |\n",
      " |      slow_thing = RunnableLambda(slow_thing)\n",
      " |\n",
      " |      async for event in slow_thing.astream_events(\"some_input\", version=\"v2\"):\n",
      " |          print(event)\n",
      " |      ```\n",
      " |\n",
      " |      Args:\n",
      " |          input: The input to the `Runnable`.\n",
      " |          config: The config to use for the `Runnable`.\n",
      " |          version: The version of the schema to use either `'v2'` or `'v1'`.\n",
      " |              Users should use `'v2'`.\n",
      " |              `'v1'` is for backwards compatibility and will be deprecated\n",
      " |              in `0.4.0`.\n",
      " |              No default will be assigned until the API is stabilized.\n",
      " |              custom events will only be surfaced in `'v2'`.\n",
      " |          include_names: Only include events from `Runnable` objects with matching names.\n",
      " |          include_types: Only include events from `Runnable` objects with matching types.\n",
      " |          include_tags: Only include events from `Runnable` objects with matching tags.\n",
      " |          exclude_names: Exclude events from `Runnable` objects with matching names.\n",
      " |          exclude_types: Exclude events from `Runnable` objects with matching types.\n",
      " |          exclude_tags: Exclude events from `Runnable` objects with matching tags.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |              These will be passed to `astream_log` as this implementation\n",
      " |              of `astream_events` is built on top of `astream_log`.\n",
      " |\n",
      " |      Yields:\n",
      " |          An async stream of `StreamEvent`.\n",
      " |\n",
      " |      Raises:\n",
      " |          NotImplementedError: If the version is not `'v1'` or `'v2'`.\n",
      " |\n",
      " |  async astream_log(\n",
      " |      self,\n",
      " |      input: 'Any',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      *,\n",
      " |      diff: 'bool' = True,\n",
      " |      with_streamed_output_list: 'bool' = True,\n",
      " |      include_names: 'Sequence[str] | None' = None,\n",
      " |      include_types: 'Sequence[str] | None' = None,\n",
      " |      include_tags: 'Sequence[str] | None' = None,\n",
      " |      exclude_names: 'Sequence[str] | None' = None,\n",
      " |      exclude_types: 'Sequence[str] | None' = None,\n",
      " |      exclude_tags: 'Sequence[str] | None' = None,\n",
      " |      **kwargs: 'Any'\n",
      " |  ) -> 'AsyncIterator[RunLogPatch] | AsyncIterator[RunLog]'\n",
      " |      Stream all output from a `Runnable`, as reported to the callback system.\n",
      " |\n",
      " |      This includes all inner runs of LLMs, Retrievers, Tools, etc.\n",
      " |\n",
      " |      Output is streamed as Log objects, which include a list of\n",
      " |      Jsonpatch ops that describe how the state of the run has changed in each\n",
      " |      step, and the final state of the run.\n",
      " |\n",
      " |      The Jsonpatch ops can be applied in order to construct state.\n",
      " |\n",
      " |      Args:\n",
      " |          input: The input to the `Runnable`.\n",
      " |          config: The config to use for the `Runnable`.\n",
      " |          diff: Whether to yield diffs between each step or the current state.\n",
      " |          with_streamed_output_list: Whether to yield the `streamed_output` list.\n",
      " |          include_names: Only include logs with these names.\n",
      " |          include_types: Only include logs with these types.\n",
      " |          include_tags: Only include logs with these tags.\n",
      " |          exclude_names: Exclude logs with these names.\n",
      " |          exclude_types: Exclude logs with these types.\n",
      " |          exclude_tags: Exclude logs with these tags.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          A `RunLogPatch` or `RunLog` object.\n",
      " |\n",
      " |  async atransform(\n",
      " |      self,\n",
      " |      input: 'AsyncIterator[Input]',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'AsyncIterator[Output]'\n",
      " |      Transform inputs to outputs.\n",
      " |\n",
      " |      Default implementation of atransform, which buffers input and calls `astream`.\n",
      " |\n",
      " |      Subclasses must override this method if they can start producing output while\n",
      " |      input is still being generated.\n",
      " |\n",
      " |      Args:\n",
      " |          input: An async iterator of inputs to the `Runnable`.\n",
      " |          config: The config to use for the `Runnable`.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          The output of the `Runnable`.\n",
      " |\n",
      " |  batch(\n",
      " |      self,\n",
      " |      inputs: 'list[Input]',\n",
      " |      config: 'RunnableConfig | list[RunnableConfig] | None' = None,\n",
      " |      *,\n",
      " |      return_exceptions: 'bool' = False,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'list[Output]'\n",
      " |      Default implementation runs invoke in parallel using a thread pool executor.\n",
      " |\n",
      " |      The default implementation of batch works well for IO bound runnables.\n",
      " |\n",
      " |      Subclasses must override this method if they can batch more efficiently;\n",
      " |      e.g., if the underlying `Runnable` uses an API which supports a batch mode.\n",
      " |\n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the `Runnable`.\n",
      " |          config: A config to use when invoking the `Runnable`. The config supports\n",
      " |              standard keys like `'tags'`, `'metadata'` for\n",
      " |              tracing purposes, `'max_concurrency'` for controlling how much work\n",
      " |              to do in parallel, and other keys. Please refer to the\n",
      " |              `RunnableConfig` for more details.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A list of outputs from the `Runnable`.\n",
      " |\n",
      " |  batch_as_completed(\n",
      " |      self,\n",
      " |      inputs: 'Sequence[Input]',\n",
      " |      config: 'RunnableConfig | Sequence[RunnableConfig] | None' = None,\n",
      " |      *,\n",
      " |      return_exceptions: 'bool' = False,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'Iterator[tuple[int, Output | Exception]]'\n",
      " |      Run `invoke` in parallel on a list of inputs.\n",
      " |\n",
      " |      Yields results as they complete.\n",
      " |\n",
      " |      Args:\n",
      " |          inputs: A list of inputs to the `Runnable`.\n",
      " |          config: A config to use when invoking the `Runnable`.\n",
      " |              The config supports standard keys like `'tags'`, `'metadata'` for\n",
      " |              tracing purposes, `'max_concurrency'` for controlling how much work to\n",
      " |              do in parallel, and other keys. Please refer to the `RunnableConfig`\n",
      " |              for more details.\n",
      " |          return_exceptions: Whether to return exceptions instead of raising them.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          Tuples of the index of the input and the output from the `Runnable`.\n",
      " |\n",
      " |  bind(self, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
      " |      Bind arguments to a `Runnable`, returning a new `Runnable`.\n",
      " |\n",
      " |      Useful when a `Runnable` in a chain requires an argument that is not\n",
      " |      in the output of the previous `Runnable` or included in the user input.\n",
      " |\n",
      " |      Args:\n",
      " |          **kwargs: The arguments to bind to the `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the arguments bound.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_ollama import ChatOllama\n",
      " |          from langchain_core.output_parsers import StrOutputParser\n",
      " |\n",
      " |          model = ChatOllama(model=\"llama3.1\")\n",
      " |\n",
      " |          # Without bind\n",
      " |          chain = model | StrOutputParser()\n",
      " |\n",
      " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
      " |          # Output is 'One two three four five.'\n",
      " |\n",
      " |          # With bind\n",
      " |          chain = model.bind(stop=[\"three\"]) | StrOutputParser()\n",
      " |\n",
      " |          chain.invoke(\"Repeat quoted words exactly: 'One two three four five.'\")\n",
      " |          # Output is 'One two'\n",
      " |          ```\n",
      " |\n",
      " |  config_schema(self, *, include: 'Sequence[str] | None' = None) -> 'type[BaseModel]'\n",
      " |      The type of config this `Runnable` accepts specified as a Pydantic model.\n",
      " |\n",
      " |      To mark a field as configurable, see the `configurable_fields`\n",
      " |      and `configurable_alternatives` methods.\n",
      " |\n",
      " |      Args:\n",
      " |          include: A list of fields to include in the config schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          A Pydantic model that can be used to validate config.\n",
      " |\n",
      " |  get_config_jsonschema(self, *, include: 'Sequence[str] | None' = None) -> 'dict[str, Any]'\n",
      " |      Get a JSON schema that represents the config of the `Runnable`.\n",
      " |\n",
      " |      Args:\n",
      " |          include: A list of fields to include in the config schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON schema that represents the config of the `Runnable`.\n",
      " |\n",
      " |      !!! version-added \"Added in version 0.3.0\"\n",
      " |\n",
      " |  get_graph(self, config: 'RunnableConfig | None' = None) -> 'Graph'\n",
      " |      Return a graph representation of this `Runnable`.\n",
      " |\n",
      " |  get_input_jsonschema(self, config: 'RunnableConfig | None' = None) -> 'dict[str, Any]'\n",
      " |      Get a JSON schema that represents the input to the `Runnable`.\n",
      " |\n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON schema that represents the input to the `Runnable`.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |          def add_one(x: int) -> int:\n",
      " |              return x + 1\n",
      " |\n",
      " |\n",
      " |          runnable = RunnableLambda(add_one)\n",
      " |\n",
      " |          print(runnable.get_input_jsonschema())\n",
      " |          ```\n",
      " |\n",
      " |      !!! version-added \"Added in version 0.3.0\"\n",
      " |\n",
      " |  get_name(self, suffix: 'str | None' = None, *, name: 'str | None' = None) -> 'str'\n",
      " |      Get the name of the `Runnable`.\n",
      " |\n",
      " |      Args:\n",
      " |          suffix: An optional suffix to append to the name.\n",
      " |          name: An optional name to use instead of the `Runnable`'s name.\n",
      " |\n",
      " |      Returns:\n",
      " |          The name of the `Runnable`.\n",
      " |\n",
      " |  get_output_jsonschema(self, config: 'RunnableConfig | None' = None) -> 'dict[str, Any]'\n",
      " |      Get a JSON schema that represents the output of the `Runnable`.\n",
      " |\n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          A JSON schema that represents the output of the `Runnable`.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |          def add_one(x: int) -> int:\n",
      " |              return x + 1\n",
      " |\n",
      " |\n",
      " |          runnable = RunnableLambda(add_one)\n",
      " |\n",
      " |          print(runnable.get_output_jsonschema())\n",
      " |          ```\n",
      " |\n",
      " |      !!! version-added \"Added in version 0.3.0\"\n",
      " |\n",
      " |  get_output_schema(self, config: 'RunnableConfig | None' = None) -> 'type[BaseModel]'\n",
      " |      Get a Pydantic model that can be used to validate output to the `Runnable`.\n",
      " |\n",
      " |      `Runnable` objects that leverage the `configurable_fields` and\n",
      " |      `configurable_alternatives` methods will have a dynamic output schema that\n",
      " |      depends on which configuration the `Runnable` is invoked with.\n",
      " |\n",
      " |      This method allows to get an output schema for a specific configuration.\n",
      " |\n",
      " |      Args:\n",
      " |          config: A config to use when generating the schema.\n",
      " |\n",
      " |      Returns:\n",
      " |          A Pydantic model that can be used to validate output.\n",
      " |\n",
      " |  get_prompts(self, config: 'RunnableConfig | None' = None) -> 'list[BasePromptTemplate]'\n",
      " |      Return a list of prompts used by this `Runnable`.\n",
      " |\n",
      " |  map(self) -> 'Runnable[list[Input], list[Output]]'\n",
      " |      Return a new `Runnable` that maps a list of inputs to a list of outputs.\n",
      " |\n",
      " |      Calls `invoke` with each input.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` that maps a list of inputs to a list of outputs.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |          def _lambda(x: int) -> int:\n",
      " |              return x + 1\n",
      " |\n",
      " |\n",
      " |          runnable = RunnableLambda(_lambda)\n",
      " |          print(runnable.map().invoke([1, 2, 3]))  # [2, 3, 4]\n",
      " |          ```\n",
      " |\n",
      " |  pick(self, keys: 'str | list[str]') -> 'RunnableSerializable[Any, Any]'\n",
      " |      Pick keys from the output `dict` of this `Runnable`.\n",
      " |\n",
      " |      Pick a single key:\n",
      " |\n",
      " |      ```python\n",
      " |      import json\n",
      " |\n",
      " |      from langchain_core.runnables import RunnableLambda, RunnableMap\n",
      " |\n",
      " |      as_str = RunnableLambda(str)\n",
      " |      as_json = RunnableLambda(json.loads)\n",
      " |      chain = RunnableMap(str=as_str, json=as_json)\n",
      " |\n",
      " |      chain.invoke(\"[1, 2, 3]\")\n",
      " |      # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3]}\n",
      " |\n",
      " |      json_only_chain = chain.pick(\"json\")\n",
      " |      json_only_chain.invoke(\"[1, 2, 3]\")\n",
      " |      # -> [1, 2, 3]\n",
      " |      ```\n",
      " |\n",
      " |      Pick a list of keys:\n",
      " |\n",
      " |      ```python\n",
      " |      from typing import Any\n",
      " |\n",
      " |      import json\n",
      " |\n",
      " |      from langchain_core.runnables import RunnableLambda, RunnableMap\n",
      " |\n",
      " |      as_str = RunnableLambda(str)\n",
      " |      as_json = RunnableLambda(json.loads)\n",
      " |\n",
      " |\n",
      " |      def as_bytes(x: Any) -> bytes:\n",
      " |          return bytes(x, \"utf-8\")\n",
      " |\n",
      " |\n",
      " |      chain = RunnableMap(str=as_str, json=as_json, bytes=RunnableLambda(as_bytes))\n",
      " |\n",
      " |      chain.invoke(\"[1, 2, 3]\")\n",
      " |      # -> {\"str\": \"[1, 2, 3]\", \"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
      " |\n",
      " |      json_and_bytes_chain = chain.pick([\"json\", \"bytes\"])\n",
      " |      json_and_bytes_chain.invoke(\"[1, 2, 3]\")\n",
      " |      # -> {\"json\": [1, 2, 3], \"bytes\": b\"[1, 2, 3]\"}\n",
      " |      ```\n",
      " |\n",
      " |      Args:\n",
      " |          keys: A key or list of keys to pick from the output dict.\n",
      " |\n",
      " |      Returns:\n",
      " |          a new `Runnable`.\n",
      " |\n",
      " |  pipe(\n",
      " |      self,\n",
      " |      *others: 'Runnable[Any, Other] | Callable[[Any], Other]',\n",
      " |      name: 'str | None' = None\n",
      " |  ) -> 'RunnableSerializable[Input, Other]'\n",
      " |      Pipe `Runnable` objects.\n",
      " |\n",
      " |      Compose this `Runnable` with `Runnable`-like objects to make a\n",
      " |      `RunnableSequence`.\n",
      " |\n",
      " |      Equivalent to `RunnableSequence(self, *others)` or `self | others[0] | ...`\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |\n",
      " |          def add_one(x: int) -> int:\n",
      " |              return x + 1\n",
      " |\n",
      " |\n",
      " |          def mul_two(x: int) -> int:\n",
      " |              return x * 2\n",
      " |\n",
      " |\n",
      " |          runnable_1 = RunnableLambda(add_one)\n",
      " |          runnable_2 = RunnableLambda(mul_two)\n",
      " |          sequence = runnable_1.pipe(runnable_2)\n",
      " |          # Or equivalently:\n",
      " |          # sequence = runnable_1 | runnable_2\n",
      " |          # sequence = RunnableSequence(first=runnable_1, last=runnable_2)\n",
      " |          sequence.invoke(1)\n",
      " |          await sequence.ainvoke(1)\n",
      " |          # -> 4\n",
      " |\n",
      " |          sequence.batch([1, 2, 3])\n",
      " |          await sequence.abatch([1, 2, 3])\n",
      " |          # -> [4, 6, 8]\n",
      " |          ```\n",
      " |\n",
      " |      Args:\n",
      " |          *others: Other `Runnable` or `Runnable`-like objects to compose\n",
      " |          name: An optional name for the resulting `RunnableSequence`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable`.\n",
      " |\n",
      " |  stream(\n",
      " |      self,\n",
      " |      input: 'Input',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'Iterator[Output]'\n",
      " |      Default implementation of `stream`, which calls `invoke`.\n",
      " |\n",
      " |      Subclasses must override this method if they support streaming output.\n",
      " |\n",
      " |      Args:\n",
      " |          input: The input to the `Runnable`.\n",
      " |          config: The config to use for the `Runnable`.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          The output of the `Runnable`.\n",
      " |\n",
      " |  transform(\n",
      " |      self,\n",
      " |      input: 'Iterator[Input]',\n",
      " |      config: 'RunnableConfig | None' = None,\n",
      " |      **kwargs: 'Any | None'\n",
      " |  ) -> 'Iterator[Output]'\n",
      " |      Transform inputs to outputs.\n",
      " |\n",
      " |      Default implementation of transform, which buffers input and calls `astream`.\n",
      " |\n",
      " |      Subclasses must override this method if they can start producing output while\n",
      " |      input is still being generated.\n",
      " |\n",
      " |      Args:\n",
      " |          input: An iterator of inputs to the `Runnable`.\n",
      " |          config: The config to use for the `Runnable`.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Yields:\n",
      " |          The output of the `Runnable`.\n",
      " |\n",
      " |  with_alisteners(\n",
      " |      self,\n",
      " |      *,\n",
      " |      on_start: 'AsyncListener | None' = None,\n",
      " |      on_end: 'AsyncListener | None' = None,\n",
      " |      on_error: 'AsyncListener | None' = None\n",
      " |  ) -> 'Runnable[Input, Output]'\n",
      " |      Bind async lifecycle listeners to a `Runnable`.\n",
      " |\n",
      " |      Returns a new `Runnable`.\n",
      " |\n",
      " |      The Run object contains information about the run, including its `id`,\n",
      " |      `type`, `input`, `output`, `error`, `start_time`, `end_time`, and\n",
      " |      any tags or metadata added to the run.\n",
      " |\n",
      " |      Args:\n",
      " |          on_start: Called asynchronously before the `Runnable` starts running,\n",
      " |              with the `Run` object.\n",
      " |          on_end: Called asynchronously after the `Runnable` finishes running,\n",
      " |              with the `Run` object.\n",
      " |          on_error: Called asynchronously if the `Runnable` throws an error,\n",
      " |              with the `Run` object.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the listeners bound.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda, Runnable\n",
      " |          from datetime import datetime, timezone\n",
      " |          import time\n",
      " |          import asyncio\n",
      " |\n",
      " |          def format_t(timestamp: float) -> str:\n",
      " |              return datetime.fromtimestamp(timestamp, tz=timezone.utc).isoformat()\n",
      " |\n",
      " |          async def test_runnable(time_to_sleep: int):\n",
      " |              print(f\"Runnable[{time_to_sleep}s]: starts at {format_t(time.time())}\")\n",
      " |              await asyncio.sleep(time_to_sleep)\n",
      " |              print(f\"Runnable[{time_to_sleep}s]: ends at {format_t(time.time())}\")\n",
      " |\n",
      " |          async def fn_start(run_obj: Runnable):\n",
      " |              print(f\"on start callback starts at {format_t(time.time())}\")\n",
      " |              await asyncio.sleep(3)\n",
      " |              print(f\"on start callback ends at {format_t(time.time())}\")\n",
      " |\n",
      " |          async def fn_end(run_obj: Runnable):\n",
      " |              print(f\"on end callback starts at {format_t(time.time())}\")\n",
      " |              await asyncio.sleep(2)\n",
      " |              print(f\"on end callback ends at {format_t(time.time())}\")\n",
      " |\n",
      " |          runnable = RunnableLambda(test_runnable).with_alisteners(\n",
      " |              on_start=fn_start,\n",
      " |              on_end=fn_end\n",
      " |          )\n",
      " |          async def concurrent_runs():\n",
      " |              await asyncio.gather(runnable.ainvoke(2), runnable.ainvoke(3))\n",
      " |\n",
      " |          asyncio.run(concurrent_runs())\n",
      " |          Result:\n",
      " |          on start callback starts at 2025-03-01T07:05:22.875378+00:00\n",
      " |          on start callback starts at 2025-03-01T07:05:22.875495+00:00\n",
      " |          on start callback ends at 2025-03-01T07:05:25.878862+00:00\n",
      " |          on start callback ends at 2025-03-01T07:05:25.878947+00:00\n",
      " |          Runnable[2s]: starts at 2025-03-01T07:05:25.879392+00:00\n",
      " |          Runnable[3s]: starts at 2025-03-01T07:05:25.879804+00:00\n",
      " |          Runnable[2s]: ends at 2025-03-01T07:05:27.881998+00:00\n",
      " |          on end callback starts at 2025-03-01T07:05:27.882360+00:00\n",
      " |          Runnable[3s]: ends at 2025-03-01T07:05:28.881737+00:00\n",
      " |          on end callback starts at 2025-03-01T07:05:28.882428+00:00\n",
      " |          on end callback ends at 2025-03-01T07:05:29.883893+00:00\n",
      " |          on end callback ends at 2025-03-01T07:05:30.884831+00:00\n",
      " |\n",
      " |          ```\n",
      " |\n",
      " |  with_config(self, config: 'RunnableConfig | None' = None, **kwargs: 'Any') -> 'Runnable[Input, Output]'\n",
      " |      Bind config to a `Runnable`, returning a new `Runnable`.\n",
      " |\n",
      " |      Args:\n",
      " |          config: The config to bind to the `Runnable`.\n",
      " |          **kwargs: Additional keyword arguments to pass to the `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the config bound.\n",
      " |\n",
      " |  with_fallbacks(\n",
      " |      self,\n",
      " |      fallbacks: 'Sequence[Runnable[Input, Output]]',\n",
      " |      *,\n",
      " |      exceptions_to_handle: 'tuple[type[BaseException], ...]' = (<class 'Exception'>,),\n",
      " |      exception_key: 'str | None' = None\n",
      " |  ) -> 'RunnableWithFallbacksT[Input, Output]'\n",
      " |      Add fallbacks to a `Runnable`, returning a new `Runnable`.\n",
      " |\n",
      " |      The new `Runnable` will try the original `Runnable`, and then each fallback\n",
      " |      in order, upon failures.\n",
      " |\n",
      " |      Args:\n",
      " |          fallbacks: A sequence of runnables to try if the original `Runnable`\n",
      " |              fails.\n",
      " |          exceptions_to_handle: A tuple of exception types to handle.\n",
      " |          exception_key: If `string` is specified then handled exceptions will be\n",
      " |              passed to fallbacks as part of the input under the specified key.\n",
      " |              If `None`, exceptions will not be passed to fallbacks.\n",
      " |              If used, the base `Runnable` and its fallbacks must accept a\n",
      " |              dictionary as input.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` that will try the original `Runnable`, and then each\n",
      " |              Fallback in order, upon failures.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from typing import Iterator\n",
      " |\n",
      " |          from langchain_core.runnables import RunnableGenerator\n",
      " |\n",
      " |\n",
      " |          def _generate_immediate_error(input: Iterator) -> Iterator[str]:\n",
      " |              raise ValueError()\n",
      " |              yield \"\"\n",
      " |\n",
      " |\n",
      " |          def _generate(input: Iterator) -> Iterator[str]:\n",
      " |              yield from \"foo bar\"\n",
      " |\n",
      " |\n",
      " |          runnable = RunnableGenerator(_generate_immediate_error).with_fallbacks(\n",
      " |              [RunnableGenerator(_generate)]\n",
      " |          )\n",
      " |          print(\"\".join(runnable.stream({})))  # foo bar\n",
      " |          ```\n",
      " |\n",
      " |      Args:\n",
      " |          fallbacks: A sequence of runnables to try if the original `Runnable`\n",
      " |              fails.\n",
      " |          exceptions_to_handle: A tuple of exception types to handle.\n",
      " |          exception_key: If `string` is specified then handled exceptions will be\n",
      " |              passed to fallbacks as part of the input under the specified key.\n",
      " |              If `None`, exceptions will not be passed to fallbacks.\n",
      " |              If used, the base `Runnable` and its fallbacks must accept a\n",
      " |              dictionary as input.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` that will try the original `Runnable`, and then each\n",
      " |              Fallback in order, upon failures.\n",
      " |\n",
      " |  with_listeners(\n",
      " |      self,\n",
      " |      *,\n",
      " |      on_start: 'Callable[[Run], None] | Callable[[Run, RunnableConfig], None] | None' = None,\n",
      " |      on_end: 'Callable[[Run], None] | Callable[[Run, RunnableConfig], None] | None' = None,\n",
      " |      on_error: 'Callable[[Run], None] | Callable[[Run, RunnableConfig], None] | None' = None\n",
      " |  ) -> 'Runnable[Input, Output]'\n",
      " |      Bind lifecycle listeners to a `Runnable`, returning a new `Runnable`.\n",
      " |\n",
      " |      The Run object contains information about the run, including its `id`,\n",
      " |      `type`, `input`, `output`, `error`, `start_time`, `end_time`, and\n",
      " |      any tags or metadata added to the run.\n",
      " |\n",
      " |      Args:\n",
      " |          on_start: Called before the `Runnable` starts running, with the `Run`\n",
      " |              object.\n",
      " |          on_end: Called after the `Runnable` finishes running, with the `Run`\n",
      " |              object.\n",
      " |          on_error: Called if the `Runnable` throws an error, with the `Run`\n",
      " |              object.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the listeners bound.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |          from langchain_core.tracers.schemas import Run\n",
      " |\n",
      " |          import time\n",
      " |\n",
      " |\n",
      " |          def test_runnable(time_to_sleep: int):\n",
      " |              time.sleep(time_to_sleep)\n",
      " |\n",
      " |\n",
      " |          def fn_start(run_obj: Run):\n",
      " |              print(\"start_time:\", run_obj.start_time)\n",
      " |\n",
      " |\n",
      " |          def fn_end(run_obj: Run):\n",
      " |              print(\"end_time:\", run_obj.end_time)\n",
      " |\n",
      " |\n",
      " |          chain = RunnableLambda(test_runnable).with_listeners(\n",
      " |              on_start=fn_start, on_end=fn_end\n",
      " |          )\n",
      " |          chain.invoke(2)\n",
      " |          ```\n",
      " |\n",
      " |  with_retry(\n",
      " |      self,\n",
      " |      *,\n",
      " |      retry_if_exception_type: 'tuple[type[BaseException], ...]' = (<class 'Exception'>,),\n",
      " |      wait_exponential_jitter: 'bool' = True,\n",
      " |      exponential_jitter_params: 'ExponentialJitterParams | None' = None,\n",
      " |      stop_after_attempt: 'int' = 3\n",
      " |  ) -> 'Runnable[Input, Output]'\n",
      " |      Create a new `Runnable` that retries the original `Runnable` on exceptions.\n",
      " |\n",
      " |      Args:\n",
      " |          retry_if_exception_type: A tuple of exception types to retry on.\n",
      " |          wait_exponential_jitter: Whether to add jitter to the wait\n",
      " |              time between retries.\n",
      " |          stop_after_attempt: The maximum number of attempts to make before\n",
      " |              giving up.\n",
      " |          exponential_jitter_params: Parameters for\n",
      " |              `tenacity.wait_exponential_jitter`. Namely: `initial`, `max`,\n",
      " |              `exp_base`, and `jitter` (all `float` values).\n",
      " |\n",
      " |      Returns:\n",
      " |          A new Runnable that retries the original Runnable on exceptions.\n",
      " |\n",
      " |      Example:\n",
      " |          ```python\n",
      " |          from langchain_core.runnables import RunnableLambda\n",
      " |\n",
      " |          count = 0\n",
      " |\n",
      " |\n",
      " |          def _lambda(x: int) -> None:\n",
      " |              global count\n",
      " |              count = count + 1\n",
      " |              if x == 1:\n",
      " |                  raise ValueError(\"x is 1\")\n",
      " |              else:\n",
      " |                  pass\n",
      " |\n",
      " |\n",
      " |          runnable = RunnableLambda(_lambda)\n",
      " |          try:\n",
      " |              runnable.with_retry(\n",
      " |                  stop_after_attempt=2,\n",
      " |                  retry_if_exception_type=(ValueError,),\n",
      " |              ).invoke(1)\n",
      " |          except ValueError:\n",
      " |              pass\n",
      " |\n",
      " |          assert count == 2\n",
      " |          ```\n",
      " |\n",
      " |  with_types(\n",
      " |      self,\n",
      " |      *,\n",
      " |      input_type: 'type[Input] | None' = None,\n",
      " |      output_type: 'type[Output] | None' = None\n",
      " |  ) -> 'Runnable[Input, Output]'\n",
      " |      Bind input and output types to a `Runnable`, returning a new `Runnable`.\n",
      " |\n",
      " |      Args:\n",
      " |          input_type: The input type to bind to the `Runnable`.\n",
      " |          output_type: The output type to bind to the `Runnable`.\n",
      " |\n",
      " |      Returns:\n",
      " |          A new `Runnable` with the types bound.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from langchain_core.runnables.base.Runnable:\n",
      " |\n",
      " |  InputType\n",
      " |      Input type.\n",
      " |\n",
      " |      The type of input this `Runnable` accepts specified as a type annotation.\n",
      " |\n",
      " |      Raises:\n",
      " |          TypeError: If the input type cannot be inferred.\n",
      " |\n",
      " |  OutputType\n",
      " |      Output Type.\n",
      " |\n",
      " |      The type of output this `Runnable` produces specified as a type annotation.\n",
      " |\n",
      " |      Raises:\n",
      " |          TypeError: If the output type cannot be inferred.\n",
      " |\n",
      " |  config_specs\n",
      " |      List configurable fields for this `Runnable`.\n",
      " |\n",
      " |  input_schema\n",
      " |      The type of input this `Runnable` accepts specified as a Pydantic model.\n",
      " |\n",
      " |  output_schema\n",
      " |      Output schema.\n",
      " |\n",
      " |      The type of output this `Runnable` produces specified as a Pydantic model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rag_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d638743d",
   "metadata": {},
   "source": [
    "## 8.Final answer tool\n",
    "This is final answer tool, which combines list and iterate over the list of tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d1cf737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "\n",
    "@tool\n",
    "def final_answer(\n",
    "    introduction: str,\n",
    "    research_steps: str or list,\n",
    "    main_body: str,\n",
    "    conclusion: str,\n",
    "    sources: str or list\n",
    "\n",
    ") -> str:\n",
    "\n",
    "    '''Returns a natural language response in the form of a research report.'''\n",
    "\n",
    "    # Format research steps if given as a list.\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
    "    \n",
    "    # Format sources if given as a list.\n",
    "    if isinstance(sources, list):\n",
    "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
    "    \n",
    "    # Construct and return the final research report.\n",
    "    return f'{introduction}\\n\\nResearch Steps:\\n{research_steps}\\n\\nMain Body:\\n{main_body}\\n\\n \\\n",
    "    Conclusion:\\n{conclusion}\\n\\nSources:\\n{sources}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29cdcd",
   "metadata": {},
   "source": [
    "## 9.Initialize agent LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09028f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define the system prompt \n",
    "system_prompt = (\n",
    "    '''You are the Agent LLM, the great AI decision-maker.\n",
    "    Given the user's query, you must decide what to do with it based on the\n",
    "    list of tools provided to you.\n",
    "\n",
    "    If you see that a tool has been used (in the scratchpad) with a particular\n",
    "    query, do NOT use that same tool with the same query again. Also, do NOT use\n",
    "    any tool more than twice (i.e., if the tool appears in the scratchpad twice, do\n",
    "    not use it again).\n",
    "\n",
    "    You should aim to collect information from a diverse range of sources before\n",
    "    providing the answer to the user. Once you have collected plenty of information\n",
    "    to answer the user's question (stored in the scratchpad), use the final_answer tool.'''\n",
    ")\n",
    "\n",
    "\n",
    "messages = [('system', system_prompt),\n",
    "\n",
    "    ## Insert past chat messages to maintain context\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "\n",
    "    ('human', '{input}'),\n",
    "\n",
    "    #scratchpad to track tool usage and intermediate steps\n",
    "    ('assistant', 'scratchpad: {scratchpad}'),\n",
    "    ]\n",
    "\n",
    "## create a prompt \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4015658e",
   "metadata": {},
   "source": [
    "### create scratch pad ( trail of messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5cdd3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolCall, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0,  openai_api_key = os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "tools = [\n",
    "    rag_search_filter,\n",
    "    rag_search,\n",
    "    fetch_arxiv,\n",
    "    web_search,\n",
    "    final_answer\n",
    "\n",
    "]\n",
    "\n",
    "def create_scratchpad(intermediate_steps: list[ToolCall]) -> str:\n",
    "    '''Create a scratchpad from the intermediate tool calls'''\n",
    "    print('NEW create_scratchpad')\n",
    "    print(f'intermediate_steps', intermediate_steps)\n",
    "\n",
    "    research_steps = []\n",
    "\n",
    "    # Iterate over the objects as a single variable\n",
    "    for action_obj in intermediate_steps:\n",
    "        # Check if the log property is not 'TBD' (meaning the action has been executed)\n",
    "        log_str = action_obj.log\n",
    "        if log_str != 'TBD':\n",
    "            research_steps.append(\n",
    "                f'Tool: {action_obj.tool}, input: {action_obj.tool_input}\\n'\n",
    "                f'Output: {log_str}'\n",
    "            )\n",
    "    \n",
    "    # Join the research steps into a readable log.\n",
    "    return '\\n---\\n'.join(research_steps)\n",
    "\n",
    "\n",
    "#define orchestrator for decision making pipeline\n",
    "\n",
    "orchestrator = (\n",
    "    {\n",
    "        'input': lambda x: x['input'],\n",
    "        'chat_history': lambda x: x['chat_history'],\n",
    "        'scratchpad': lambda x: create_scratchpad(intermediate_steps=x['intermediate_steps']),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice='any')\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db03f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orchestrator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca6b173",
   "metadata": {},
   "source": [
    "## 10.Test orchestrator agent tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "079b7021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create_scratchpad\n",
      "intermediate_steps []\n",
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 382, 'total_tokens': 404, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CczQPvP8w6ydFRd8C0s1iL6UB6thd', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--c8067180-a2cb-469d-89da-5ac42daad5a8-0' tool_calls=[{'name': 'fetch_arxiv', 'args': {'arvix_id': '2407.21783'}, 'id': 'call_BQrSgx4YE0WHb6P9XL7Hvy1v', 'type': 'tool_call'}] usage_metadata={'input_tokens': 382, 'output_tokens': 22, 'total_tokens': 404, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#input = 'Tell me something interesting about dynamic backtracking AI and LLMs'\n",
    "input = 'What is the ArXiv paper with the ID 2407.21783 all about?'\n",
    "\n",
    "input = {\n",
    "\n",
    "    'input': input,\n",
    "    'chat_history': [],\n",
    "    'intermediate_steps': []\n",
    "}\n",
    "\n",
    "output = orchestrator.invoke(input)\n",
    "\n",
    "\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdee062b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fetch_arxiv'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "279b1d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arvix_id': '2407.21783'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls[0]['args']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4a60b",
   "metadata": {},
   "source": [
    "## 11.Create run tools ( decision making nodes ) for Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39178c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_orchestrator(): main function that executes the orchestrator and processes its output to extract the relevant tool and its arguments.\n",
    "# We'll use this information to update the state for future steps.\n",
    "def run_orchestrator(state: dict) -> dict:\n",
    "    '''Runs the orchestrator and processes the output to extract tool information.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing the 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new state with updated 'intermediate_steps' including the tool action.\n",
    "    '''\n",
    "    \n",
    "    print('run_orchestrator')\n",
    "    print(f'intermediate_steps: {state[\"intermediate_steps\"]}')\n",
    "    \n",
    "    # Invoke the oraorchestratorcle with the current state.\n",
    "    out = orchestrator.invoke(state)\n",
    "\n",
    "    # Extract the tool name and its arguments from the orchestrator's response.\n",
    "    tool_name = out.tool_calls[0]['name']\n",
    "    tool_args = out.tool_calls[0]['args']\n",
    "\n",
    "    # Create an AgentAction object, which records the tool used and the input provided.\n",
    "    action_out = AgentAction(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        log='TBD'  # To be determined later after the tool runs.\n",
    "    )\n",
    "\n",
    "    # Return a new state with updated 'intermediate_steps'.\n",
    "    return cast(AgentState,{\n",
    "        'intermediate_steps': [action_out]\n",
    "    })\n",
    "\n",
    "\n",
    "# The router() function determines the next tool to use based on the current state.\n",
    "def router(state: dict) -> str:\n",
    "    '''Determines the next tool to use based on the current state.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the tool to use next.\n",
    "    '''\n",
    "\n",
    "    if isinstance(state['intermediate_steps'], list):\n",
    "        return state['intermediate_steps'][-1].tool\n",
    "    else:\n",
    "        print('Router invalid format')\n",
    "        return 'final_answer'\n",
    "\n",
    "\n",
    "tool_str_to_func = {\n",
    "    'rag_search_filter': rag_search_filter,\n",
    "    'rag_search': rag_search,\n",
    "    'fetch_arxiv': fetch_arxiv,\n",
    "    'web_search': web_search,\n",
    "    'final_answer': final_answer\n",
    "}\n",
    "\n",
    "# The run_tool() function executes the appropriate tool based on the current state.\n",
    "def run_tool(state: dict) -> dict:\n",
    "    '''Executes the appropriate tool based on the current state.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state containing the 'intermediate_steps'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A new state with updated 'intermediate_steps' including the tool's result.\n",
    "    '''\n",
    "\n",
    "    tool_name = state['intermediate_steps'][-1].tool\n",
    "    tool_args = state['intermediate_steps'][-1].tool_input\n",
    "\n",
    "    print(f'{tool_name}.invoke(input={tool_args})')\n",
    "\n",
    "    out = tool_str_to_func[tool_name].invoke(input=tool_args)\n",
    "\n",
    "    observation = str(out)\n",
    "\n",
    "    action_out = AgentAction(\n",
    "        tool=tool_name,\n",
    "        tool_input=tool_args,\n",
    "        log=str(out)\n",
    "    )\n",
    "\n",
    "    return {'intermediate_steps': [(action_out, observation)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64c88a",
   "metadata": {},
   "source": [
    "## 12. Define langgraph agent state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ee86450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.agents import AgentAction\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    '''Represents the state of an agent., this will be parameter to StateGraph instance'''\n",
    "    \n",
    "    input: str\n",
    "    chat_history: List[BaseMessage]\n",
    "    intermediate_steps: Annotated[List[tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac0ac39",
   "metadata": {},
   "source": [
    "## 13. Define a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32531126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "possible_next_nodes = [\n",
    "    'rag_search_filter',\n",
    "    'rag_search',\n",
    "    'fetch_arxiv',\n",
    "    'web_search',\n",
    "    'final_answer',\n",
    "]\n",
    "\n",
    "# Initialize the state graph with AgentState to manage the workflow.\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node('orchestrator', run_orchestrator)\n",
    "graph.add_node('rag_search_filter', run_tool)\n",
    "graph.add_node('rag_search', run_tool)\n",
    "graph.add_node('fetch_arxiv', run_tool)\n",
    "graph.add_node('web_search', run_tool)\n",
    "graph.add_node('final_answer', run_tool)\n",
    "\n",
    "# Set the entry point to 'oracle'.\n",
    "graph.set_entry_point('orchestrator')\n",
    "\n",
    "# # Add conditional edges to determine the next step using the router function.\n",
    "# graph.add_conditional_edges(source='orchestrator', \n",
    "#                             path=router,\n",
    "#                             nodes=possible_next_nodes \n",
    "#                             \n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    'orchestrator',              # Positional: 1st argument (source)\n",
    "    router,                      # Positional: 2nd argument (path function)\n",
    "    possible_next_nodes          # Positional: 3rd argument (destinations)\n",
    ")\n",
    "\n",
    "# Add edges from each tool back to 'orchestrator', except 'final_answer', which leads to 'END'.\n",
    "for tool_obj in tools:\n",
    "    if tool_obj.name != 'final_answer':\n",
    "        graph.add_edge(tool_obj.name, 'orchestrator')\n",
    "\n",
    "graph.add_edge('final_answer', END)\n",
    "\n",
    "# Compile the graph to make it executable.\n",
    "runnable = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71cc9813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x000001F88CB07250>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e946a19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image,display\n",
    "\n",
    "display(Image(runnable.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2886e1",
   "metadata": {},
   "source": [
    "## 14. Debug and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6ec311d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_orchestrator\n",
      "intermediate_steps: []\n",
      "NEW create_scratchpad\n",
      "intermediate_steps []\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI interesting facts'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/')]\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI applications'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/')]\n",
      "web_search.invoke(input={'query': 'LLMs applications in AI'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps')]\n",
      "rag_search.invoke(input={'query': 'Dynamic Backtracking AI and LLMs'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n')]\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI and its relation to LLMs'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/')]\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI and LLMs relationship'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nTo Backtrack or Not to Backtrack: When Sequential Search ...\\nUnderstanding whether backtracking enhances the reasoning ability of large language models helps us build smarter AI systems.\\nhttps://kempnerinstitute.harvard.edu/research/deeper-learning/to-backtrack-or-not-to-backtrack-when-sequential-search-limits-model-reasoning/\\n---\\nBuilding Cutting-Edge AI Models: From Advanced LLMs to ...\\nModern AI development is a multi-stage journey, from training massive LLMs to integrating advanced reasoning, and even expanding beyond text ...\\nhttps://medium.com/@sanderink.ursina/building-cutting-edge-ai-models-from-advanced-llms-to-multimodal-agents-f75a1a9873f1\\n---\\nAI Agents from First Principles - Deep (Learning) Focus\\nIn this overview, we will build an understanding of AI agents from first principles. Starting with a standard text-to-text LLM, we will explore how ...\\nhttps://cameronrwolfe.substack.com/p/ai-agents')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nTo Backtrack or Not to Backtrack: When Sequential Search ...\\nUnderstanding whether backtracking enhances the reasoning ability of large language models helps us build smarter AI systems.\\nhttps://kempnerinstitute.harvard.edu/research/deeper-learning/to-backtrack-or-not-to-backtrack-when-sequential-search-limits-model-reasoning/\\n---\\nBuilding Cutting-Edge AI Models: From Advanced LLMs to ...\\nModern AI development is a multi-stage journey, from training massive LLMs to integrating advanced reasoning, and even expanding beyond text ...\\nhttps://medium.com/@sanderink.ursina/building-cutting-edge-ai-models-from-advanced-llms-to-multimodal-agents-f75a1a9873f1\\n---\\nAI Agents from First Principles - Deep (Learning) Focus\\nIn this overview, we will build an understanding of AI agents from first principles. Starting with a standard text-to-text LLM, we will explore how ...\\nhttps://cameronrwolfe.substack.com/p/ai-agents')]\n",
      "web_search.invoke(input={'query': 'Dynamic Backtracking AI applications'})\n",
      "run_orchestrator\n",
      "intermediate_steps: [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nTo Backtrack or Not to Backtrack: When Sequential Search ...\\nUnderstanding whether backtracking enhances the reasoning ability of large language models helps us build smarter AI systems.\\nhttps://kempnerinstitute.harvard.edu/research/deeper-learning/to-backtrack-or-not-to-backtrack-when-sequential-search-limits-model-reasoning/\\n---\\nBuilding Cutting-Edge AI Models: From Advanced LLMs to ...\\nModern AI development is a multi-stage journey, from training massive LLMs to integrating advanced reasoning, and even expanding beyond text ...\\nhttps://medium.com/@sanderink.ursina/building-cutting-edge-ai-models-from-advanced-llms-to-multimodal-agents-f75a1a9873f1\\n---\\nAI Agents from First Principles - Deep (Learning) Focus\\nIn this overview, we will build an understanding of AI agents from first principles. Starting with a standard text-to-text LLM, we will explore how ...\\nhttps://cameronrwolfe.substack.com/p/ai-agents'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/')]\n",
      "NEW create_scratchpad\n",
      "intermediate_steps [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nTo Backtrack or Not to Backtrack: When Sequential Search ...\\nUnderstanding whether backtracking enhances the reasoning ability of large language models helps us build smarter AI systems.\\nhttps://kempnerinstitute.harvard.edu/research/deeper-learning/to-backtrack-or-not-to-backtrack-when-sequential-search-limits-model-reasoning/\\n---\\nBuilding Cutting-Edge AI Models: From Advanced LLMs to ...\\nModern AI development is a multi-stage journey, from training massive LLMs to integrating advanced reasoning, and even expanding beyond text ...\\nhttps://medium.com/@sanderink.ursina/building-cutting-edge-ai-models-from-advanced-llms-to-multimodal-agents-f75a1a9873f1\\n---\\nAI Agents from First Principles - Deep (Learning) Focus\\nIn this overview, we will build an understanding of AI agents from first principles. Starting with a standard text-to-text LLM, we will explore how ...\\nhttps://cameronrwolfe.substack.com/p/ai-agents'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/')]\n",
      "final_answer.invoke(input={'introduction': 'Dynamic Backtracking AI is a sophisticated problem-solving technique that enhances traditional backtracking methods by allowing the search process to move deeper into the search space, thereby avoiding unnecessary backtracking to shallow points. This approach is particularly useful in various AI applications, including constraint satisfaction problems, planning, and scheduling.', 'research_steps': \"1. Dynamic Backtracking allows for the recording of 'nogoods'information about portions of the search space that have been eliminated, which helps in avoiding redundant searches. 2. It has been applied in fields such as propositional theorem proving, map coloring, and scheduling problems, showcasing its versatility in handling complex decision-making tasks. 3. Recent advancements have explored the integration of dynamic backtracking with large language models (LLMs), enhancing their reasoning capabilities by enabling them to backtrack during both training and inference.\", 'main_body': 'Large Language Models (LLMs) are AI systems designed to understand and generate human language by processing vast amounts of text data. They have found applications in various domains, including virtual assistants, content generation, translation, and sentiment analysis. The integration of dynamic backtracking into LLMs introduces a self-backtracking mechanism that allows these models to revisit previous decisions, thereby improving their reasoning and problem-solving abilities. This is particularly significant in complex tasks where the initial decision may not lead to the optimal solution. Research has shown that self-backtracking can enhance the reasoning capabilities of LLMs, making them more effective in tasks that require logical deduction and sequential decision-making.', 'conclusion': 'The relationship between Dynamic Backtracking AI and LLMs represents a promising frontier in artificial intelligence, where traditional problem-solving techniques are being adapted to enhance the capabilities of language models. This synergy not only improves the efficiency of LLMs in reasoning tasks but also opens new avenues for developing more intelligent and adaptable AI systems.', 'sources': '1. Dynamic Backtracking - Journal of Artificial Intelligence Research. 2. GSAT and Dynamic Backtracking - AAAI. 3. Self-Backtracking for Boosting Reasoning of Language Models - arXiv. 4. The State of LLM Reasoning Model Inference - Sebastian Raschka.'})\n"
     ]
    }
   ],
   "source": [
    "# Run the graph with input.\n",
    "output = runnable.invoke({\n",
    "    'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs',\n",
    "    'chat_history': [],\n",
    "})\n",
    "\n",
    "#print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a3b31ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: {'input': 'Tell me something interesting about Dynamic Backtracking AI and LLMs', 'chat_history': [], 'intermediate_steps': [AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI interesting facts'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://jair.org/index.php/jair/article/download/10107/23929\\n---\\nA Gentle Introduction to Backtracking\\nBacktracking is a versatile technique for exploring the solution space of various types of data science problems and incrementally constructing candidate ...\\nhttps://towardsdatascience.com/a-gentle-introduction-to-backtracking/\\n---\\nGSAT and Dynamic Backtracking\\n3 DYNAMIC BACKTRACKING Dynamic backtracking uses the set of nogoods to both record information about the portion of the search space that has been eliminated ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nBacktracking In Artificial Intelligence\\nBacktracking is a problem-solving technique that involves exploring all possible solutions and abandoning those that fail to satisfy the conditions of the ...\\nhttps://heycoach.in/blog/backtracking-in-artificial-intelligence/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'LLMs applications in AI'}, log='Top 10 Real-Life Applications of Large Language Models\\nMost popular LLM applications span from virtual assistants, content generation, and translation to sentiment analysis, education, and data ...\\nhttps://pixelplex.io/blog/llm-applications/\\n---\\n55 real-world LLM applications and use cases from top ...\\nCreators of AI-powered writing assistant Grammarly use LLMs to protect users from harmful conversations. The company goes beyond toxicity ...\\nhttps://www.evidentlyai.com/blog/llm-applications\\n---\\nWhat Are Large Language Models (LLMs)?\\nLarge language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\nhttps://www.ibm.com/think/topics/large-language-models\\n---\\nWhat is an LLM (large language model)?\\nA large language model (LLM) is a type of artificial intelligence (AI) program that can recognize and generate text, among other tasks.\\nhttps://www.cloudflare.com/learning/ai/what-is-large-language-model/\\n---\\nShubhamsaboo/awesome-llm-apps\\nA curated collection of Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.\\nhttps://github.com/Shubhamsaboo/awesome-llm-apps'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='TBD'), AgentAction(tool='rag_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs'}, log='Title: Dynamic Backtracking\\nChunk: Journal of Arti/\\x0ccial In telligence Researc h /1 /(/1/9/9/3/) /2/5/-/4/6 Submitted /7///9/3/; published /8///9/3\\nDynamic Bac ktrac king\\nMatthew L/. Ginsb erg ginsber g/@cs/.uoregon/.edu\\nCIRL/, University of Or e gon/,\\nEugene/, OR /9/7/4/0/3/-/1/2/6/9 USA\\nAbstract\\nBecause of their o ccasional need to return to shallo w p oin ts in a searc h tree/, existing\\nbac ktrac king metho ds can sometimes erase meaningful progress to w ard solving a searc h\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: A System for Induction of Oblique Decision Trees\\nChunk: Bro dley /& Utgo/\\x0b/, /1/9/9/2/)/, whic h is a successor to the P erceptron T ree metho d /(Utgo/\\x0b/, /1/9/8/9/;\\nUtgo/\\x0b /& Bro dley /, /1/9/9/0/)/. Eac h in ternal no de in an LMDT tree is a Linear Mac hine /(Nilsson/,\\n/1/9/9/0/)/. The training algorithm presen ts examples rep eatedly at eac h no de un til the linear\\nmac hine con v erges/. Because con v ergence cannot b e guaran teed/, LMDT uses heuristics to\\ndetermine when the no de has stabilized/. T o mak e the training stable ev en when the set of\\nArXiv ID: 9408103v1\\n\\n---\\nTitle: Truncating Temporal Differences: On the Efficient Implementation of\\n  TD(lambda) for Reinforcement Learning\\nChunk: on appro ximating dynamic programming/. In Pr o c e e dings of the Seventh International\\nConfer enc e on Machine L e arning /(ML/-/9/0/) /. Morgan Kaufmann/.\\nSutton/, R/. S/./, Barto/, A/. G/./, /& Williams/, R/. J/. /(/1/9/9/1/)/. Reinforcemen t learning is direct\\nadaptiv e optimal con trol/. In Pr o c e e dings of the A meric an Contr ol Confer enc e /, pp/.\\n/2/1/4/3/{/2/1/4/6/. Boston/, MA/.\\nSutton/, R/. S/./, /& Singh/, S/. P /. /(/1/9/9/4/)/. On step/-size and bias in temp oral/-di/\\x0berence learning/.\\nArXiv ID: 9501103v1\\n\\n---\\nTitle: Dynamic Backtracking\\nChunk: D ynamic Ba cktra cking\\nPro of/. That few er no des are examined is clear/; for completeness/, it follo ws from Lemma\\n/3/./2 that the bac ktrac k to some elemen t of E in step /5 will alw a ys b e necessary if a solution\\nis to b e found/.\\nProp osition /3/./5 The amount of sp ac e ne e de d by b ackjumping is o /( i\\n/2\\nv /) /, wher e i /= j I j is\\nthe numb er of variables in the pr oblem and v is the numb er of values for that variable with\\nthe lar gest value set V\\ni\\n/.\\nArXiv ID: 9308101v1\\n\\n---\\nTitle: Pac-Learning Recursive Logic Programs: Efficient Algorithms\\nChunk: P a c/-Learning Recursive Logic Pr ograms/: Efficient Algorithms\\nBiermann/, A/. /(/1/9/7/8/)/. The inference of regular lisp programs from examples/. IEEE T r ans/-\\nactions on Systems/, Man and Cyb ernetics /, /8 /(/8/)/.\\nCohen/, W/. W/. /(/1/9/9/3a/)/. A pac/-learning algorithm for a restricted class of recursiv e logic\\nprograms/. In Pr o c e e dings of the T enth National Confer enc e on A rti/\\x0ccial Intel ligenc e\\nW ashington/, D/.C/.\\nArXiv ID: 9505104v1\\n'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and its relation to LLMs'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nSelf-Backtracking Boosting Reasoning | by QvickRead\\nThe Researchers concluded that self-backtracking is a promising step toward Level 2 AGI Reasoners (per OpenAI\\'s AGI framework). By enabling LLMs ...\\nhttps://medium.com/advancedai/ai-that-thinks-twice-the-power-of-self-backtracking-aa11a293b05d\\n---\\nASTRO: Teaching Language Models to Reason by ...\\nWe introduce ASTRO, the \"Autoregressive Search-Taught Reasoner\", a framework for training language models to reason like search algorithms.\\nhttps://ai.meta.com/research/publications/astro-teaching-language-models-to-reason-by-reflecting-and-backtracking-in-context/\\n---\\nEmergent Hierarchical Reasoning in LLMs through ...\\nReinforcement Learning (RL) has been a game-changer for teaching LLMs complex reasoning, but how it works has been a mystery.\\nhttps://tiger-ai-lab.github.io/Hierarchical-Reasoner/'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI and LLMs relationship'}, log='Self-Backtracking for Boosting Reasoning of Language ...\\nWe propose a self-backtracking mechanism that equips LLMs with the ability to backtrack during both training and inference.\\nhttps://arxiv.org/html/2502.04404v1\\n---\\nThe State of LLM Reasoning Model Inference\\nThis article explores recent research advancements in reasoning-optimized LLMs, with a particular focus on inference-time compute scaling.\\nhttps://magazine.sebastianraschka.com/p/state-of-llm-reasoning-and-inference-scaling\\n---\\nTo Backtrack or Not to Backtrack: When Sequential Search ...\\nUnderstanding whether backtracking enhances the reasoning ability of large language models helps us build smarter AI systems.\\nhttps://kempnerinstitute.harvard.edu/research/deeper-learning/to-backtrack-or-not-to-backtrack-when-sequential-search-limits-model-reasoning/\\n---\\nBuilding Cutting-Edge AI Models: From Advanced LLMs to ...\\nModern AI development is a multi-stage journey, from training massive LLMs to integrating advanced reasoning, and even expanding beyond text ...\\nhttps://medium.com/@sanderink.ursina/building-cutting-edge-ai-models-from-advanced-llms-to-multimodal-agents-f75a1a9873f1\\n---\\nAI Agents from First Principles - Deep (Learning) Focus\\nIn this overview, we will build an understanding of AI agents from first principles. Starting with a standard text-to-text LLM, we will explore how ...\\nhttps://cameronrwolfe.substack.com/p/ai-agents'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='TBD'), AgentAction(tool='web_search', tool_input={'query': 'Dynamic Backtracking AI applications'}, log='Dynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this difficulty.\\nhttps://www.jair.org/index.php/jair/article/view/10107\\n---\\nGSAT and Dynamic Backtracking\\nCsPs arise naturally in subfields of AI from planning to vision, and examples include propositional theorem proving, map coloring and scheduling problems. The ...\\nhttps://cdn.aaai.org/ARPI/1996/ARPI96-019.pdf\\n---\\nDynamic Backtracking\\nIn this paper, we present a method by which backtrack points can be moved deeper in the search space, thereby avoiding this di culty. The technique developed is.\\nhttps://arxiv.org/pdf/cs/9308101\\n---\\nDynamic Backtracking. - DTIC\\nThe goal of this project was to turn the intuitions behind dynamic backtracking into a series of formally verified algorithms, implement the algorithms, ...\\nhttps://apps.dtic.mil/sti/tr/pdf/ADA322974.pdf\\n---\\nOn research of optimization strategy for dynamic backtracking\\nThe Dynamic Backtracking algorithm proposed by Ginsberg in 1993 is an efficient algorithm which uses backtracking integrates with constraint propagation.\\nhttps://ieeexplore.ieee.org/document/5212518/'), AgentAction(tool='final_answer', tool_input={'introduction': 'Dynamic Backtracking AI is a sophisticated problem-solving technique that enhances traditional backtracking methods by allowing the search process to move deeper into the search space, thereby avoiding unnecessary backtracking to shallow points. This approach is particularly useful in various AI applications, including constraint satisfaction problems, planning, and scheduling.', 'research_steps': \"1. Dynamic Backtracking allows for the recording of 'nogoods'information about portions of the search space that have been eliminated, which helps in avoiding redundant searches. 2. It has been applied in fields such as propositional theorem proving, map coloring, and scheduling problems, showcasing its versatility in handling complex decision-making tasks. 3. Recent advancements have explored the integration of dynamic backtracking with large language models (LLMs), enhancing their reasoning capabilities by enabling them to backtrack during both training and inference.\", 'main_body': 'Large Language Models (LLMs) are AI systems designed to understand and generate human language by processing vast amounts of text data. They have found applications in various domains, including virtual assistants, content generation, translation, and sentiment analysis. The integration of dynamic backtracking into LLMs introduces a self-backtracking mechanism that allows these models to revisit previous decisions, thereby improving their reasoning and problem-solving abilities. This is particularly significant in complex tasks where the initial decision may not lead to the optimal solution. Research has shown that self-backtracking can enhance the reasoning capabilities of LLMs, making them more effective in tasks that require logical deduction and sequential decision-making.', 'conclusion': 'The relationship between Dynamic Backtracking AI and LLMs represents a promising frontier in artificial intelligence, where traditional problem-solving techniques are being adapted to enhance the capabilities of language models. This synergy not only improves the efficiency of LLMs in reasoning tasks but also opens new avenues for developing more intelligent and adaptable AI systems.', 'sources': '1. Dynamic Backtracking - Journal of Artificial Intelligence Research. 2. GSAT and Dynamic Backtracking - AAAI. 3. Self-Backtracking for Boosting Reasoning of Language Models - arXiv. 4. The State of LLM Reasoning Model Inference - Sebastian Raschka.'}, log='TBD'), AgentAction(tool='final_answer', tool_input={'introduction': 'Dynamic Backtracking AI is a sophisticated problem-solving technique that enhances traditional backtracking methods by allowing the search process to move deeper into the search space, thereby avoiding unnecessary backtracking to shallow points. This approach is particularly useful in various AI applications, including constraint satisfaction problems, planning, and scheduling.', 'research_steps': \"1. Dynamic Backtracking allows for the recording of 'nogoods'information about portions of the search space that have been eliminated, which helps in avoiding redundant searches. 2. It has been applied in fields such as propositional theorem proving, map coloring, and scheduling problems, showcasing its versatility in handling complex decision-making tasks. 3. Recent advancements have explored the integration of dynamic backtracking with large language models (LLMs), enhancing their reasoning capabilities by enabling them to backtrack during both training and inference.\", 'main_body': 'Large Language Models (LLMs) are AI systems designed to understand and generate human language by processing vast amounts of text data. They have found applications in various domains, including virtual assistants, content generation, translation, and sentiment analysis. The integration of dynamic backtracking into LLMs introduces a self-backtracking mechanism that allows these models to revisit previous decisions, thereby improving their reasoning and problem-solving abilities. This is particularly significant in complex tasks where the initial decision may not lead to the optimal solution. Research has shown that self-backtracking can enhance the reasoning capabilities of LLMs, making them more effective in tasks that require logical deduction and sequential decision-making.', 'conclusion': 'The relationship between Dynamic Backtracking AI and LLMs represents a promising frontier in artificial intelligence, where traditional problem-solving techniques are being adapted to enhance the capabilities of language models. This synergy not only improves the efficiency of LLMs in reasoning tasks but also opens new avenues for developing more intelligent and adaptable AI systems.', 'sources': '1. Dynamic Backtracking - Journal of Artificial Intelligence Research. 2. GSAT and Dynamic Backtracking - AAAI. 3. Self-Backtracking for Boosting Reasoning of Language Models - arXiv. 4. The State of LLM Reasoning Model Inference - Sebastian Raschka.'}, log=\"Dynamic Backtracking AI is a sophisticated problem-solving technique that enhances traditional backtracking methods by allowing the search process to move deeper into the search space, thereby avoiding unnecessary backtracking to shallow points. This approach is particularly useful in various AI applications, including constraint satisfaction problems, planning, and scheduling.\\n\\nResearch Steps:\\n1. Dynamic Backtracking allows for the recording of 'nogoods'information about portions of the search space that have been eliminated, which helps in avoiding redundant searches. 2. It has been applied in fields such as propositional theorem proving, map coloring, and scheduling problems, showcasing its versatility in handling complex decision-making tasks. 3. Recent advancements have explored the integration of dynamic backtracking with large language models (LLMs), enhancing their reasoning capabilities by enabling them to backtrack during both training and inference.\\n\\nMain Body:\\nLarge Language Models (LLMs) are AI systems designed to understand and generate human language by processing vast amounts of text data. They have found applications in various domains, including virtual assistants, content generation, translation, and sentiment analysis. The integration of dynamic backtracking into LLMs introduces a self-backtracking mechanism that allows these models to revisit previous decisions, thereby improving their reasoning and problem-solving abilities. This is particularly significant in complex tasks where the initial decision may not lead to the optimal solution. Research has shown that self-backtracking can enhance the reasoning capabilities of LLMs, making them more effective in tasks that require logical deduction and sequential decision-making.\\n\\n     Conclusion:\\nThe relationship between Dynamic Backtracking AI and LLMs represents a promising frontier in artificial intelligence, where traditional problem-solving techniques are being adapted to enhance the capabilities of language models. This synergy not only improves the efficiency of LLMs in reasoning tasks but also opens new avenues for developing more intelligent and adaptable AI systems.\\n\\nSources:\\n1. Dynamic Backtracking - Journal of Artificial Intelligence Research. 2. GSAT and Dynamic Backtracking - AAAI. 3. Self-Backtracking for Boosting Reasoning of Language Models - arXiv. 4. The State of LLM Reasoning Model Inference - Sebastian Raschka.\")]}\n"
     ]
    }
   ],
   "source": [
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b1fcd",
   "metadata": {},
   "source": [
    "## 15. Create report in readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fa79f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_report(output: dict) -> str:\n",
    "    '''Builds a formatted report based on the oracle's output.\n",
    "\n",
    "    Args:\n",
    "        output (dict): A dictionary containing the various sections of the report (graph's output).\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string containing the full research report.\n",
    "    '''\n",
    "    research_steps = output['research_steps']\n",
    "    if isinstance(research_steps, list):\n",
    "        research_steps = '\\n'.join([f'- {r}' for r in research_steps])\n",
    "    \n",
    "    sources = output['sources']\n",
    "    if isinstance(sources, list):\n",
    "        sources = '\\n'.join([f'- {s}' for s in sources])\n",
    "    \n",
    "    return f\"\"\"\n",
    "        INTRODUCTION\n",
    "        ------------\n",
    "        {output['introduction']}\n",
    "        \n",
    "        RESEARCH STEPS\n",
    "        --------------\n",
    "        {research_steps}\n",
    "        \n",
    "        REPORT\n",
    "        ------\n",
    "        {output['main_body']}\n",
    "        \n",
    "        CONCLUSION\n",
    "        ----------\n",
    "        {output['conclusion']}\n",
    "        \n",
    "        SOURCES\n",
    "        -------\n",
    "        {sources}\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffa2fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        INTRODUCTION\n",
      "        ------------\n",
      "        Dynamic Backtracking AI is a sophisticated problem-solving technique that enhances traditional backtracking methods by allowing the search process to move deeper into the search space, thereby avoiding unnecessary backtracking to shallow points. This approach is particularly useful in various AI applications, including constraint satisfaction problems, planning, and scheduling.\n",
      "        \n",
      "        RESEARCH STEPS\n",
      "        --------------\n",
      "        1. Dynamic Backtracking allows for the recording of 'nogoods'information about portions of the search space that have been eliminated, which helps in avoiding redundant searches. 2. It has been applied in fields such as propositional theorem proving, map coloring, and scheduling problems, showcasing its versatility in handling complex decision-making tasks. 3. Recent advancements have explored the integration of dynamic backtracking with large language models (LLMs), enhancing their reasoning capabilities by enabling them to backtrack during both training and inference.\n",
      "        \n",
      "        REPORT\n",
      "        ------\n",
      "        Large Language Models (LLMs) are AI systems designed to understand and generate human language by processing vast amounts of text data. They have found applications in various domains, including virtual assistants, content generation, translation, and sentiment analysis. The integration of dynamic backtracking into LLMs introduces a self-backtracking mechanism that allows these models to revisit previous decisions, thereby improving their reasoning and problem-solving abilities. This is particularly significant in complex tasks where the initial decision may not lead to the optimal solution. Research has shown that self-backtracking can enhance the reasoning capabilities of LLMs, making them more effective in tasks that require logical deduction and sequential decision-making.\n",
      "        \n",
      "        CONCLUSION\n",
      "        ----------\n",
      "        The relationship between Dynamic Backtracking AI and LLMs represents a promising frontier in artificial intelligence, where traditional problem-solving techniques are being adapted to enhance the capabilities of language models. This synergy not only improves the efficiency of LLMs in reasoning tasks but also opens new avenues for developing more intelligent and adaptable AI systems.\n",
      "        \n",
      "        SOURCES\n",
      "        -------\n",
      "        1. Dynamic Backtracking - Journal of Artificial Intelligence Research. 2. GSAT and Dynamic Backtracking - AAAI. 3. Self-Backtracking for Boosting Reasoning of Language Models - arXiv. 4. The State of LLM Reasoning Model Inference - Sebastian Raschka.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "report = build_report(\n",
    "    output=output['intermediate_steps'][-1].tool_input\n",
    ")\n",
    "\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
