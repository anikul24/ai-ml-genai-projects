## ðŸš€ Agentic Research Assistant â€” Multi-Tool GenAI System Using LangGraph

This project implements an Agentic AI system capable of autonomous reasoning, multi-step decision-making, and retrieving information from multiple sources (RAG, Arxiv API, Web Search).
It uses LangGraph to build a state-driven agent that plans â†’ chooses tools â†’ observes â†’ continues â†’ produces a final answer.


ðŸ§  Core Capabilities
## âœ” Agentic Reasoning

Orchestrator LLM decides the next action.

Router directs the workflow based on the agent state.

Loop continues until final_answer is reached.

## âœ” Multi-Tool Integration

rag_search_filter

rag_search

fetch_arxiv

web_search

final_answer

Each tool is a callable node in the LangGraph state machine.

## âœ”  Retrieval-Augmented Generation (RAG)

Embeddings & vector search pipeline.

Dynamic chunking + metadata.

Sources: Arxiv papers, Web search results, internal documents.

## âœ”  Self-Monitoring State

Stores tool results, actions, and history in:

AgentState = {
    input: str
    chat_history: []
    intermediate_steps: List[(AgentAction, str)]
}

## âœ”  Architecture High-Level Agent Flow
```mermaid

flowchart TD

    A[User Query] --> B[Orchestrator LLM]
    B --> C[Router]

    C -->|rag_search| D[RAG Search Tool]
    C -->|rag_search_filter| E[RAG Filter Tool]
    C -->|fetch_arxiv| F[Arxiv API Tool]
    C -->|web_search| G[Web Search Tool]

    D --> B
    E --> B
    F --> B
    G --> B

    B -->|return final| H[Final Answer Tool]
    H --> I[Output to User]
    I --> J((End))
```


## ðŸ§© Tech Stack

Component	Technology
Agent Framework	LangGraph (LangChain core)
LLM	OpenAI GPT models
Vector DB	Pinecone
Retrieval	Embeddings + similarity search
Tools	Python functions wrapped with LangChain Tool
State Machine	StateGraph


##  ðŸ“¦ Proposed Project Structure 

(Curretly code is in one ipynb file)
```
/agent/
    â”œâ”€â”€ orchestrator.py
    â”œâ”€â”€ router.py
    â”œâ”€â”€ tools/
    â”‚     â”œâ”€â”€ rag_search.py
    â”‚     â”œâ”€â”€ web_search.py
    â”‚     â”œâ”€â”€ fetch_arxiv.py
    â”‚     â””â”€â”€ final_answer.py
    â”œâ”€â”€ graph.py
    â”œâ”€â”€ state.py
    â”œâ”€â”€ readme.md
```

##  â–¶ï¸ How It Works

User sends query

Orchestrator LLM interprets intent

Router maps intent to tool name

Tool executes and returns observation

Observation appended to intermediate_steps

Orchestrator re-evaluates based on new state

Loop continues until final_answer

Final answer synthesized from tool outputs



##  ðŸ§ª Example Query

"Tell me something interesting about Dynamic Backtracking AI and LLMs"

Agent may autonomously choose:

fetch_arxiv

then rag_search

then final_answer


## ðŸ Expected Output

A deeply synthesized LLM-generated answer, grounded with fetched evidence from multiple sources.

Agent Data Flow Diagram

```mermaid
flowchart TD

    %% Main Flow Nodes
    A[User Input] --> B(Orchestrator LLM<br>LLM decides the next tool)
    B --> C(Router<br>Reads last tool in state)

    %% Tool Routing
    C -->|rag_search| D[RAG Search Tool]
    C -->|rag_search_filter| E[RAG Filter Tool]
    C -->|fetch_arxiv| F[Fetch Arxiv Tool]
    C -->|web_search| G[Web Search Tool]

    %% Tool Results Loop Back
    D --> B
    E --> B
    F --> B
    G --> B
    
    %% Final Output
    B --> H[Final Answer]
    H --> I((Output to User))


```

